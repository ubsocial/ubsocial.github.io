<!doctype html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="../icons/logoTit.png">
    <link rel="stylesheet" href="../estilo.css">
    <title>UB Social</title>
</head>
<body>
<div class="container-fluid">


    <div class="row">
        <div class="col-sm-12">
            <nav class="navbar rounded-bottom fixed-top navbar-expand-lg navbar-light bg-light shadow">
                <div class="container-fluid">
                    <a class="navbar-brand" href="../index.html"><img src="../icons/logo.png" class="d-inline-block align-text-top" width="11pt"> UB Social</a>
                    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
                    <div class="collapse navbar-collapse" id="navbarNav">
                        <ul class="navbar-nav">
                            <li class="nav-item"><a class="nav-link" href="../index.html">Home</a></li>
                            <li class="nav-item"><a class="nav-link" href="../sobre/sobre.html">Sobre</a></li>
                            <li class="nav-item"><a class="nav-link" href="../livros/livros.html">Livros</a></li>
                        </ul>
                    </div>
                </div>
            </nav>
        </div>
    </div>

    <div class="row">
        <div class="col-sm-12 text-center" id="titulo">
            <h1>IA reconhecimento de imagens</h1>
            <h6><strong>IA reconhecimento de imagens com Python</strong></h6>
            <a href="../index.html" class="btn btn-link text-decoration-none mb-3">Voltar</a><br>
            <a href="https://youtu.be/B96os1QhKRA?si=3onkLedZ8GKrOfqv" class="btn btn-link text-decoration-none" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" width="1.3em" height="1.3em" fill="currentColor" class="bi bi-youtube text-danger" viewBox="0 0 16 16"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.007 2.007 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.007 2.007 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31.4 31.4 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.007 2.007 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A99.788 99.788 0 0 1 7.858 2h.193zM6.4 5.209v4.818l4.157-2.408L6.4 5.209z"/></svg> Conteúdo disponível</a><br>
            <a href="https://github.com/mateusschwede/python_algoritmos_ia" class="btn btn-link text-decoration-none" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-github text-dark" viewBox="0 0 16 16"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.01 8.01 0 0 0 16 8c0-4.42-3.58-8-8-8"/></svg> Github do projeto</a><br><br>
        </div>

        <div class="col-sm-12">
            <h4>Introdução</h4>
            <p id="textoPost">Criação de notebook Python para reconhecimento de imagens (gatos e cães), através de processo via rede neural CNN (convolutional neural network), com Keras. Dataset utilizado 'Cats vs Dogs', disponível no <a href="https://www.kaggle.com/c/dogs-vs-cats/data" target="_blank" class="text-decoration-none">Kaggle</a> e <a href="https://www.tensorflow.org/datasets/catalog/cats_vs_dogs" target="_blank" class="text-decoration-none">Tensorflow Datasets</a>.</p>

            <br><h4>Pré-processamento dos dados:</h4>
            <p>Carregamento dos dados:</p>
<small><pre><code>
# Instalar pré-requisitos: pip install tensorflow numpy matplotlib pillow
import tensorflow as tf
from tensorflow.keras import layers, models
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt

(train_data, test_data), metadata = tfds.load('cats_vs_dogs', split=['train[:80%]', 'train[80%:]'], with_info=True, as_supervised=True)
</code></pre></small>

            <br><p>Redimencionamento e normalização das imagens:</p>
<small><pre><code>
IMG_SIZE = 128

def format_image(image, label):
    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))
    image = image / 255.0 # Normalizar
    return image, label

train_data = train_data.map(format_image)
test_data = test_data.map(format_image)
</code></pre></small>

            <br><p>Batching (tamanho do lote) e otimização em cache de leitura de dados:</p>
<small><pre><code>
BATCH_SIZE = 32
SHUFFLE_BUFFER_SIZE = 1000

train_data = train_data.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)
test_data = test_data.batch(BATCH_SIZE)
</code></pre></small>

            <br><p>Criação do modelo, com camadas Conv2D e MaxPooling2D:</p>
<small><pre><code>
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),
    layers.MaxPooling2D(2, 2),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),
    layers.Flatten(),
    layers.Dense(512, activation='relu'),
    layers.Dense(1, activation='sigmoid') # Saída: 0 (gato) ou 1 (cão)
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
</code></pre></small>

            <br><p>Treinamento do modelo:</p>
            <p id="textoPost">Aumentar nº de épocas e ajustar arquitetura da rede podem melhorar precisão, mas também aumentar risco de overfitting.</p>
<small><pre><code>
EPOCHS = 10
history = model.fit(train_data, epochs=EPOCHS, validation_data=test_data)
</code></pre></small>

            <br><p>Visualização dos resultados:</p>
<small><pre><code>
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs_range = range(EPOCHS)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()
</code></pre></small>

            <br><p>Avaliação no conjunto de teste:</p>
<small><pre><code>
test_loss, test_acc = model.evaluate(test_data)
print(f'Test accuracy: {test_acc}')
</code></pre></small>

            <br><p>Salvar/exportar modelo:</p>
<small><pre><code>
model.save('cat_dog_classifier.keras') # salvar '.keras' ou '.h5'
</code></pre></small>

            <br><h4>Novas submissões:</h4>
            <p>Necessária adequação prévia da imagem a ser submetida, redimencionado-a 128x128, normalizando-a (dividindo por 250) e convertê-la para formato compatível com o modelo. Abaixo, pode-se criar loop para submissão de várias imagens, simultaneamente.</p>
<small><pre><code>
import numpy as np
from tensorflow.keras.preprocessing import image
from PIL import Image

def prepare_image(img_path):
    img = Image.open(img_path)
    img = img.resize((IMG_SIZE, IMG_SIZE))
    img = np.array(img) / 255.0
    img = np.expand_dims(img, axis=0)
    return img

img_path = 'diretorio/imagem.jpg' # exemplo: '/content/gato.jpg'
new_image = prepare_image(img_path)

prediction = model.predict(new_image)
print(prediction[0])

if prediction[0] &gt; 0.5:
    print("É um cão!")
else:
    print("É um gato!")
</code></pre></small>

            <br><p>Carregamento do modelo:</p>
<small><pre><code>
from tensorflow.keras.models import load_model
model = load_model('cat_dog_classifier.keras') # modelo '.keras' ou '.h5'
</code></pre></small>
        </div>
    </div>


<!--Rodapé-->
<div class="row">
    <div class="col-sm-12 text-center bg-black text-light pt-4 pb-3">
        <p>Elaborado por Mateus Schwede<br><small class="text-muted">ubsocial.github.io</small></p>
    </div>
</div>

</div>
</body>
</html>