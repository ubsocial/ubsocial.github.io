<!doctype html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="../../icons/logoTit.png">
    <link rel="stylesheet" href="../../estilo.css">
    <title>UB Social</title>
</head>
<body>
<div class="container-fluid">


    <div class="row">
        <div class="col-sm-12">
            <nav class="navbar rounded-bottom fixed-top navbar-expand-lg navbar-light bg-light shadow">
                <div class="container-fluid">
                    <a class="navbar-brand" href="../../index.html"><img src="../../icons/logo.png" class="d-inline-block align-text-top" width="11pt"> UB Social</a>
                    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
                    <div class="collapse navbar-collapse" id="navbarNav">
                        <ul class="navbar-nav">
                            <li class="nav-item"><a class="nav-link" href="../../index.html">Home</a></li>
                            <li class="nav-item"><a class="nav-link" href="../../sobre/sobre.html">Sobre</a></li>
                            <li class="nav-item"><a class="nav-link" href="../../cursos.html" id="navCursos">Cursos</a></li>
                            <li class="nav-item"><a class="nav-link" href="../../livros/livros.html">Livros</a></li>
                        </ul>
                    </div>
                </div>
            </nav>
        </div>
    </div>

    <div class="row">
        <div class="col-sm-12 text-center" id="titulo">
            <h1>Kubernetes</h1>
            <h6><strong>Conceitos básicos de Kubernetes K8s</strong></h6>
            <a href="../../index.html" class="btn btn-link text-decoration-none mb-3">Voltar</a><br>
            <a href="https://github.com/mateusschwede/kubernetes" target="_blank" class="btn btn-link text-decoration-none">Github do projeto</a><br>
            <a href="https://youtube.com/playlist?list=PLnPZ9TE1Tj4CpbmTsTgqVpRG0hIgHXsaX" class="btn btn-link text-decoration-none" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" width="1.3em" fill="currentColor" class="bi bi-youtube text-danger" viewBox="0 0 16 16"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.007 2.007 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.007 2.007 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31.4 31.4 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.007 2.007 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A99.788 99.788 0 0 1 7.858 2h.193zM6.4 5.209v4.818l4.157-2.408L6.4 5.209z"/></svg> Conteúdo disponível</a>
        </div>

        <div class="col-sm-12">
            <h4>Problemática</h4>
            <p id="textoPost">Nos primórdios, para cada serviço em uma aplicação (Apache, MySQL, nginx...) era necessária uma máquina física para alocá-lo, resultando-se em vários servidores para rodar um site que necessitasse dessas várias aplicações, promovendo capacidade subutilizada. Com a chegada da Virtualização, tudo fora executado, em VMs, numa máquina física única, porém há muito gasto de hardware na alocação e cotidiano. Dessa forma, havia-se a Consolidação do Servidor, onde que os servidores que não estavam sendo utilizados, em alguns momentos de pouco fluxo, eram desligados. Quando a necessidade de carga era maior, os demais servidores eram religados, alocando novamente as outras VMs que haviam sido movidas para o único servidor no início (Live Migration). Com o surgimento dos Containers, constituiram-se as aplicações isoladas (Microsserviços), descartou-se a necessidade de replicar stacks do SO, como duplicação de libraries, a própria infra do SO e trazendo, com isso, maior desempenho, facilidade de manutenção e leveza.</p>
            
            <br><h4>Conceito</h4>
            <p id="textoPost">Kubernetes (K8s) é ferramenta de código aberto para automatizar implantação, gerenciamento e escalonamento de aplicações conteinerizadas, automatizando, com isso, toda a infraestrutura de aplicações. A <b>Orquestração</b> gerenciará os containers entre os servidores e os ativará/desativará de acordo com a necessidade de carga no cluster, escalando recursos e corrigindo problemas. O Kubernetes pode ser utilizado em Cluster Single Node (1 só servidor) ou Cluster padrão (1-N Master Node (Máquina Mestre/gerenciadora), 1-N Slaves/Workers Node (Máquina Escrava/gerenciada)).</p>
            <ul>
                <li>Quando um node que aloca recursos tem pane, os containers nele serão perdidos?</li>
                <li>Se há 10 réplicas da aplicação 1.0 no cluster, e insiro uma réplica da 1.1, como as demais serão atualizadas?</li>
                <li>Como escalar o software para lidar com o aumento da demanda?</li>
            </ul>

            <br><h4>Arquitetura K8s</h4>
            <img src="arquitetura.jpg" class="img-fluid rounded" width="350px">
            <p id="textoPost">Orquestrar tarefas de gerenciamento. Pode ser instalado em modo single ou cluster. O cluster é formado por nós master e worker, onde o master é node de interação com o usuário. Em grandes estruturas, podem haver mais de 1 master, para o caso de falhas e correção de problemas.</p>
            <ul>
                <li><b>Master</b>: Executa os componentes do plano de controle;</li>
                <li><b>Worker</b>: Geralmente executa os Containers.</li>
            </ul>
            <p>Componentes:</p>
            <ul>
                <li><b>kubeadm</b>: Automatiza grande parte do processo de criação/instalação do cluster;</li>
                <li><b>kubelet</b>: Componente essencial do K8s que lida com a execução de Pods. Atua como um agente em cada node, intermediando (interface) as trocas de mensagens entre API server e Docker runtime. Tecnicamente, faz interação com o Docker e kube-apiserver;</li>
                <li><b>kubectl</b>: CLI de interação com o K8s cluster.</li>
            </ul>
            <p><b>Pod</b>:</p>
            <img src="pod.jpg" class="img-fluid rounded" width="350px">
            <img src="pod2.jpg" class="img-fluid" width="380px">
            <p id="textoPost">Menor e mais básica estrutura do K8s, criada para abstrair o conceito de Container. Consiste de 1 ou mais Containers, recursos de armazenamento (Volumes) e 1 único ID e IP na rede do cluster K8s. Utiliza-se vários Containers dentro de um Pod, raramente, geralmente em que hajam vários processos, processos em batch (lote) e demais tarefas pesadas (Ex: Um Container Web Service recebe outra Imagem, que deverá ser processada pelo mesmo, ou seja, quando à 'relações' entre Containers em 1 mesmo Pod).</p>
            <p>Ciclo de Vida:</p>
            <img src="pod3.jpg" class="img-fluid" width="300px">
            <ul>
                <li><b>Pending</b>: Pod foi aceito pelo K8s, mas 1 ou mais Containers ainda não foram criados. Isso inclui tempo de escalonamento e tempo de download da Imagem;</li>
                <li><b>Running</b>: Pod foi alocado em um node e todos os Containers foram criados. Pelo menos 1 Container deve estar em execução, ou no processo de (re)inicialização;</li>
                <li><b>Succeeded</b>: Containers do Pod terminaram com sucesso;</li>
                <li><b>Failed</b>: Containers do Pod terminaram, pelo menos 1 deles com falha (status!=zero ou terminado pelo sistema);</li>
                <li><b>Unknown</b>: Por alguma razão, o estado do Pod não pode ser obtido. Tipicamente por causa de erro de comunicação entre node e Pod.</li>
            </ul>
            
            <p><b>Control Plane</b>:</p>
            <img src="controlPlane.jpg" class="img-fluid" width="380px">
            <p><small class="text-muted"><u>Legenda</u>: Minion é worker node</small></p>
            <ul>
                <li><b>etcd</b>: Provê sistema distribuído e compartilhado para armazenar o estado do cluster, sendo os dados armazenados em formato chave-valor (Informações como status do node master, status dos workers, status de Pods, etc). O etcd é executado, no K8s, como um Pod do mesmo;</li>
                <li><b>kube-apiserver</b>: Serve a API do K8s, baseada em REST, requisições via YAML (yml) que serão convertidas em JSON pelo kubectl;</li>
                <li><b>kube-controller-manager</b>: Pacote com diversos componentes de controle (Executa ações como verificação de funcionamento de Pods e, se houverem erros, criará novos Pods);</li>
                <li><b>kube-scheduler</b>: Escalona os Pods para serem executados nos nodes (Quando o Pod é criado, será escalonado para o node mais ideal). Pode também ser manipulado via usuário para escalonamento personalizado (Exemplo, escalonar Pods somente para as máquinas com GPU);</li>
                <li><b>kube-proxy</b>: Trata da comunicação entre nodes, adicionando regras ao firewall (Como em iptables, para abertura e redirecionamento de portas, túneis, etc).</li>
            </ul>
            <p id="textoPost">Tem-se também Registry, sendo geralmente em repositório local do Docker e outro remoto, como Docker Hub.</p>

            <br><h4>Rede no K8s</h4>
            <img src="rede.jpg" class="img-fluid" width="300px">
            <p id="textoPost">O modelo de redes do K8s envolve a criação de redes virtuais (Rede overlay) no cluster. Cada Pod do cluster tem um IP único (Externo ou interno), mesmo aqueles que são executados em outros nodes. Entre os plugins para criação de redes entre nodes, responsáveis por criar túneis seguros de comunicação, tem-se:</p>
            <ul>
                <li>Flannel;</li>
                <li>Weave.</li>
            </ul>

            <br><h4>Arquivo de Manifesto/Especificação</h4>
            <p id="textoPost">Pode ser escritos via YAML ou JSON, como modelo abaixo:</p>
<small><pre><code>
<b><u>arquivoTeste.yaml</u>:</b>
<b>apiVersion:</b> v1
<span class="text-muted"># Comentário</span>
<b>kind:</b> Pod
<b>metadata:</b>
    <b>name:</b> kuard
<b>spec:</b>
    <b>containers:</b>
        <b>-image:</b> gcr.io/kuar-demo/kuard-amd64:blue
        <b>name:</b> kuard
        <b>ports:</b>
            <b>- containerPort:</b> 8080
            <b>name:</b> http
            <b>protocol:</b> TCP
</code></pre></small>

            <br><h4>Recursos/Objetos no K8s (Kind)</h4>
            <ul>
                <li>Pods;</li>
                <li>Nodes;</li>
                <li>Deployment;</li>
                <li>ReplicaSet;</li>
                <li>Service.</li>
            </ul>

            <br><h4>kubectl e maneiras de interação</h4>
            <p id="textoPost">Há 2 maneiras básicas de interagir com K8s:</p>
            <ul>
                <li><b>Imperativa</b>: Através de diversos parâmetros do kubectl;
                    <ul>
                        <li>Diz ao K8s o que fazer (Ex: 'Crie 3 Pods com configurações X');</li>
                        <li>Ideal para aprendizado, visando experimentos interativos ou debugar serviços em produção.</li>
                    </ul>
                </li>
                <li><b>Declarativa</b>: Escrevendo manifestos e os usando com o comando <i>kubectl apply</i>.
                    <ul>
                        <li>Diz ao K8s o que você quer (Ex: 'Quero que seja XYZ', então serão feitas, automaticamente, criações e gestão de Pods e afins para alcançar o objetivo solicitado);</li>
                        <li>Melhor para implantar serviços de maneira a facilitar reprodutibilidade;</li>
                        <li>Recomendado para gerenciar aplicações K8s em produção.</li>
                    </ul>
                </li>
            </ul>

            <br><h5>Comandos de Abordagem Imperativa:</h5>
            <p id="textoPost">Kubectl <i>get</i>, <i>describe</i> e <i>delete</i> podem ser usados com quaisquer recursos. Além desses, tem-se também <i>create</i>, <i>run</i>, <i>scale</i>, <i>expose</i>, <i>exec</i>, <i>copy</i> e <i>logs</i>.</p>
<small><pre><code>
<span class="text-muted"># Listar</span>
kubectl get pods
kubectl get nodes
kubectl get services

<span class="text-muted"># Ver informações detalhadas</span>
kubectl describe pod &lt;nome do Pod&gt;
kubectl describe service &lt;nome do Service&gt;

<span class="text-muted"># Exclusão</span>
kubectl delete pod &lt;nome do Pod&gt;
kubectl delete deployment &lt;nome do Deployment&gt;
</code></pre></small>

            <br><h5>Comandos de Abordagem Declarativa:</h5>
            <p id="textoPost">Em caso de mudanças no arquivo, <i>apply</i> atualiza os recursos.</p>
<small><pre><code>
kubectl apply -f &lt;arquivo.yaml&gt;
kubectl apply -f &lt;arquivo1.yaml&gt; -f &lt;arquivo2.yaml&gt;
kubectl apply -f &lt;folder&gt;/
</code></pre></small>

            <br><h4>Criar Pod</h4>
            <p id="textoPost">Há diversos maneiras, entre as principais, via comando '<i><span class="text-muted">kubectl run nginx --generator=run-pod/v1 --image=nginx</span></i>', via comando de criação em arquivo manifesto ('<i><span class="text-muted">kubectl create -f diretorio/nomeManifesto.yaml</span></i>') ou neste formato, diretamente:</p>
<small><pre><code>
<span class="text-muted">cat &lt;&lt; EOF | kubectl create -f -</span>
apiVersion: <span class="text-muted">v1</span>
kind: <span class="text-muted">Pod</span>
metadata:
    name: <span class="text-muted">nginx-pod</span>
spec:
    containers:
        -name: <span class="text-muted">nginx-container</span>
        image: <span class="text-muted">nginx</span>
<span class="text-muted">EOF</span>
</code></pre></small>

            <br><h4>Exportar manifesto</h4>
            <ol>
                <li>Salvar manifesto de um Pod: <span class="text-muted">kubectl get pod my-pod -o yaml &gt; my-pod.yaml</span></li>
                <li>Salvar manifesto sem informações específicas do cluster: <span class="text-muted">kubectl get pod my-pod -o yaml --export &gt; my-pod.yaml</span></li>
            </ol>

            <br><h4>Namespace</h4>
            <p id="textoPost">K8s usa namespaces para organizar objetos no cluster através de uma divisão lógica (Como se fosse uma pasta). Por padrão, kubectl interage com o namespace padrão (default). Para usar namespace específico (Diferente do padrão), pode-se usar a flag <span class="text-muted">--namespace=&lt;nome&gt;</span>, ou ainda <span class="text-muted">-n &lt;nome&gt;</span>. Para interagir com todos os namespaces, pode-se usar a flag <span class="text-muted">--all-namespaces</span> ao comando.</p>
<small><pre><code>
<b>Criar namespace:</b>
kubectl create namespace dev
kubectl create namespace prod

<b>Listar namespaces:</b>
kubectl get namespaces

<b>Remover namespace:</b>
kubectl delete namespace dev

<b>Filtrar Pods por namespace:</b>
kubectl get pods --namespace=teste
kubectl get pods -n teste

<b>Listar Pods de todos namespaces:</b>
kubectl get pods --all-namespaces
</code></pre></small>

            <br><h4>Label</h4>
            <p id="textoPost">Par de chave-valor String. Todos os recursos/objetos do K8s podem ser rotulados. Ideal para filtragens/classificações. Existem 2 tipos de labels:</p>
<small><pre><code>
<b>1. Equality-based requirement (Igualdades/Diferenças):</b>
environment = production <span class="text-muted"># environment é igual a production</span>
tier != frontend

<b>2. Set-based requirement (Conjuntos):</b>
environment in (production, qa) <span class="text-muted"># environment está em production ou qa</span>
tier notin (frontend, backend)

<u>COMANDOS</u>:
<b>Mostrar labels dos recursos:</b> kubectl get pods --show-labels

<b>Excluir Pods com label <i>run=myapp</i>:</b>
kubectl delete pods -l environment=production,tier=frontend
kubectl get pods -l 'environment in (production),tier in (frontend)'

<b>Atribuir label:</b> kubectl label deployment nginx-deployment tier=dev
</code></pre></small>

            <br><h4>Instalação Singlenode do K8s (Ubuntu)</h4>
            <p id="textoPost">Pode-se instalar a versão K8s Singlenode, via Microk8s (Para dispositivos embarcados, sendo mais estável) ou Minikube (Para ambientes Singlenode). Tem-se, também, a instalação em cluster (Instruções abaixo), onde precisa-se definir Master(s), Worker Nodes.</p>
<small><pre><code>
<b>1. Instalar Docker em todos Nodes:</b>
sudo apt install curl
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
sudo apt update && sudo sudo apt list docker-ce -a

sudo apt install docker-ce=18.06.1~ce~3-0~ubuntu
sudo apt-mark hold docker-ce
cat &gt; /etc/docker/daemon.json &lt;&lt;EOF
{
    "exec-opts": ["native.cgroupdriver=systemd"],
    "log-driver": "json-file"
    "log-opts": {
        "max-size": "100m"
    },
    "storage-driver": "overlay2"
}
EOF

mkdir -p /etc/systemd/system/docker.service.d
systemctl daemon-reload
systemctl restart docker
sudo docker version

<b>2. Instalar K8s em todos Nodes:</b>
<span class="text-muted"># No final, desabilita-se swap para que o K8s funcione melhor</span>
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
cat &lt;&lt; EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF

sudo apt update
sudo apt list kubelet -a

sudo apt install kubelet=1.12.7-00 kubeadm=1.12.7-00 kubectl=1.12.7-00
sudo apt-mark hold kubelet kubeadm kubectl
sudo kubeadm version

sudo swapoff -a
sudo sed -i'/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
</code></pre></small>

            <br><h4>Minikube em Singlenode</h4>
<small><pre><code>
<b>Versão Minikube</b>: minikube version
<b>Iniciar cluster Minikube</b>: minikube start --wait=false <span class="text-muted">#Instala Imagens e Pods necessários</span>

<b>Ver informações do cluster</b>: kubectl cluster-info
<b>Ver nodes do cluster</b>: kubectl get nodes
<b>Ver namespaces do cluster:</b> kubectl get namespaces <span class="text-muted">#Namespace 'kube-system' é onde o K8s está instalado</span>
<b>Ver Pods do cluster</b>: kubectl get pods <span class="text-muted">#Mostrará Pods do Namespace default</span>
<b>Ver Pods por namespace</b>: kubectl get pods -n kube-system <span class="text-muted">#De todos namespaces 'get pods --all-namespaces'. Flag '-w' mostra iterativamente (Ctrl+c para sair). Flag '-o wide' mostra informações extras</span>
<b>Ver informações do Pod</b>: kubectl describe pod etcd-minikube -n kube-system

<b>Criar namespace</b>: kubectl create namespace ubsocial
<b>Criar Pod</b>: kubectl run nginx --generator=run-pod/v1 --image=nginx -n ubsocial <span class="text-muted">#Criará Pod no Namespace ubsocial. Nesse caso, utilizando 'curl ipPodNginx' acessará a página do nginx</span>
<b>Criar Pod via arquivo Manifesto diretamente</b>:
cat &lt;&lt; EOF | kubectl create -f -
apiVersion: v1
kind: Pod
metadata:
    name: nginx-pod
spec:
    containers:
        -name: nginx-container
        image: nginx
EOF

<b>Criar Pod via arquivo Manifesto específico (arquivoManifesto.yaml)</b>: kubectl create -f arquivoManifesto.yaml -n ubsocial
<b>Exportar Manifesto de Pod</b>: kubectl get pod nginx -o yaml -n ubsocial --export &gt; nginx.yaml <span class="text-muted">#Pode-se não redirecionar ao arquivo, também retirar o --export para ver na tela</span>

<b>Ver labels</b>: kubectl get pods --show-labels -n ubsocial
<b>Atribuir label ao Pod</b>: kubectl label pod nginx-pod -n ubsocial run=novoNginx

<b>Excluir Pod</b>: kubectl delete pod nginx -n ubsocial <span class="text-muted">#Excluirá Pod 'nginx' do Namespace 'ubsocial'</span>
<b>Excluir Pods via label</b>: kubectl delete pods -l run=novoNginx --all-namespaces <span class="text-muted">#Flag '-n nomeNamespace' para filtrar por namespace</span>

<b>Ver Services dos Namespaces:</b> kubectl get services --all-namespaces (Em ports, mostrará, portaHost:portaService)

<b>Editar Manifesto de Pod via label</b>: kubectl edit pod nginx -n ubsocial <span class="text-muted">#Teclas 'Esc', após ':wq' para salvar e sair</span>
</code></pre></small>

            <br><h4>Dashboard Minikube</h4>
            <p id="textoPost">Sistema GUI para gerenciamento Kubernetes (Namespaces, Nodes, Volumes, Pods, etc).</p>
            <img src="dashboardKubernetes.png" class="img-fluid rounded" width="500px">
<small><pre><code>
<b>Instalação Dashboard via Minikube:</b> minikube addons enable dashboard
<b>Arquivo manifesto para executar o Dashboard:</b> cat /opt/kubernetes-dashboard.yaml (Conteúdo abaixo)

apiVersion: v1
kind: Service
metadata:
    labels:
        app: kubernetes-dashboard
    name: kubernetes-dashboard-katacoda
    namespace: kubernetes-dashboard
spec:
    ports:
        - port: 80
    protocol: TCP
    targetPort: 9090
    nodePort: 30000
selector:
    k8s-app: kubernetes-dashboard
type: NodePort

<b>Criar Service Dashboard:</b> kubectl apply -f /opt/kubernetes-dashboard.yaml (apply mesmo que create)
<i>Service acima habilitará a porta 30000, que dará acesso ao Dashboard (Imagem acima)</i>
<b>Acesso via curl:</b> curl localhost:30000 <span class="text-muted">#Mas para acessá-lo, precisa ser via Browser</span>
</code></pre></small>

            <br><h4>Configuração multi-node do K8s</h4>
            <p id="textoPost">Levando em conta que os componentes do K8s Singlenode (kubeadm, kubelet...) já estejam instalados.</p>
<small><pre><code>
<span class="text-muted">-- (Master Node) --</span>
<b>1. Iniciar Master Node (No fim, salvar o comando <i>kubeadm join</i>):</b>
kubeadm init --apiserver-advertise-address $(hostname -i)
<span class="text-muted">#Comando acima gerará token de autenticação para acesso junto com o comando para usar nos workers (<i>kubeadm join ipHost:porta --token numToken --discovery-token-ca-cert-hash sha256:numHash</i> (Exemplo 'ipHost:porta': 172.17.0.8:6443))</span>
<span class="text-muted">#Comando 'kubeadm token list' mostrará os tokens</span>

<b>2. Setar arquivo de configuração para kubectl poder interagir com o cluster:</b>
sudo cp /etc/kubernetes/admin.conf $HOME/
sudo chown $(id -u):$(id -g) $HOME/admin.conf
export KUBECONFIG=$HOME/admin.conf

<b>3. Configurar rede do K8s com Plugin Weave:</b>
kubectl apply -n kube-system -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 |tr -d '\n')" <span class="text-muted">#Baixará/Executará manifesto e o salvará em '/opt/weave-kube'</span>

<b>4. Testar Node master:</b> kubectl get nodes <span class="text-muted">#Node master possuirá status 'ready'</span>
<b>5. Verificar Plugin Weave:</b> kubectl get pod -n kube-system <span class="text-muted">#Pod weave-net-rdgfx possuirá 2 Pods ready e status 'running' (1 para casos de falha)</span>

<span class="text-muted">-- (Worker Node 1) --</span>
<b>6. Adicionar Worker Nodes ao cluster (Usar comando salvo após configurar Master Node):</b>
kubeadm join ipHost:porta --token numToken --discovery-token-ca-cert-hash sha256:numHash <span class="text-muted">(Exemplo 'ipHost:porta': 172.17.0.8:6443, comando 'kubectl cluster-info' mostra isso)</span>

<span class="text-muted">-- (Master Node) --</span>
<b>7. Verificar se há Worker Node:</b> kubectl get nodes <span class="text-muted">#Mostrará node01 com status 'ready'</span>
<b>8. Mostrar detalhes do Master Node:</b> kubectl describe node nomeMaster <span class="text-muted">(Geralmente 'master')</span>
<b>9. Mostrar detalhes do Worker Node 1:</b> kubectl describe node nomeNode01 <span class="text-muted">(Geralmente 'node01')</span>

<b>10. Listar status dos componentes:</b> kubectl get componentstatuses
<b>11. Listar Pods de todos Namespaces:</b> kubectl get pod --all-namespaces
<b>12. Mostrar informações do cluster:</b> kubectl cluster-info
<b>13. Permitir que Master execute Pods:</b> kubectl taint node nomeMaster node-role.kubernetes.io/master:NoSchedule- <span class="text-muted">#Não é recomendado que Master execute Pods</span>

<b>Outros comandos úteis:</b>
kubectl logs deployment/myapp
kubectl -n kube-system logs -f POD_NAME
kubectl exec POD_NAME -it sh
kubectl cp POD_NAME:&lt;FILE&gt; &lt;LOCAL FILE&gt;
kubectl top pod POD_NAME --containers
kubectl -n my-ns delete pod,svc --all
kubectl edit svc/docker-registry
</code></pre></small>

            <br><h4>ReplicaSet</h4>
            <p id="textoPost">ReplicaSet é o controller que mantém estável um conjunto de Pods em execução, garantindo disponibilidade de um número específico de Pods idênticos. ReplicaSet é raramente utilizado diretamente, pois existe um conceito de mais alto nível: Deployment, que gerencia ReplicaSets e provê uma maneira de atualizar os Pods, além de outras features.</p>
<small><pre><code>
<b><u>Manifesto exemplo</u>:</b>
apiVersion: extensions/v1beta1
kind: ReplicaSet
metadata:
    name: kuard
spec:
    replicas: 1
    template:
        metadata:
            labels:
                app: kuard
                version: "2"
        spec:
            containers:
                - name: kuard
                image: "gcr.io/kuar-demo/kuard-amd64:green"
</code></pre></small>

            <p><b>Manifesto modelo para ReplicaSet:</b></p>
            <p id="textoPost">De acordo com o manifesto abaixo, todos os Pods com tier 'busybox' serão replicados, conforme quantidade informada. No próprio manifesto de criação dos Pods, pode ser informado o ReplicaSet, conforme abaixo. ReplicaSet é controller Equality-based, então, no selector, o tier informado pode ser diferente, conforme necessidade, podendo informar múltiplos tiers no selector.</p>
<small><pre><code>
<b><u>busybox-rs.yaml:</u></b>
apiVersion: apps/v1
kind: ReplicaSet <span class="text-muted">#Tipo ReplicaSet</span>
metadata:
    <b>name: busybox</b> <span class="text-muted">#Nome da ReplicaSet</span>
    labels:
        app: busybox
spec:
    <b>replicas: 2</b> <span class="text-muted">#Quantidade de réplicas</span>
    <b>selector:</b> <span class="text-muted">#Pods que serão replicados pelo K8s</span>
        <b>matchLabels:</b>
            <b>tier: busybox</b> <span class="text-muted">#Nome de acordo com label do Pod à replicar</span>
    template:
        metadata:
            labels:
                tier: busybox
        spec:
            containers:
                - name: busybox
                image: radial/busyboxplus:curl
</code></pre></small>

            <p><b>Comandos ReplicaSet:</b></p>
<small><pre><code>
<span class="text-muted">-- (Master Node) --</span>
<b>1. Criar ReplicaSet:</b> kubectl create -f busybox-rs.yaml
<b>2. Listar ReplicaSets:</b> kubectl get rs
<b>3. Listar Pods relacionados:</b> kubectl get pods -o wide
<b>4. Mostrar detalhes do ReplicaSet:</b> kubectl describe rs/busybox
<b>5. Escalar um ReplicaSet:</b> kubectl scale --replicas 3 rs busybox <span class="text-muted">#Alterna para 3 réplicas ao busybox</span>
<b>6. Deletar um ReplicaSet:</b> kubectl delete rs busybox
<b>7. Deletar todos Pods e ReplicaSets:</b> kubectl delete pod,rs --all
</code></pre></small>

            <br><h4>Deployment</h4>
            <p id="textoPost">É uma maneira de automatizar o gerenciamento de Pods. Permite especificar um estado desejado para um conjunto de Pods e o cluster vai constantemente trabalhar para manter o estado desejado, dessa forma o Pod permanece 'vivo' e com status congelado em seu ciclo de vida. Todo Deployment cria um ReplicaSet. Com o Deployment em funcionamento, descarta-se necessidade de lembrar nomes e ip's de Pods. Entre as vantagens, tem-se:</p>
            <ul>
                <li><b>Escalabilidade</b>: Com um Deployment, pode-se especificar o número de réplicas desejado e o Deployment vai criar ou remover Pods até alcançar tal número;</li>
                <li><b>Atualizações</b>: É possível alterar a Imagem de um Container para uma nova versão (Rollout) e o Deployment vai gradualmente substituir os Containers para a versão nova (Evitando downtime);</li>
                <li><b>Self-healing</b>: Se um dos Pods for acidentalmente destruído, o Deployment vai imediatamente iniciar um novo Pod para substituí-lo.</li>
            </ul>
            <p id="textoPost">O Deployment é criado através de Manifesto, conforme exemplo-modelo abaixo (O modelo abaixo executará automaticamente, devido à 1ª linha de execução):</p>
<small><pre><code>
<span class="text-muted">cat &lt;&lt;EOF | kubectl create -f -</span>
apiVersion: apps/v1
<b>kind: Deployment</b>
metadata:
    name: nginx-deployment
    labels:
        apps: nginx
spec:
    <b>replicas: 2</b>
    selector:
        <b>matchLabels:</b>
            <b>app: nginx</b> <span class="text-muted">#Nome de acordo com label do Pod à replicar</span>
    template:
        metadata:
            <b>labels:</b>
                <b>app: nginx</b>
        spec:
            containers:
                - name: nginx
                image: nginx:1.15.4
                ports:
                    - containerPort: 80
<span class="text-muted">EOF</span>
</code></pre></small>

            <p><b>Comandos Deployment:</b></p>
            <p id="textoPost">Ao atualizar/modificar aplicação envolvida em Deployment, a modificação será gradativa, ou seja, atualizará 1 Pod e, após esse funcionando, atualizará outro e assim sucessivamente.</p>
<small><pre><code>
<span class="text-muted">-- (Master Node) --</span>
<b>1. Criar Deployment (Sem Manifesto):</b>
kubectl create deployment nomeDeployment --image=nginx <span class="text-muted">#Nome do Deployment à preferência do usuário</span>

<b>2. Ver informações relacionadas:</b>
kubectl get pods -o wide <span class="text-muted">#Criou Pod relacionado. Mesmo se o usuário removê-lo, o Deployment criará outro para satisfazer a regra no Manifesto de sua origem</span>
kubectl get deployments <span class="text-muted">#Criou deployment conforme solicitado</span>
kubectl describe deployment nomeDeployment <span class="text-muted">#Mostrar detalhes do deployment</span>
curl ipPodCriado <span class="text-muted">#Acessará página nginx do Pod criado, então está funcionando corretamente</span>

<b>3. Alterar quantidade de réplicas:</b> kubectl scale --replicas 3 deployment nomeDeployment
kubectl delete pods -l nomeLabelPodsReplicados
kubectl get pods -o wide -w <span class="text-muted">#Deployment refará os Pods de acordo com a quantidade de réplicas solicitadas no Manifesto de sua origem</span>

<b>4. Atualizar Deployment com nova versão da aplicação:</b> kubectl set image deployment/nomeDeployment nginx=nginx:1.91 --record <span class="text-muted">#Ficará com status Scaled up</span>
<b>5. Ver status da atualização:</b> kubectl rollout status deployment.v1.apps/nomeDeployment
kubectl describe deployment nomeDeployment <span class="text-muted">#De acordo com as atualizações será a versão do Deployment. Caso a versão da Imagem não exista (Como a do nginx acima), mostrará status erro ImagePullBackOff</span>
<b>6. Desfazer atualização do Deployment:</b> kubectl rollout undo deployment.v1.apps/nomeDeployment <span class="text-muted">#Ficará com status Scaled down</span>
</code></pre></small>

            <br><h4>Service</h4>
            <img src="service.jpg" class="img-fluid" width="500px">
            <p id="textoPost">Pods podem ser criados e destruídos constantemente por um Deployment. Uma vez que cada Pod recebe um IP diferente, os Pods em execução em um dado momento podem ser diferentes dos Pods em um momento posterior. Como manter o acesso aos serviços providos pelos Pods? <u>Exemplo</u>: Como 'frontend' Pods mantém a informação sobre 'backend' Pods se os IPs dos mesmos mudam repentinamente?</p>
            <p id="textoPost">O Service cria uma camada de abstração acima do conjunto de Pods réplicas, permitindo acesso dinâmico a um grupo de Pods (Balanceador de Carga). Então, esse Balanceador de Carga vai, dinamicamente, acessar as listas de Pods do Deployment, permitindo acesso aos Pods (Se um Pod cair, ele selecionará outro ao balanceamento, para acesso. Tanto faz o Pod, o Service K8s escolherá e gerenciará isso de forma automática, sem que o usuário precise se preocupar). Assim, pode-se prover acesso ininterrupto e dinâmico a qualquer réplica, além de balanceamento de carga.</p>
            <img src="serviceConceito.png" class="img-fluid" width="270px">
            <p id="textoPost">É através das labels referenciadas no selector do arquivo Manifesto. O arquivo de Manifesto de Service é do tipo Equality-based, ou seja, não possui 'matchLabels' em sua composição. Abaixo, segue modelo exemplo de Manifesto com Service:</p>
            <p id="textoPost" style="color: red;">O ideal no K8s é criar Deployment para criar e gerenciar quantidade de Pods e, após isso, criar Service para acesso.</p>
<small><pre><code>
apiVersion: v1
<b>kind: Service</b>
metadata:
    name: meuService
spec:
    <b>selector:</b>
        <b>app: meuApp</b>
    ports:
        - protocol: TCP
        port: 80
        targetPort: 9376
</code></pre></small>

            <p><b>Tipos de Services:</b></p>
            <ul>
                <li><b>ClusterIP</b>: Expõe o Service apenas para a rede interna do cluster, fornecendo IP estático para acesso aos Pods. Esse é o ServiceType padrão (K8s cria um assim para o kube-apiserver, pode-se conferir com 'kubectl get services -n kube-system'). Recomendado para somente acessos internos do cluster;</li>
                <li><b>NodePort</b>: Expõe o Service em cada Node com uma porta estática (NodePort), permitindo acesso externo através do endereço 'ipNode:NodePort' (Mapeará uma porta à uma porta de todos Containers, para todos os Nodes incluindo o Master). Recomendado para acessos com dispositivos externos, como acesso externo no cluster para BD, serviços web, etc;</li>
                <li><b>ExternalName</b>: Mapeia o Service para um nome/endereço (e.g.foo.bar.example.com). Recomendado para ambientes de produção, com serviços de DNS, onde descartará IPs e labels, para dar vez a nomes como endereços web;</li>
                <li><b>LoadBalancer</b>: Expõe o Service externamente através de um balanceador de carga de um provedor de nuvem. Internamente, cria NodePort, pra onde o balanceador de carga externo roteia. Recomendado em situações onde descartará o LoadBalancer do K8s local, trocando-o por outro em cloud, como em Web Services.</li>
            </ul>

            <p><b>Exemplo prático (Service ClusterIP):</b></p>
<small><pre><code>
<span class="text-muted">-- (Master Node) --</span>
<b>1. Criar Deployment (kubectl create -f nomeArquivo.yaml)</b>
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-deployment
spec:
  selector:
    matchLabels:
      app: metrics
      department: sales
  replicas: 3
  template:
    metadata:
      labels:
        app: metrics
        department: sales
    spec:
      containers:
      - name: hello
        image: "us-docker.pkg.dev/google-samples/containers/gke/hello-app:2.0"

<b>2. Ver Pods criados:</b> kubectl get pods
<b>3. Criar Service tipo ClusterIP (kubectl create -f nomeArquivo.yaml)</b>
apiVersion: v1
kind: Service
metadata:
  name: my-cip-service
spec:
  type: ClusterIP
  <span class="text-muted"># Uncomment the below line to create a Headless Service</span>
  <span class="text-muted"># clusterIP: None</span>
  selector:
    app: metrics
    department: sales
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080

<b>4. Listar services em execução:</b> kubectl get svc
<b>5. Mostrar detalhes do Service:</b> kubectl describe svc nomeService
<b>6. Acessar Service:</b> kubectl exec -ti nomePod (my-deployment)
<b>7. No container, solicitar requisição ao Service (Via curl):</b>
apk add --no-cache curl
curl ipCluster:80
<b>8. Deletar Service:</b> kubectl delete svc nomeService

<b><u>Estrutura do describe service</u>:</b>
<b>Name:</b> nginx-service
<b>Namespace:</b> default
<b>Labels:</b> &lt;none&gt;
<b>Annotations:</b> &lt;none&gt;
<b>Selector:</b> app=nginx
<b>Type:</b> NodePort
<b>IP:</b> ipService
<b>Port:</b> &lt;unset&gt; 80/TCP
<b>TargetPort:</b> 80/TCP
<b>NodePort:</b> &lt;unset&gt; 30080/TCP
<b>Endpoints:</b> ipPod1:80,ipPod2:80
<b>Session Afﬁ.:</b> None
<b>Ext. Trafﬁc P.:</b> Cluster
<b>Events:</b> &lt;none&gt;
</code></pre></small>

            <br><h4>Microservices</h4>
            <p id="textoPost">Aplicações monolíticas consistem em única aplicação de software em camadas no qual frontend e backend estão juntos em único programa e plataforma. Porém, dificuldades em escalabilidade e arquitetura difícil de manter e evoluir são desafios que limitam essa abordagem.</p>
            <img src="monolitica1.png" class="img-fluid" width="500px">
            <img src="monolitica2.png" class="img-fluid" width="400px"><br><br>

            <p><b>Arquitetura de Microsserviços:</b></p>
            <p id="textoPost">Abordagem que desenvolve única aplicação como uma suíte de pequenos serviços, cada uma executando seu próprio processo e comunicando-se via mecanismos leves. Os serviços funcionam via mecanismos de deploy independentes totalmente automatizados. Há o mínimo possível de gerenciamento centralizado dos serviços, que podem ser escritos em diferentes linguagens e usar diferentes tecnologias para armazenamento de dados. Decompõe a aplicação por funções básicas, onde cada função é denominada um serviço e pode ser criada e implantada de maneira independente. Cada serviço individual pode funcionar e falhar sem comprometer os demais. O uso de microsserviços é uma das melhores maneiras de demonstrar o quão valioso é gerenciar Containers via K8s.</p>
            <img src="monolitica3.png" class="img-fluid" width="430px"><br><br>
            <p id="textoPost">Cada um desses microsserviços pode ser escalonado diferente e independentemente. Assim, se necessário, é possível alocar mais recursos para um determinado microsserviço. Entre as vantagens da utilização de Microservices, tem-se escalabilidade, facilidade na atualização de partes da aplicação, confiabilidade e disponibilidade (Uma parte pode parar, mas as outras continuam de pé), usar tecnologias diversificadas ideais para cada situação específica. Abaixo, exemplo prático de aplicação baseada em Microservices:</p>
            <img src="monolitica4.png" class="img-fluid" width="280px"><br><br>

            <p><b>Deploy de aplicação na prática:</b></p>
            <p id="textoPost">Aplicação, em Microservices, de carrinho de compras, composta por várias tecnologias. Abaixo, comandos para construção de toda a aplicação. Com poucos comandos, toda a aplicação já estará no ar rapidamente.</p>
<small><pre><code>
<span class="text-muted">-- (Master Node) --</span>
<b>1. Clonar o repositório do Git:</b> git clone https://github.com/linuxacademy/robot-shop.git <span class="text-muted">#Aplicação de carrinho de compras</span>

<b>2. Listar arquivos de descrições dentro do projeto:</b> ls robot-shop/K8s/descriptors/ <span class="text-muted">#Lista de vários Manifestos, entre eles Deployment, que garantirá a execução e gestão dos demais, e Service para acessá-los externamente</span>

<b>2. Criar Namespace e fazer deploy da aplicação:</b>
kubectl create namespace robot-shop
kubectl -n robot-shop create -f ~/robot-shop/K8s/descriptors/

<b>3. Acompanhar status dos Pods:</b> kubectl get pods -n robot-shop -w
<b>4. Acessar frontend da aplicação:</b> http://ipMasterNode:30080
</code></pre></small>

            <br><h4>StatefulSet</h4>
            <p id="textoPost">Pods, nativamente, são <i>stateless</i> (sem estado, não armazenam dados). No Deployment, ao reiniciar o Pod, os dados armazenados não estão garantidos e os ip's são modificados. Com StatefulSet, o Pod possuirá mesmo ip de rede, host e estado (armazenamento de dados assegurado), mesmo após cair e reiniciar. Diferente do Deployment, no StatefulSet cada volume é dedicado e não compartilhado.</p>
<small><pre><code>
apiVersion: v1
kind: Service
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  ports:
  - port: 80
    name: web
  clusterIP: None
  selector:
    app: nginx
---
apiVersion: apps/v1
<b>kind: StatefulSet</b>
metadata:
  name: web
spec:
  selector:
    matchLabels:
      app: nginx
  <b>serviceName: "nginx"</b>
  replicas: 3
  minReadySeconds: 10
  template:
    metadata:
      labels:
        app: nginx
    spec:
      terminationGracePeriodSeconds: 10
      containers:
      - name: nginx
        image: registry.k8s.io/nginx-slim:0.8
        ports:
        - containerPort: 80
          name: web
        volumeMounts:
        - name: www
          mountPath: /usr/share/nginx/html
  volumeClaimTemplates:
  - metadata:
      name: www
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: "my-storage-class"
      resources:
        requests:
          storage: 1Gi
</code></pre></small>

            <br><h4>Job</h4>
            <p id="textoPost">Carga de trabalho para determinada tarefa, onde os containers em execução saiam com êxito após conclusão. Jobs são ideiais para processamento único ou em lote, ao invés de serviço contínuo. <b>cron jobs</b>, construídos sob jobs, atuam com componente de agendamento (cron) para execução, a fim de agendar trabalhos futuros ou regulares/recorrentes.</p>
<small><pre><code>
apiVersion: v1
<b>kind: Job</b>
metadata:
  name: pi
spec:
  template:
    spec:
      containers:
      - name: pi
        image: perl:5.34.0
        command: ["perl",  "-Mbignum=bpi", "-wle", "print bpi(2000)"]
      restartPolicy: Never
  backoffLimit: 4
</code></pre></small>

            <br><h4>K8s em sistemas ML</h4>
            <img src="k8s_ml.jpg" class="img-fluid rounded" width="350px">
            <ol>
                <li>Interior K8s;</li>
                <li>K8s control plane;</li>
                <li>Interior de cada worker node;</li>
                <li>Escalabilidade (vários worker nodes);</li>
                <li>Implantação da aplicação no K8s, via YAML;</li>
                <li>Usuários com autonomia na arquitetura de suas aplicações, nos limites estabelecidos pelo administrador do cluster.</li>
            </ol>
        </div>
    </div>


<!--Rodapé-->
<div class="row">
    <div class="col-sm-12 text-center bg-black text-light pt-4 pb-3">
        <p>Elaborado por Mateus Schwede<br><small class="text-muted">ubsocial.github.io</small></p>
    </div>
</div>

</div>
</body>
</html>