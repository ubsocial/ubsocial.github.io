<!doctype html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="../../icons/logoTit.png">
    <link rel="stylesheet" href="../../estilo.css">
    <title>UB Social</title>
</head>
<body>
<div class="container-fluid">


    <div class="row">
        <div class="col-sm-12">
            <nav class="navbar rounded-bottom fixed-top navbar-expand-lg navbar-light bg-light shadow">
                <div class="container-fluid">
                    <a class="navbar-brand" href="../../index.html"><img src="../../icons/logo.png" class="d-inline-block align-text-top" width="11pt"> UB Social</a>
                    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
                    <div class="collapse navbar-collapse" id="navbarNav">
                        <ul class="navbar-nav">
                            <li class="nav-item"><a class="nav-link" href="../../index.html">Home</a></li>
                            <li class="nav-item"><a class="nav-link" href="../../sobre/sobre.html">Sobre</a></li>
                            <li class="nav-item"><a class="nav-link" href="../../cursos.html" id="navCursos">Cursos</a></li>
                            <li class="nav-item"><a class="nav-link" href="../../livros/livros.html">Livros</a></li>
                        </ul>
                    </div>
                </div>
            </nav>
        </div>
    </div>

    <div class="row">
        <div class="col-sm-12 text-center" id="titulo">
            <h1>Kafka</h1>
            <h6><strong>Apache Kafka, teoria e prática</strong></h6>
            <a href="../../index.html" class="btn btn-link text-decoration-none mb-3">Voltar</a>
        </div>

        <div class="col-sm-12">
            <p id="textoPost">Plataforma de streaming de eventos, que recebe (push), organiza (topics in brokers) e envia (pull) dados (messages). Ex: Sistema de folha de pagamentos possui BD compartilhado com vários setores da empresa. Tal sistema produz dados, demais setores os consomem. Tecnicamente, é software EDA (event driven architecture - arquitetura orientada a eventos), atuando com event streaming (captura, análise e resposta a events, em real-time, via TCP). Praticamente, Kafka auxiliará no processo de produção/consumo dos dados, evitando sobrecargas no BD, indisponibilidades e falhas, baixo desempenho, etc.</p>

            <br><h4>Estrutura:</h4>
            <p class="text-danger"><b>producer</b> -(push message)-&gt; <b>Cluster Kafka</b> (topic in broker) &lt;-(pull message)- <b>consumer</b></p>
            <ul>
                <li>Producer/publisher: Produtor das messages (dados), que a enviará para um topic (assunto - tabela de armazenamento), em um broker (servidor) no Kafka;</li>
                <li>Consumer/subscriber: Consumidor das messages, pode lê-las mais de uma vez.</li>
            </ul>
            <img src="kafka.jpg" class="img-fluid rounded my-4" width="530px">

            <br><h4>Event:</h4>
            <p id="textoPost">Mudança significativa dos dados (possui chave, valor e data). Exemplo: comando de 'update' em table. No Kafka, events são messages. Componentes básicos de um event:</p>
            <ul>
                <li>Event key: "fulana"</li>
                <li>Event value: "café no starbucks"</li>
                <li>Event timestamp: "Jun. 23, 2024 at 8:00 p.m."</li>
            </ul>

            <br><h4>Broker:</h4>
            <p id="textoPost">Servidor lógico do Kafka, faz intermédio producer-consumer. Cada node físico executa 1 ou mais brokers. Pode-se acessar, num mesmo broker, diferentes instâncias na mesma porta. Atribui numeração ordenada (offset) às messages. Broker chefe é escolhido aleatoriamente e denominado controller. Bootstrap é a porta lógica de entrada para conexão em topic (em broker qualquer), para producer e consumer.</p>

            <br><h4>Cluster Kafka:</h4>
            <p id="textoPost">Cada servidor físico é um broker. Cada broker pode ter 0 ou mais topics. Cada topic pode ter várias partitions (partições físicas), distribuídas em diferentes brokers. Cada topic pode ter somente 1 partition num mesmo broker. Podem haver brokers que não possuam partitions de determinados topics. Num mesmo broker, não pode haver mesmo topic duplicado. Num mesmo broker, pode haver mesma partition armazenando diferentes topics. Partitions são armazenadas, fisicamente, em node único do cluster, mas podendo estar, logicamente, replicada em diferentes brokers.</p>

            <br><h4>Controller:</h4>
            <p id="textoPost">Broker principal do cluster (se controller cair, outro broker assumirá). Cada broker possui topics em partitions. Partitions principais são denominadas <i>leaders</i>, e suas cópias são denominadas <i>followers</i>. Cada partition é replicada em 1 leader e 1 ou mais followers, distribuídas em diferentes brokers (quantidade de followers depende do fator de replicação). Cada broker possui 0 ou mais partitions leaders e 0 ou mais followers. Pode haver broker somente com leaders, somente com followers, ou com ambas. Um broker possui pelo menos 1 partition. Recomendável que followers estejam em brokers separados de suas leaders (mesma partition compartilhada, via replicação, em diferentes brokers) e, com isso, em diferentes servidores e racks (tolerância a falhas). Partition leader guarda requisições dos producers e consumers. Producer recebe lista (ISR) de leaders e decide para qual delas enviar (push) as messages. Producer enviará message para broker da partition leader escolhida, que a guardará enviará feedback (acknowledgement). Consumer consome (pull) messages da partition leader.</p>
            <p><u>Exemplo de replicação</u>: 3 brokers em diferentes racks, 1 topic em 4 partitions com 3 réplicas (1 leader e 2 followers), totalizando 12 partitions:</p>
            <ol>
                <li>Ordenar brokers (broker 0, broker 1, broker 2);</li>
                <li><span class="text-muted">(réplica 1)</span> Distribuir partitions leaderes entre os brokers;
                    <ol>
                        <li>broker 0 recebe partition leader 0;</li>
                        <li>broker 1 recebe partition leader 1;</li>
                        <li>broker 2 recebe partition leader 2;</li>
                        <li>broker 0 recebe partition leader 3;</li>
                    </ol>
                </li>
                <li><span class="text-muted">(réplica 2)</span> Distribuir 1ª partition follower entre os brokers;
                    <ol>
                        <li>broker 1 recebe partition follower 0;</li>
                        <li>broker 2 recebe partition follower 1;</li>
                        <li>broker 0 recebe partition follower 2;</li>
                        <li>broker 1 recebe partition follower 3;</li>
                    </ol>
                </li>
                <li><span class="text-muted">(réplica 3)</span> Distribuir 2ª partition follower entre os brokers;
                    <ol>
                        <li>broker 2 recebe partition follower 0;</li>
                        <li>broker 0 recebe partition follower 1;</li>
                        <li>broker 1 recebe partition follower 2;</li>
                        <li>broker 2 recebe partition follower 3.</li>
                    </ol>
                </li>
                Obs: Caso algum broker estivesse no mesmo rack de outro, o Kafka não repetiria as mesmas partitions entre esses.
            </ol>
            <p id="textoPost">Partitions followers não respondem requisições (mantém-se atualizadas via leader). Followers existem somente para backup. Objetivo da follower é ser leader, em caso de falhas (follower somente será leader se estiver atualizada). Conforme exemplo acima, se no broker 1 a partition leader 1 falhar, sua partition follower 1 (no broker 2) se tornará leader no broker 2. Então, broker 1 possuirá somente followers a partir desse momento, e broker 2 possuirá 2 leaders.</p>

            <br><h4>ISR (in-sync-replicas):</h4>
            <p id="textoPost">Lista, mantida pelo broker com a leader, de followers que estão em sincronia com suas leaderes. Quando partition leader falha, Kafka verifica quais followers a essa estão na lista, para tornar uma delas leader. A lista mantém-se atualizada via offsets solicitados pelas followers (se follower solicitou messages atualizadas nos últimos 10seg, tal follower se mantém na lista).<br>Se leader falhar, e todas suas followers estiverem fora da ISR? Pode-se configurar leader para não considerar messages confirmadas até que sejam copiadas em todas suas followers da ISR. Então, leader pode ter messages confirmadas e não confirmadas. Se leader falhar, perdem-se somente messages não confirmadas, que precisam ser reenviadas pelo producer, o qual fica aguardando feedback de recebimento (acknowledgement).<br>Minimum ISR list: Lista com nº mínimo de réplicas definidas. Se houver problema, broker não aceitará messages, pois não há followers suficientes. Leader torna-se read only, onde não poderá mais receber novas messages.</p>
            <p id="textoPost"><u>Arquivos segments</u>: Messages ficam em arquivos, em diretórios denominados 'logs'. Arquivos de partitions são divididos em arquivos menores, os segments. Tudo numa mesma partition, dados vão do 1º segmento, até o limite, então inicia novo arquivo. Por padrão, tamanho máximo de segmento é 1GB ou 7 dias (configurável). Offset não é nº único no topic (não reinicia em novo segment), mas sim na partition (partition será dividida em novo segment, mas offset continua sua sequência. Cada partition tem seu próprio offset, independente da quantidade de segments). Partition offset permite manter o state, também reiniciá-lo, além de identificar menssages de forma única.</p>
            <p id="textoPost"><u>Arquivos timeindex</u>: Arquivo nas messages em 'log', permite buscar messages em intervalo de tempo (ex: messages enviadas pelos producers entre minutos x e y).</p>

            <br><h4>ZooKeeper:</h4>
            <p id="textoPost">Realiza gestão física do cluster (máquina/node master gerencia demais nodes workers/slaves). Futuramente, ZooKeeper será substituído por 'real-time' KRaft no Kafka 4. Pode-se ter 1 ou mais ZooKeepers gerenciando um ou mais brokers (com ZooKeeper, será 1 broker leader, e 0 ou mais followers).</p>

            <br><h4>Topic:</h4>
            <p id="textoPost">Assunto, imutável, semelhante à tabela de BD, para armazenar messages. Ex: topics para gerenciar logs de websites. Cada producer (websites) enviam messages (error, warning, success) para respectivos topics, que serão consumidas pelos consumers da equipe de TI (dev, segurança, marketing). Cada message possui key (chave, similar ao header request). Além disso, cada message possui período de retenção (determinado por tamanho ou tempo) e pode reter apenas última message (log compacted). Messages são distribuídas nas partitions. As partitions não precisam ter mesma quantidade de topics, e partitions não podem ser divididas posteriormente, e só pode haver 1 consumer por partition. Offsets são commitados em mesmo topic, denominado '__consumer_offsets', onde o commit é o ponto de referência para o offset procurado para ser lido. Messages são identificadas por topic, seguido do nº da partition e, então, offset. Messages podem ser serializadas para transferência em rede, no formato Avro.</p>

            <br><h4>Escopo de message:</h4>
            <ul><u>Argumentos obrigatórios</u>:
                <li>Topic</li>
                <li>Mensagem</li>
            </ul>
            <ul><u>Opcionais</u>:
                <li>Partition
                    <ul>
                        <li>Conforme estratégia de particionamento</li>
                        <li>Default: hash key ou rodízio</li>
                    </ul>
                </li>
                <li>Timestamp (hora da criação ou hora do log)</li>
                <li>Message key: usado para particionamento, agrupamento, joins, etc</li>
            </ul>

            <br><h4>Producer:</h4>
            <p id="textoPost">A qualquer momento pode-se adicionar e remover producers e consumers, sem afetar a plataforma. A partition de envio da message pode ser definida no objeto ProducerRecord, da API do Kafka. A message pode ter uma key, como referência da partition onde ficará. Caso contrário, ocorre rodízio. A lógica de particionamento pode ser definida pelo usuário. Pode-se criar producers e consumers via console, API Kafka ou Kafka Connect. Tipos de producer:</p>
            <ul>
                <li>Single thread: Para poucas messages;</li>
                <li>Multi thread: Escala o producer. Multi thread save permite compartilhar mesmo thread e usar mesmo producer para enviar messages em paralelo (mais recomendável do que criar múltiplos producers).</li>
            </ul>

            <br><h4>Consumer:</h4>
            <p id="textoPost">Lê messages, ordenadamente, de uma partition de um broker. Um consumer pode ler messages de mais de uma partition. Não há garantia de ordem entre partitions num mesmo topic, apenas dentro de cada partition. O consumer group dividirá processamento para determinado topic. Consumer groups geralmente são criados quando alguns consumers não conseguem processar todas as messages. A quantidade de partitions em determinado topic é a quantidade limite de consumers em um consumer group, que processará tais messages (os demais consumers no group ficarão inativos). Dentro de mesmo group, cada consumer lê sua(s) partition(s) específica(s) (um consumer pode ler mais de uma partition, se essas não estão sendo lidas por outros consumers do mesmo group). Portanto, de forma geral, não pode-se ter mais consumers do que partitions. Para ter mais de 1 consumer lendo mesma partition, deve-se criar novo group.</p>

            <br><h4>Acknowledgment:</h4>
            <p id="textoPost">Producer pode, ou não, aguardar confirmação de recebimento da message, via parâmetros acks:</p>
            <ul>
                <li>0: Producer sempre considera message enviada com sucesso;</li>
                <li>1: Producer considera message enviada com sucesso, se confirmada pela partition leader;</li>
                <li>All: Producer considera message enviada com sucesso, se todas réplicas mínimas sincronizadas receberem a message.</li>
            </ul>

            <br><h4>Transactions:</h4>
            <p id="textoPost">Similar a BDs. Operação só ocorrerá somente após confirmação das todas etapas realizadas (tudo ou nada). Exemplo, executar operação somente após réplicas factor for maior que 3, e réplicas sincronizadas for maior que 2.</p>
            <ul>
                <li>Padrão: "pelo menos 1 vez", onde que, em caso de falha ou não confirmação, productor reenvia message. Se broker receber message mais de 1 vez, entregará a mesma todas as respectivas vezes;</li>
                <li>No máximo 1 vez: Productor não reenviará message em caso de falha ou não confirmação. Haverá no máximo 1 message e, em caso de falha, consumer não a receberá;</li>
                <li>Exatamente 1 vez: Se houver falha ou não confirmação, productor reenviará menssage. Se broker receber message mais de 1 vez, só persistirá e entregará 1 única vez.</li>
            </ul>

            <br><h4>Produção e consumo de messages:</h4>
            <p id="textoPost">Via console, API Kafka e Kafka Connect. Via console, segue exemplo prático, de comandos, no final do artigo. Via API, tem-se Producer API (permite que producer envie messages), Consumer API (permite que consumer consuma messages, via 1 ou mais topics), Streams API (permite que aplicação atue como processador de fluxo, consumindo messages e gerando resultados processados para outro topic), Connector API (permite criar producer e consumers reutilizáveis, que conectam os topics em sistemas existentes - ex: connector para BD relacional que captura todas alterações em uma table) e Admin API (gerencia e inspeciona topics, brokers e demais objetos do kafka). Kafka Connect: Conectores prontos (declarativo), que só precisam ser instalados e configurados. Pode ser usado com producer (Kafka Connect Source) ou consumer (Kafka Connect Sink). Escalado automaticamente e com balanceamento de carga. Tolerante a falhas. Suporta modo standalone e distributed. Connect em cluster: Connect worker (conexões individuais no cluster, para source e sink). Para escalar, adiciona-se mais workers. Pode-se ter source e sink no mesmo connect. Transformações SMTs (simple messages transform): InsertField, ReplaceField, MaskField, ValueToKey, HostField, ExtractField, SetSchemaMetadata, TimestampRouter, RegexRouter, Filter.</p>

            <br><h4>Utilização do Kafka:</h4>
            <ul>
                <li>Exemplo prático via console;</li>
                <li>Arquivos em 'kafka/bin': '.sh' são scripts Linux, arquivos '.bat' são scripts Windows;</li>
                <li>Arquivos em 'kafka/lib': bibliotecas Java para conexões via Kafka Connect.</li>
            </ul>
            <ol><u>Passo a passo de uso, via Linux</u>:
                <li>Baixar Kafka e extraí-lo</li>
                <li><span class="text-muted">(shell 1)</span> Executar ZooKeeper: <i>cd kafka/bin/ && ./zookeeper-server-start.sh ../config/zookeeper.properties</i></li>
                <li><span class="text-muted">(shell 2)</span> Executar Kafka: <i>cd kafka/bin && ./kafka-server-start.sh ../config/server.properties</i></li>
            </ol>
            <p>Exemplo prático para criar topics, escrever (simular producer) e consumir (simular consumer) messages nos topics (comandos em '/bin/kafka'):</p>
            <ul><u>Criar topic</u>:
                <li><span class="text-muted">(shell 3)</span> Executar script de criação de topics: <i>./kafka-topics.sh --create topic meuTopico --botstrap-server localhost:9092</i>
                    <ul>
                        <li>Bootstrap server é o endereço do broker: <i>maquina:porta</i></li>
                    </ul>
                </li>
            </ul>
            <ul><u>Enviar messages</u>:
                <li><span class="text-muted">(shell 3)</span> <i>./kafka-console-producer.sh --topic meuTopico --bootstrap-server localhost:9092</i>
                    <ul>
                        <li>&gt; informar mensagens no console</li>
                    </ul>
                </li>
            </ul>
            <ul><u>Ler messages:</u>
                <li><span class="text-muted">(shell 4)</span> <i>./kafka-console-consumer.sh --topic meuTopico --from-beginning --bootstrap-server localhost:9092</i>
                    <ul>
                        <li>'from beginning' lerá messages desde antes do shell 4 iniciado (se removê-lo, lerá somente messages após shell 4 iniciado)</li>
                        <li>Conforme producer escrever novas messages, consumer irá lendo-as</li>
                        <li>ctrl+c para encerrar shell</li>
                    </ul>
                </li>
            </ul>
            <p><u>Listar topics de um broker (via ZooKeeper)</u>: <i>./kafka-topics.sh --zookeeper localhost:2181 --list</i>
            <br><u>Ver informações de topic</u>: <i>./kafka-topics.sh --describe --topic meuTopico --bootstrap-server localhost:9092</i></p>
        </div>
    </div>


<!--Rodapé-->
<div class="row">
    <div class="col-sm-12 text-center bg-black text-light pt-4 pb-3">
        <p>Elaborado por Mateus Schwede<br><small class="text-muted">ubsocial.github.io</small></p>
    </div>
</div>

</div>
</body>
</html>