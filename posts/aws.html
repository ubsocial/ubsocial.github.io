<!doctype html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="../icons/logoTit.png">
    <link rel="stylesheet" href="../estilo.css">
    <title>UB Social</title>
</head>
<body>
<div class="container-fluid">


    <div class="row">
        <div class="col-sm-12">
            <nav class="navbar rounded-bottom fixed-top navbar-expand-lg navbar-light bg-light shadow">
                <div class="container-fluid">
                    <a class="navbar-brand" href="../index.html"><img src="../icons/logo.png" class="d-inline-block align-text-top" width="11pt"> UB Social</a>
                    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
                    <div class="collapse navbar-collapse" id="navbarNav">
                        <ul class="navbar-nav">
                            <li class="nav-item"><a class="nav-link" href="../index.html">Home</a></li>
                            <li class="nav-item"><a class="nav-link" href="../sobre/sobre.html">Sobre</a></li>
                            <li class="nav-item"><a class="nav-link" href="../cursos.html">Cursos</a></li>
                            <li class="nav-item"><a class="nav-link" href="../livros/livros.html">Livros</a></li>
                        </ul>
                    </div>
                </div>
            </nav>
        </div>
    </div>

    <div class="row">
        <div class="col-sm-12 text-center" id="titulo">
            <h1>AWS</h1>
            <h6>Console Amazon Web Services free tier</h6>
            <a href="../index.html" class="btn btn-link text-decoration-none mb-3">Voltar</a>
        </div>

        <div class="col-sm-12">
            <p class="text-warning text-center">RESUMO EM CONSTRUÇÃO</p>
            <h4>Material complementar:</h4>
            <ul>
                <li>Conteúdo no YouTube: <a href="https://youtube.com/playlist?list=PLnPZ9TE1Tj4CygvubCbQtSUFFAaTR0Ehm&si=M2_9DbAEJ44bRBon" target="_blank" class="text-decoration-none">Acesse</a></li>
                <li>Conteúdo no GitHub: <a href="https://github.com/mateusschwede/workover_aws" target="_blank" class="text-decoration-none">Acesse</a></li>
                <li>Curso gratuito e com certificado na Workover Academy (Curso AWS Free Tier): <a class="text-decoration-none">Acesse em breve</a></li>
            </ul>

            <br><h4>Instância EC2:</h4>
            <p id="textoPost">Amazon EC2 (Elastic Compute Cloud) fornece servidores virtuais na nuvem (instâncias) que podem ser usados para rodar aplicações, hospedar sites, bancos de dados, entre outros. Integra-se com outros serviços AWS, como S3 (armazenamento), RDS (banco de dados) e VPC (rede privada). Usado para hospedar site ou aplicação web, criar ambientes de desenvolvimento e testes, hospedar softwares pesados (IA ML, processamento de dados) e jogos, e backend de aplicações. Criar instância EC2 Ubuntu CLI (free tier), com aplicação nginx, habilitada para acesso externo:</p>
<small><pre><code>
--- CRIAR INSTÂNCIA AWS ---
EC2 / Instâncias / Executar instâncias
- Nome: ubuntuNginxTeste1
- AMI: Ubuntu Server (nível gratuito)
- Tipo: t3.micro (verificar se região é t2 ou t3 nível gratuito)
- Criar par de chaves:
-- Nome: keyNginxTeste1
-- Tipo: RSA
-- Formato: conforme SO de sua máquina
- Rede:
-- Atribuir IP público automaticamente: habilitar
-- Grupo de segurança criado automaticamente, com regras:
--- Permitir tráfego HTTP qualquer lugar
--- Permitir tráfego HTTPS qualquer lugar
--- Permitir tráfego SSH qualquer lugar
OBS: Após instância criada, pode-se editar regras de entrada do grupo de segurança, para permitir acesso apenas de IPs e portas específicas (EC2 / Grupos de segurança / Selecionar grupo / Editar regras de entrada)
- Armazenamento: 8GB (nível gratuito)
Executar instância

--- CONECTAR INSTÂNCIA AWS ---
EC2 / Instâncias / Selecionar instância / Ações / Conectar
- Connection type: IP público
- Endereço IPv4 público: selecionar (guardar IPv4 para acesso futuro)
Conectar

--- OPERAR INSTÂNCIA AWS ---
Na instância EC2 Ubuntu CLI, executar comandos:
- sudo apt update && sudo apt install nginx -y && sudo systemctl enable nginx --now && sudo su
- echo '&lt;h1&gt;Servidor EC2 UB Social&lt;/h1&gt;' &gt; /var/www/html/index.html

--- ACESSAR INSTÂNCIA AWS ---
- Acessar no browser: http://IPv4-PUBLICO-INSTANCIA
- Via Linux: ssh -i "sua-chave.pem" ubuntu@DNS-PUBLICO-INSTANCIA
</code></pre></small>

            <br><h4>Buckets S3:</h4>
            <p id="textoPost">Serviço de armazenamento de dados na AWS, permitindo armazenar qualquer tipo de dado (arquivos, imagens, vídeos, logs, backups, datasets, etc.) em unidades chamadas buckets. Cada bucket é "balde" de armazenamento lógico que pode conter objetos (arquivos), e cada objeto é identificado por key única. Integra-se com EC2 para armazenar backups, logs e arquivos de servidor. Usado também para armazenar BD via Athena. Possibilidade de backups automáticos ao S3. Geralmente usado para armazenar backups, dados, datasets, BDs e sites estáticos. Objetivo é criar S3 para armazenar site UB Social:</p>
<small><pre><code>
--- CRIAR BUCKET S3 ---
S3 / Buckets / Criar bucket
- Nome: bucket-ubsocial-teste1
- Propriedade de objeto: Marcar ACLs desabilitadas (recomendado)
- Configurações de bloqueio do acesso público deste bucket: desabilitar tudo
Criar bucket

--- UPLOAD ARQUIVOS NO BUCKET S3 ---
- Baixar arquivos do site estático: <a href="https://github.com/mateusschwede/workover_aws/archive/refs/heads/main.zip" target="_blank" class="text-decoration-none">https://github.com/mateusschwede/workover_aws/archive/refs/heads/main.zip</a>
- Descompactar arquivos baixados (site está em 2_buckets_s3, pasta ubsocial.github.io)

- S3 / Buckets / Selecionar bucket / Aba Objetos / Carregar
- Adicionar pastas: selecionar pasta ubsocial.github.io
Carregar

--- PUBLICAR SITE ESTÁTICO NO S3 ---
S3 / Buckets / Selecionar bucket / Aba Propriedades / Hospedagem de site estático / Editar / Ativar
- Documento de índice: index.html (se não estiver em uma pasta)
S3 / Buckets / Selecionar bucket / Aba Permissões / Editar política de bucket, informando conteúdo:
&#123;
    "Version": "2012-10-17",
    "Statement": [
        &#123;
            "Sid": "PublicReadGetObject",
            "Effect": "Allow",
            "Principal": "*",
            "Action": "s3:GetObject",
            "Resource": "arn:aws:s3:::bucket-ubsocial-teste1/*"
        &#125;
    ]
&#125;
- Salvar

--- ACESSAR SITE ESTÁTICO NO S3 ---
S3 / Buckets / Selecionar bucket / Aba Propriedades / Hospedagem de site estático
- Copiar URL do endpoint
- Acessar no browser: urlEndpoint/ubsocial.github.io/index.html
</code></pre></small>

            <br><h4>Banco de dados RDS:</h4>
            <p id="textoPost">Amazon RDS (Relational Database Service) é serviço de banco de dados relacional, permitindo gestão e escalabilidade de BD. Geralmente integrado com instâncias EC2 via VPC, funções serverless Lambda, coleção de logs via CloudWatch, backup e armazenamento em bucket S3, entre outros. Utilizado no cotidiano em conjunto com aplicações REST instaladas em instâncias EC2, backups em bucket S3, com disponibilidade para big data. Objetivo é criar BD MySQL em RDS e acessá-lo via máquina externa:</p>
<small><pre><code>
--- CRIAR BANCO DE DADOS RDS ---
Aurora and RDS / Bancos de dados / Criar banco de dados
- Método de criação: Padrão
- Opções de mecanismo: MySQL
- Modelos: Nível gratuito
- Configurações:
-- Identificador do banco de dados: ubsocial-mysql-teste1
-- Nome do usuário principal: admin
-- Senha: UBsocial123
- Configuração da instância:
-- Tipo de instância: (ver opções disponíveis no nível gratuito)
- Armazenamento:
-- Tipo de armazenamento: SSD de uso geral (gp2)
-- Armazenamento alocado: 20GB
-- Escalabilidade automática do armazenamento: desabilitar (para evitar custos extras)
- Conectividade:
-- Recurso de computação: Não se conectar a um recurso de computação do EC2
-- VPC: padrão
-- Grupo de sub-redes de banco de dados: padrão
-- Acesso público: Sim
-- Grupo de segurança de VPC (firewall): criar novo grupo de segurança
--- Nome: grupoSegurancaRDS1
-- Porta do banco de dados: 3306 (padrão MySQL)
- Configuração adicional:
-- Nome do banco de dados inicial: ubsocialdb1
Criar banco de dados

--- HABILITAR PORTA DE ACESSO RDS ---
EC2 / Grupos de segurança / Selecionar grupoSegurancaRDS1 / Editar regras de entrada (adicionar nova regra)
- Tipo: MySQL/Aurora
- Protocolo: TCP (padrão)
- Porta: 3306 (padrão MySQL)
- Origem: Qualquer local-IPv4 (0.0.0.0/0)
Salvar regras

--- ACESSAR BANCO DE DADOS RDS ---
RDS / Bancos de dados / Selecionar banco de dados / Aba Segurança e conexão / Copiar endpoint do RDS
No editor SQL, criar conexão:
- Host: Endpoint do RDS (sem "https://")
- Porta: 3306
- User: admin
- Senha: UBsocial123
- (opcional) Database: ubsocialdb1
Testar conexão e Conectar

Editor SQL, executar comandos:
CREATE TABLE tableTeste (
    id INT AUTO_INCREMENT PRIMARY KEY,
    nome VARCHAR(100) NOT NULL,
    email VARCHAR(100) NOT NULL UNIQUE
);
INSERT INTO tableTeste (nome, email) VALUES ('UB Social','ubsocial@example.com'),('UB Social 2','ubsocial2@example.com');
SELECT * FROM tableTeste;

RDS / Bancos de dados / Selecionar banco de dados / Aba Logs e eventos / Selecionar log de auditoria / Visualizar
</code></pre></small>

            <br><h4>DynamoDB:</h4>
            <p id="textoPost">Amazon DynamoDB é serviço de BD NoSQL, escalável de alta performance. Usa tables de itens (identificados por key única) com atributos - via JSON. Integra-se com Lambda para criar aplicações serverless, API Gateway para expor APIs RESTful, CloudWatch para monitoramento e S3 para armazenamento de dados em buckets. Usado em aplicações web e mobile, jogos, IoT e big data. Objetivo é criar e testar BD NoSQL DynamoDB, via AWS Console e CloudShell:</p>
<small><pre><code>
--- CRIAR TABLE DYNAMODB ---
DynamoDB / Tabelas / Criar tabela
- Nome da tabela: usuarios-teste1
- Chave primária: user_id (String)
- Configurações da tabela: padrão
Criar tabela

--- INSERIR DADOS NA TABLE ---
DynamoDB / Tabelas / Selecionar usuarios-teste1 / Explorar itens da tabela / Criar item
- user_id: 1
Adicionar novo atributo (String)
- nome: 'UB Social'
Adicionar novo atributo (String)
- email: 'ubsocial@example.com'
Criar item

DynamoDB / Tabelas / Selecionar usuarios-teste1 / Explorar itens da tabela / Criar item
- user_id: 2
- nome: 'UB Social 2'
- email: 'ubsocial2@example.com'
Criar item

--- CONSULTAR DADOS NA TABLE ---
DynamoDB / Tabelas / Selecionar usuarios-teste1 / Explorar itens da tabela / Verificar ou consultar itens
- Tipo: Consulta
- Selecionar projeção de atributos: Atributos específicos
- Atributos específicos do projeto: nome
- Chave de partição (user_id): 1
Executar

--- CONSULTAR DADOS NA TABLE - CloudShell ---
Canto superior direito do console AWS / CloudShell, e executar comandos:
- aws dynamodb scan --table-name usuarios-teste1
- aws dynamodb put-item --table-name usuarios-teste1 --item '&#123;"user_id":&#123;"S":"u003"&#125;,"nome":&#123;"S":"UB Social 3"&#125;,"email":&#123;"S":"ubsocial3@example.com"&#125;&#125;'
- aws dynamodb get-item --table-name usuarios-teste1 --key '&#123;"user_id": &#123;"S": "u003"&#125;&#125;'
- aws dynamodb scan --table-name usuarios-teste1 --filter-expression "#n = :nomeVal AND email = :emailVal" --expression-attribute-names '&#123;"#n":"nome "&#125;' --expression-attribute-values '&#123;":nomeVal":&#123;"S":"UB Social 2"&#125;,":emailVal":&#123;"S":"ubsocial2@example.com"&#125;&#125;'
</code></pre></small>

            <br><h4>ECS Fargate:</h4>
            <p id="textoPost">Amazon ECS (Elastic Container Service) é serviço para gerenciar e executar containers Docker, de forma orquestrada e automática, dispensando instalação manual de cluster Kubernetes ou servidores. AWS Fargate é motor de execução (compute engine) do ECS, permitindo executar containers, sem precisar gerenciar servidores EC2. ECS integra-se com ECR (Elastic Container Registry) para criação de registry de Images, VPC para rede de containers, S3/DynamoDB/RDS para armazenamento de dados (Volumes), Elastic Load Balancer (ALB/NLB) para distribuição de tráfego entre containers, CloudWatch para gestão de logs, etc. Usado em microservices web, APIs REST ou GraphQL, Sites estáticos com backend leve (ex: Nginx), onde containers executam tecnologias base para armazenamento e funcionamento de tais aplicações. Fargate usado em tarefas de processamento de dados, para execução de containers on demand. Usado também em ambientes de teste ou CI/CD, na criação de containers temporários em Pipelines. Objetivo é criar ECS de container Nginx, através de cluster Fargate, contendo definição de tarefa para execução do container, e acesso via IP público:</p>
<small><pre><code>
--- CRIAR CLUSTER FARGATE ---
ECS / Clusters / Criar cluster
- Nome: ecs-fargate-nginx-demo
- Infraestrutura: Somente Fargate
Criar

--- CRIAR DEFINIÇÃO DE TAREFA ---
ECS / Definições de tarefa / Criar nova definição de tarefa
- Nome: nginx-fargate-demo
- Tipo de inicialização: AWS Fargate
- CPU: .25vCPU
- Memória: .5GB
- Função da tarefa: Nenhum
- Função de execução de tarefas: ecsTaskExecutionRole
- Container 1:
-- Nome: nginx
-- URI da imagem: nginx:alpine
- Mapeamentos de porta:
-- Porta do container: 80
-- Protocolo: TCP
- Coleção de logs: desabilitar
Criar

--- CRIAR GRUPO DE SEGURANÇA ---
EC2 / Grupos de segurança / Criar grupo de segurança
- Nome: grupoSeg-ecs-fargate-http
- Descrição: Permitir acesso HTTP externo ao Nginx ECS
- VPC: padrão
- Regras de entrada (adicionar nova regra):
-- Tipo: HTTP
-- Protocolo: TCP (padrão)
-- Intervalo de portas: 80 (padrão)
-- Origem: Qualquer local-IPv4 (0.0.0.0/0)
Criar

--- EXECUTAR TAREFA ---
ECS / Clusters / Selecionar ecs-fargate-nginx-demo / Aba Tarefas / Executar nova tarefa
- Família da definição de tarefa: nginx-fargate-demo
- Opções de computação: Selecionar Tipo de inicialização
- Tipo de inicialização: Fargate
- Rede:
-- VPC: padrão
-- Sub-redes: padrão
-- Nome do grupo de segurança: grupoSeg-ecs-fargate-http
-- IP público: Habilitar
Criar

--- ACESSAR CONTAINER ECS FARGATE ---
ECS / Clusters / Selecionar ecs-fargate-nginx-demo / Aba Tarefas / Selecionar tarefa em execução / Aba Associações de rede / Copiar IP público
- Acessar no browser: http://IP-PUBLICO-TAREFA (abrirá página padrão do Nginx)
- Via Linux: curl http://IP-PUBLICO-TAREFA

--- Exclusões ---
1.ECS / Clusters / Selecionar ecs-fargate-nginx-demo / Aba Tarefas / Selecionar tarefa em execução / Ações / Parar
2.ECS / Clusters / Selecionar ecs-fargate-nginx-demo / Excluir cluster
3.ECS / Definições de tarefa / Selecionar definição / nginx-fargate-demo / Ações / Cancelar registro, depois Excluir
4.EC2 / Grupos de segurança / Selecionar grupoSeg-ecs-fargate-http / Excluir
</code></pre></small>

            <br><h4>Serverless Lambda e API Gateway:</h4>
            <p id="textoPost">Serviços serverless não necessitam de servidores como base de funcionamento, sendo própria AWS responsável por manter e escalar aplicação. Lambda é motor que executa códigos serverless on demand, em resposta a eventos (triggers). API Gateway expõe funções Lambda e outros backends à internet, criando endpoints acessáveis externamente como porta de entrada a essas APIs HTTP REST ou WebSocket. Lambda e API Gateway integram-se com serviços S3 para armazenamento permanente de dados, via RDS, DynamoDB e logs no CloudWatch, e integrações com SNS para notificações e SQS para fila de mensagens. Lambda e API Gateway utilizados em APIs REST, juntamente com DynamoDB. Também em processamento de arquivos, tarefas agendadas de backups diários (EventBridge), e IA ML de processamento leve, dispensando necessidade de servidor. Objetivo é criar serviço serverless, via Lambda, que retorna mensagem quando acessado externamente, disponibilizado via API Gateway.</p>
<small><pre><code>
--- CRIAR FUNÇÃO LAMBDA ---
Lambda / Criar função
- Criar função do zero
- Nome da função: hello-serverless
- Tempo de execução: Python
- Permissões / Alterar a função de execução padrão: Selecionar 'Criar uma função com permissões básicas do Lambda'
Criar função

--- ADICIONAR CÓDIGO NA FUNÇÃO LAMBDA ---
Lambda / Selecionar função hello-serverless / Aba Código / Editar código:
def lambda_handler(event, context):
    return &#123;
        "statusCode": 200,
        "headers": {"Content-Type": "text/plain; charset=utf-8"},
        "body": "Olá, mundo serverless!"
    &#125;
- No VSCode da AWS, clicar em Deploy

--- TESTAR FUNÇÃO LAMBDA ---
Lambda / Selecionar função hello-serverless / Aba Testar / Evento de teste
- Ação de evento de teste: Criar novo evento
- Nome do evento: eventoTeste1
Salvar e Testar
- Verificar resultado: Status 200, Body "Olá, mundo UB Social Serverless!"

--- CRIAR API GATEWAY ---
API Gateway / APIs / Criar API
- Tipo de API: API HTTP / Compilar
- Nome da API: api-hello-serverless
- Tipo de endereço IP: IPv4
- Integrações / Acicionar integração
-- Tipo: Lambda
-- Escolher função Lambda: localizacaoAWS:hello-serverless
Avançar
- Configurar rotas:
-- Método: GET
-- Rota: /
-- Destino: hello-serverless
Avançar
- Estágio de implantação: padrão (geralmente com implantação automática habilitada)
Avançar / Criar / Implantar

--- TESTAR API GATEWAY ---
API Gateway / APIs / Selecionar api-hello-serverless / Aba Visão geral
- Copiar URL do endpoint padrão
- Acessar no browser: urlEndpoint
- Via Linux: curl urlEndpoint
- Verificar resultado: "Olá, mundo UB Social Serverless!"

--- Exclusões ---
1.API Gateway / APIs / Selecionar api-hello-serverless / Ações / Excluir
2.Lambda / Selecionar função hello-serverless / Ações / Excluir
3.CloudWatch / Logs / Selecionar grupo de logs / Ações / Excluir grupo de logs
</code></pre></small>

            <br><h4>CloudWatch:</h4>
            <p id="textoPost">Amazon CloudWatch é serviço de monitoramento e observabilidade da AWS, coletando, armazenando e exibindo métricas, logs e eventos dos serviços AWS. Integra-se com praticamente todos serviços AWS, como métricas alarme em instâncias EC2, medindo processamento, armazenamento e memória. Coleta logs e métricas de execução de funções Lambda e APIs Gateway, medindo tempo de resposta, erros e latência. Coleta métricas de desempenho em bases de dados RDS, DynamoDB, em ECS Fargate, e métricas de armazenamento de buckets S3. Usado em praticamente todo ambiente AWS profissional, monitorando servidores EC2, APIs serverless Lambda, dashboards e logs centralizados para times de operações, métricas para gerar escalonamento automático (auto scaling), e alertas de segurança e compliance quando função IAM for modificada, via CloudWatch e CloudTrail. Objetivo é criar alarme no CloudWatch que monitora logs personalizados de função AWS Lambda, disparando quando função for executada:</p>
<small><pre><code>
--- CRIAR FUNÇÃO LAMBDA ---
Lambda / Criar função
- Criar função do zero
- Nome: logLambdaCloudWatch
- Tempo de execução: Python
- Permissões / Alterar a função de execução padrão: Selecionar 'Criar uma função com permissões básicas do Lambda'
Criar função

--- ADICIONAR CÓDIGO NA FUNÇÃO LAMBDA ---
Lambda / Selecionar função logLambdaCloudWatch / Aba Código / Editar código:
import json
import logging

logger = logging.getLogger()
logger.setLevel(logging.INFO)

def lambda_handler(event, context):
    logger.info("Função Lambda executada com sucesso!")
    return &#123;
        'statusCode': 200,
        'body': json.dumps('Log enviado ao CloudWatch!')
    &#125;
- No VSCode da AWS, clicar em Deploy

--- TESTAR FUNÇÃO LAMBDA ---
Lambda / Selecionar função logLambdaCloudWatch / Aba Testar / Evento de teste
- Ação de evento de teste: Criar novo evento
- Nome do evento: eventoTesteLog1
Salvar e Testar

--- VERIFICAR LOGS NO CLOUDWATCH ---
CloudWatch / Logs / Selecionar grupo de logs / Selecionar grupo / Aba Streams de log / Selecionar fluxo / Verificar logs

--- CRIAR ALARME NO CLOUDWATCH ---
CloudWatch / Alarmes / Criar alarme
- Selecionar métrica / Lambda by Function name / Selecionar logLambdaCloudWatch invocations / Selecionar e continuar
- Período: 1 minuto
- Condição: Maior que ou igual a 1
Avançar
- Nome do alarme: AlertaExecucaoLambda
Avançar / Criar alarme

--- TESTAR ALARME NO CLOUDWATCH ---
Lambda / Selecionar função logLambdaCloudWatch / Aba Testar / Evento de teste
- Ação de evento de teste: Selecionar eventoTesteLog1
Testar
- CloudWatch / Alarmes / Selecionar AlertaExecucaoLambda / Verificar estado do alarme (Ok -&gt; Em alarme)

--- Exclusões ---
1.CloudWatch / Alarmes / Selecionar AlertaExecucaoLambda / Ações / Excluir
2.CloudWatch / Logs / Selecionar grupo de logs / Ações / Excluir grupo de logs
3.Lambda / Selecionar função logLambdaCloudWatch / Ações / Excluir
</code></pre></small>

            <br><h4>SNS e SQS:</h4>
            <p id="textoPost">SNS (Simple Notification Service) é serviço de publicação/assinatura (pub/sub), enviando notificações automaticamente para destinos (emails, SMS, filas, funções Lambda) a partir de gatilho. Integra-se com CloudWatch no disparo de alertas automáticos, a partir de gatilhos em execuções de funções Lambda, alteração em arquivos nos buckets S3 e filas SQS de mensagens. SQS (Simple Queue Service) é serviço de filas de mensagens, armazenando mensagens temporariamente até que outro sistema as processe. Integra-se na publicação de mensagens SNS, leitura automatica de fila via funções Lambda, processamento de mensagens em EC2/ECS, e gatilhos de envio de eventos na manipulação de arquivos em buckets S3. Utilizados em ambiente de produção, em que CloudWatch detecta alto consumo CPU, envia evento SNS, que repassa notificação via email e cópia à SQS. Lambda processa fila SQS e executa ações automáticas (ex: escalar instâncias). Também utilizados em sistemas API Gateway de publicação de pedido SNS, que direciona-se em fila SQS, separando mensagens entre setores (ex: faturamento, estoque), e cada microserviço processa sua fila no próprio tempo. Objetivo é publicar mensagem em tópico SNS, entregando-a em fila SQS que, por sua vez, aciona função Lambda de processamento da mensagem, e registrará em log CloudWatch:</p>
<small><pre><code>
--- CRIAR TÓPICO SNS ---
SNS / Tópicos / Criar tópico
- Nome: meu-topico-sns1
- Tipo: Padrão
Criar tópico (anotar ARN gerado)

--- CRIAR FILA SQS ---
SQS / Filas / Criar fila
- Tipo: Padrão
- Nome: minha-fila-sqs1
Criar fila (anotar ARN gerado)

--- CONECTAR SNS COM SQS ---
SNS / Tópicos / Selecionar meu-topico-sns1 / Aba Assinaturas / Criar assinatura
- Protocolo: Amazon SQS
- Endpoint: ARN da fila SQS
Criar assinatura

--- CRIAR FUNÇÃO LAMBDA ---
Lambda / Criar função
- Criar função do zero
- Nome: lambda-processa-sqs1
- Tempo de execução: Python
- Permissões / Alterar a função de execução padrão: Selecionar 'Criar uma função com permissões básicas do Lambda'
Criar função

--- ADICIONAR CÓDIGO NA FUNÇÃO LAMBDA ---
Lambda / Selecionar função lambda-processa-sqs1 / Aba Código / Editar código:
import json

def process_text_message(text):
    text = text.strip()
    if not text:
        print("Mensagem vazia ou somente espaços - ignorando")
        return
    print("Mensagem final:", text)

def lambda_handler(event, context):
    for record in event.get('Records', []):
        body = record.get('body', '')
        try:
            parsed = json.loads(body)
        except Exception:
            parsed = None

        if isinstance(parsed, dict) and 'Message' in parsed:
            msg = parsed.get('Message', '')
            try:
                inner = json.loads(msg)
                print("Mensagem original (JSON):")
                print(json.dumps(inner, ensure_ascii=False))
            except Exception:
                process_text_message(msg)

        elif isinstance(parsed, dict):
            print("Mensagem recebida (body JSON):")
            print(json.dumps(parsed, ensure_ascii=False))
        
        else:
            process_text_message(body)

    return &#123;"statusCode": 200, "body": json.dumps("OK")&#125;

- No VSCode da AWS, clicar em Deploy

--- IAM PERMITIR LAMBDA ACESSAR FILA SQS ---
Lambda / Selecionar função lambda-processa-sqs1 / Aba Configurações / Permissões / Função de execução / Clicar no nome da função (irá para tela IAM)
- Políticas de permissões / Adicionar permissões / Criar política em linha / Aba JSON:
&#123;
  "Version": "2012-10-17",
  "Statement": [
    &#123;
      "Sid": "AllowLambdaToAccessSQS",
      "Effect": "Allow",
      "Action": [
        "sqs:ReceiveMessage",
        "sqs:DeleteMessage",
        "sqs:GetQueueAttributes",
        "sqs:ChangeMessageVisibility"
      ],
      "Resource": "ARN-SUA-FILA-SQS-AQUI"
    &#125;
  ]
&#125;

Avançar
- Nome da política: LambdaSQSAccessPolicy1
Criar política

--- CONECTAR FILA SQS À LAMBDA ---
Lambda / Selecionar função lambda-processa-sqs1 / Aba Configurações / Gatilhos / Adicionar gatilho
- Configuração do gatilho: Selecionar SQS
- Fila: minha-fila-sqs1
Adicionar
- Habilitar gatilho: Aba Gatilhos / Clicar no gatilho SQS / Aba Triggers do Lambda (verificar se trigger está habilitado)

--- PUBLICAR MENSAGEM NO TÓPICO SNS ---
SNS / Tópicos / Selecionar meu-topico-sns1 / Publicar mensagem
- Assunto: Novo pedido 1
- Corpo da mensagem: Pedido de compra UB Social
Publicar mensagem

--- VER LOG NO CLOUDWATCH ---
CloudWatch / Logs / Selecionar grupo de logs / Aba Streams de log / Selecionar fluxo / Verificar logs (deve conter mensagem "Mensagem recebida: Pedido de compra UB Social")

--- Exclusões ---
1.Lambda / Selecionar função lambda-processa-sqs1 / Ações / Excluir
2.SQS / Filas / Selecionar minha-fila-sqs1 / Ações / Excluir fila
3.SNS / Tópicos / Selecionar meu-topico-sns1 / Ações / Excluir tópico
4.CloudWatch / Logs / Selecionar grupo de logs / Ações / Excluir grupo de logs
5.IAM / Funções / Selecionar função criada para Lambda / Ações / Excluir função
6.IAM / Políticas / Selecionar política LambdaSQSAccessPolicy1 / Ações / Excluir política
</code></pre></small>

            <br><h4>CloudFormation:</h4>
            <p id="textoPost">Serviço IaC (infrastructure as code) que permite criar, configurar e versionar infraestrutura AWS via templates YAML/JSON. Integra-se com CodePipeline, na criação de etapas de deploy, e com recursos computacionais de serviços como IAM, EC2, S3, Lambda, RDS, entre outros. Utilizado na prática para gerar arquitetura de tecnologia (VPC, EC2, banco de dados, Lambda), a partir de único template, sendo reprodutível, auditável e padronizada. Objetivo é criar template CloudFormation que cria bucket S3, gerando e destruindo toda sua infraestrutura, de forma automatizada:</p>
<small><pre><code>
--- CRIAR TEMPLATE CLOUDFORMATION ---
- Criar arquivo s3-bucket-simple.yaml:
AWSTemplateFormatVersion: "2010-09-09"
Description: Template CloudFormation simples que cria um bucket S3
Resources:
    MeuBucketS3:
        Type: AWS::S3::Bucket
        Properties:
            BucketName: !Sub "${AWS::AccountId}-meu-bucket-exemplo"
            VersioningConfiguration:
                Status: Suspended
Outputs:
    BucketName:
        Description: "Nome do bucket criado"
        Value: !Ref MeuBucketS3

--- CRIAR PILHA CLOUDFORMATION ---
AWS / CloudFormation / Pilhas / Criar pilha / Com novos recursos (padrão)
- Preparar modelo: Escolher um modelo existente
- Especificar modelo: Fazer upload de um arquivo de modelo
Avançar
- Nome da pilha: exemplo-s3-iac
Avançar / Enviar
- Verificar criação da pilha (Status CREATE_IN_PROGRESS - aguardar até CREATE_COMPLETE)

--- VERIFICAR BUCKET S3 CRIADO ---
S3 / Buckets / Verificar bucket criado com nome ID-CONTA-meu-bucket-exemplo

--- Exclusões ---
1.CloudFormation / Pilhas / Selecionar exemplo-s3-iac / Ações / Excluir
2.Verificar exclusão do bucket S3 (deve ser excluído automaticamente junto com pilha)
</code></pre></small>

            <br><h4>CodePipeline:</h4>
            <p id="textoPost">Serviço DevOps na AWS, orquestrando fluxo completo de integração e entrega contínua (CI/CD), como obtenção de código, compilação e testes, e deploy. Integra-se com repositórios (origem do código), CodeBuild (build e teste), e CloudFormation / Elastic Beanstalk / S3 / ECS / Lambda para destino de deploy. Utilizado na prática para Pipelines de deploy de aplicações, gerados a partir de gatilhos, como push no repositório, gerando artefato e fazendo deploy automático na AWS. Objetivo é criar Pipeline de deploy automatizado de site HTML, executado a partir de push ao repositório GitHub, onde CodePipeline detecta mudança no repositório, baixa artefato e copia arquivos para bucket S3, atualizando o site automaticamente na AWS (necessário conta no GitHub):</p>
<small><pre><code>
--- CRIAR REPOSITÓRIO GITHUB ---
GitHub / New repository
- Nome: meu-site-demo1
- Visibilidade: Público
Criar repositório
- Acessar repositório / Adicionar arquivo / Create new file
- Nome do arquivo: index.html, conteúdo:
&lt;h1&gt;Meu Site Demo 1&lt;/h1&gt;
Commit changes

--- CRIAR BUCKET S3 ---
S3 / Buckets / Criar bucket
- Nome: meu-site-demo1-ubsocial
- Bloquear todo o acesso público: desabilitar
Criar bucket
S3 / Buckets / Selecionar bucket / Aba Propriedades / Hospedagem de site estático / Editar / Ativar
- Documento de índice: index.html
Salvar alterações (aba Propriedades / Hospedagem de site estático / Copiar URL do endpoint)
S3 / Buckets / Selecionar bucket / Aba Permissões / Editar política de bucket, informando conteúdo:
&#123;
    "Version": "2012-10-17",
    "Statement": [
        &#123;
            "Effect": "Allow",
            "Principal": "*",
            "Action": [
                "s3:GetObject"
            ],
            "Resource": [
                "arn:aws:s3:::meu-site-demo1-ubsocial/*"
            ]
        &#125;
    ]
&#125;

- Salvar alterações

--- CRIAR PIPELINE CODEPIPELINE ---
AWS / CodePipeline / Pipelines / Criar pipeline
- Category: Criar pipeline personalizado
Avançar
- Nome: meu-site-demo1-pipeline
- Função de serviço: Nova função de serviço
- Nome da função: CodePipelineServiceRole1
Avançar
- Origem (provedor): GitHub (por meio do aplicativo OAuth)
- Conectar ao GitHub / Autorizar AWS CodePipeline
- Repositório: selecionar meu-site-demo1
- Ramificação: main
Avançar
- Compilação: ignorar etapa de compilação
- Teste: ignorar etapa de teste
- Implantação (Provedor): Amazon S3
- Bucket: meu-site-demo1-ubsocial
- Chave do objeto: site1.zip
- Extraia o arquivo antes de implantar: habilitar
Avançar / Criar pipeline

--- CONFERIR CRIAÇÃO DO PIPELINE ---
CodePipeline / Pipelines / Selecionar meu-site-demo1-pipeline / Verificar execução do pipeline (Status: Succeeded)
S3 / Buckets / Selecionar meu-site-demo1-ubsocial / Verificar arquivo site1.zip criado
- Acessar no browser: URL endpoint do bucket S3 (urlBucket/site.zip/index.html)

--- ALTERAR ARQUIVO NO REPOSITÓRIO GITHUB ---
GitHub / Repositório meu-site-demo1 / Selecionar arquivo index.html / Editar
- Alterar conteúdo do arquivo:
&lt;h1&gt;Meu Site Demo 1 - Atualizado&lt;/h1&gt;
Commit changes

--- CONFERIR EXECUÇÃO DO PIPELINE APÓS ALTERAÇÃO ---
CodePipeline / Pipelines / Selecionar meu-site-demo1-pipeline / Verificar nova execução automática do pipeline (Status: Succeeded)
S3 / Buckets / Selecionar meu-site-demo1-ubsocial / Verificar arquivo site1.zip atualizado
- Atualizar no browser: URL endpoint do bucket S3 (urlBucket/site.zip/index.html)

--- Exclusões ---
1.CodePipeline / Pipelines / Selecionar meu-site-demo1-pipeline / Ações / Excluir pipeline
2.S3 / Buckets / Selecionar meu-site-demo1-ubsocial / Ações / Excluir bucket
3.IAM / Funções / Selecionar CodePipelineServiceRole1 / Ações / Excluir função
4.IAM / Políticas / Selecionar AWSCodePipelineServiceRole-sa-east-1-meu-site-demo1-pipeline / Ações / Excluir política
5.(Opcional) GitHub / Repositório meu-site-demo1 / Settings / Delete this repository
</code></pre></small>

            <hr><br><h4>Publicar container na AWS:</h4>
            <p id="textoPost">Publicar container nginx na AWS via Amazon Elastic Container Service (ECS) e Amazon Elastic Container Registry (ECR), com cluster Fargate.</p>
<small><pre><code>
--- CONTAINER NO HOST DOCKER ---
1.Criar Dockerfile:
FROM nginx:latest
RUN rm -rf /usr/share/nginx/html/*
RUN echo '&lt;h1&gt;UB Social&lt;/h1&gt;&lt;p&gt;Container com servidor nginx na AWS&lt;/p&gt;' &gt; /usr/share/nginx/html/index.html
2.Criar Image e construir container:
- docker build -t ubsocial/meu-nginx .
- docker run -dti -p 8080:80 ubsocial/meu-nginx2
3.Acessar nginx via host docker: curl http://localhost:8080

--- CRIAR USUÁRIO AWS ---
1.IAM / Usuários / Criar usuário
- Nome: usuarioUB1
- Fornecer acesso console AWS: habilitar
- Tipo: Quero criar usuário do IAM
- Senha do console: Senha gerada automaticamente
Próximo
- Permissões: Anexar políticas diretamente
-- AmazonEC2ContainerRegistryFullAccess
-- AmazonECS_FullAccess
-- AdministratorAccess
Próximo / Criar usuário / Baixar CSV
2.Selecionar usuário / Habilitar acesso console FMA
- Nome dispositivo: ubuntuTeste1
- MFA device: Chave de acesso ou chave de segurança
Próximo / Ativar via navegador
3.Selecionar usuário / Criar chave de acesso
- Tipo: CLI
- Valor etiqueta descrição: Criar containers
Criar chave de acesso / Baixar CSV

--- INSTALAR AWS CLI ---
1.curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
2.sudo apt update && sudo apt install -y unzip
3.unzip awscliv2.zip
4.sudo ./aws/install
5.aws --version
6.aws configure
- informar keys geradas no CSV com dados de chave de acesso do usuário
- região: sa-east-1
- Default output format: json
7.Login AWS CLI: aws ecr get-login-password --region sa-east-1 | docker login --username AWS --password-stdin ID-CONTA.dkr.ecr.sa-east-1.amazonaws.com

--- PUBLICAR IMAGE NA AWS ---
1.ECR / Repositórios / Criar repositório
- Nome: ubsocial/meu-nginx
- Etiqueta: Mutable
Criar
2.No host Docker, upload Image na AWS:
- docker tag ubsocial/meu-nginx:latest ID-CONTA.dkr.ecr.sa-east-1.amazonaws.com/ubsocial/meu-nginx:latest
- docker push ID-CONTA.dkr.ecr.sa-east-1.amazonaws.com/ubsocial/meu-nginx:latest

--- CRIAR CLUSTER FARGATE ---
ECS / Clusters / Criar cluster
- Nome gerado automaticamente
- Infraestrutura: AWS Fargate (sem servidor)
Criar

--- CRIAR DEFINIÇÃO DE TAREFA ---
ECS / Definições de tarefa / Criar nova definição de tarefa
- Família: familia-task
- Tipo de inicialização: AWS Fargate
- CPU: .25vCPU
- Memória: .5GB
Container 1:
- Nome: meu-nginx-container
- URI da imagem: ID-CONTA.dkr.ecr.sa-east-1.amazonaws.com/ubsocial/meu-nginx:latest
- Porta do container: 80
Criar

--- CRIAR SERVIÇO FARGATE ---
ECS / Clusters / Selecionar cluster / Aba serviços / Criar
- Família da definição de tarefa: familia-task
- Nome do serviço gerado automaticamente
- Provedor de capacidade: Fargate (padrão)
- Tarefas desejadas: 1 (padrão)
- Rede VPC: padrão
- Sub-redes: padrão
- IP público: habilitar (padrão)
Criar

--- HABILITAR ACESSO AO CONTAINER AWS ---
ECS / Clusters / Selecionar cluster / Aba Serviços / Tarefas / Selecionar tarefa
- Aba Redes: clicar no ID da ENI
- Na ENI: clicar no grupo de segurança
- No grupo de segurança: editar regras de entrada (adicionar nova regra)
-- Tipo: HTTP
-- Protocolo: TCP (padrão)
-- Intervalo de portas: 80 (padrão)
-- Origem: Qualquer local-IPv4
-- 0.0.0.0/0
Salvar regras

--- ACESSAR CONTAINER AWS ---
ECS / Clusters / Selecionar cluster / Aba Serviços / Tarefas / Selecionar tarefa
- Aba Associações de rede: Copiar IP-AWS
- No host docker: curl http://IP-AWS

--- Exclusões ---
1.ECS / Clusters / Selecionar cluster / Excluir cluster
2.ECS / Definições de tarefa / Selecionar definição / familia-task / Ações / Cancelar registro
3.ECR / Repositórios / Selecionar repositório / Excluir
4.IAM / Usuários / Selecionar usuário / Excluir (desativar chave de acesso, e confirmar exclusão)
5.Apagar dados locais no host docker (images, container, Dockerfile)
</code></pre></small>

            <br><h4>Publicar projeto RESTful fullstack AWS:</h4>
            <p id="textoPost">Publicar projeto RESTful fullstack, com frontend Vue.js e backend Django, via criação de instância EC2 (Ubuntu).</p>
<small><pre><code>
--- CRIAR INSTÂNCIA AWS ---
EC2 / Instâncias / Executar instâncias
- Nome: ubuntuDjangoTeste1
- AMI: Ubuntu Server (nível gratuito)
- Tipo: t3.micro (verificar se região é t2 ou t3 nível gratuito)
- Criar par de chaves:
-- Nome: keyDjangoTeste1
-- Tipo: RSA
-- Formato: conforme SO de sua máquina
- Rede:
-- Atribuir IP público automaticamente: habilitar
-- Grupo de segurança criado automaticamente, com regras:
--- Permitir tráfego HTTP qualquer lugar
--- Permitir tráfego HTTPS qualquer lugar
--- Permitir tráfego SSH qualquer lugar
- Armazenamento: 8GB (nível gratuito)
Criar

--- CRIAR E ATRIBUIR GRUPO DE SEGURANÇA ---
EC2 / Grupos de segurança / Criar grupo de segurança
- Nome: grupoSegurancaTeste1
- Descrição: Grupo de seguranca para testes 1
- Regras de entrada:
-- SSH: porta 22, IP 0.0.0.0/0
-- HTTP: porta 80, IP 0.0.0.0/0
-- Personalizado TCP: porta 8000 (porta Django), IP 0.0.0.0/0
-- Personalizado TCP: porta 5173 (porta Vue.js), IP 0.0.0.0/0
Criar

EC2 / Instâncias / Selecionar instância / Ações / Segurança
- Alterar grupos de segurança para grupoSegurancaTeste1
Confirmar Executar instância (guardar IPv4 para acesso futuro)

--- CONECTAR INSTÂNCIA AWS ---
EC2 / Instâncias / Selecionar instância / Ações / Conectar CLI usando IP público (e executar comandos):
- sudo apt update && sudo apt install python3-pip npm python3-venv git -y && sudo pip3 install django djangorestframework markdown django-filter django-cors-headers pytest pytest-django pytest-html model_bakery --break-system-packages && sudo npm install -g @vue/cli
- curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash - && sudo apt install nodejs -y
- git clone https://github.com/mateusschwede/cafe_fullstack.git && cd cafe_fullstack/paris_cafe
- python3 manage.py migrate
- nano paris_cafe/settings.py (informar conteúdo abaixo):
ALLOWED_HOSTS = [
    'ec2-54-233-2-156.sa-east-1.compute.amazonaws.com', // IPv4 da instância EC2
    'localhost',
    '127.0.0.1',
]

- cd ../ && python3 manage.py runserver 0.0.0.0:8000 &
-- Enter para sair do comando iterativo (servidor Django executando em background nohup)
- cd ../cafe-frontend
- sudo npm install
- nano vite.config.ts (informar conteúdo abaixo):
export default defineConfig(&#123;
    // outro conteúdo
    server: &#123;
        host: '0.0.0.0',
        port: 5173,
        allowedHosts: [
            'ec2-54-233-2-156.sa-east-1.compute.amazonaws.com' // IPv4 da instância EC2
        ]
    &#125;
&#125;)

- nano src/services/api.ts (informar conteúdo abaixo):
// outro conteúdo
baseURL: 'http://ec2-54-233-2-156.sa-east-1.compute.amazonaws.com:8000' // IPv4 da instância EC2

- sudo npx vite --host
-- Acessar API REST backend Django: http://ipv4_aws:8000
-- Acessar projeto no browser: http://ipv4_aws:5173

--- Exclusões ---
1.EC2 / Instâncias / Selecionar instância / Ações / Estado da instância / Encerrar instância
2.EC2 / Grupos de segurança / Selecionar grupoSegurancaTeste1 / Excluir
3.EC2 / Chaves de acesso / Selecionar ubuntuDjangoTeste1-key.pem / Excluir
</code></pre></small>
        </div>
    </div>


<!--Rodapé-->
<div class="row">
    <div class="col-sm-12 text-center bg-black text-light pt-4 pb-3">
        <p>Elaborado por Mateus Schwede<br><small class="text-muted">ubsocial.github.io</small></p>
    </div>
</div>

</div>
</body>
</html>