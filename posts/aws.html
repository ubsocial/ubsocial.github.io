<!doctype html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="../icons/logoTit.png">
    <link rel="stylesheet" href="../estilo.css">
    <title>UB Social</title>
</head>
<body>
<div class="container-fluid">


    <div class="row">
        <div class="col-sm-12">
            <nav class="navbar rounded-bottom fixed-top navbar-expand-lg navbar-light bg-light shadow">
                <div class="container-fluid">
                    <a class="navbar-brand" href="../index.html"><img src="../icons/logo.png" class="d-inline-block align-text-top" width="11pt"> UB Social</a>
                    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
                    <div class="collapse navbar-collapse" id="navbarNav">
                        <ul class="navbar-nav">
                            <li class="nav-item"><a class="nav-link" href="../index.html">Home</a></li>
                            <li class="nav-item"><a class="nav-link" href="../sobre/sobre.html">Sobre</a></li>
                            <li class="nav-item"><a class="nav-link" href="../cursos.html">Cursos</a></li>
                            <li class="nav-item"><a class="nav-link" href="../livros/livros.html">Livros</a></li>
                        </ul>
                    </div>
                </div>
            </nav>
        </div>
    </div>

    <div class="row">
        <div class="col-sm-12 text-center" id="titulo">
            <h1>AWS</h1>
            <h6>Console Amazon Web Services free tier</h6>
            <a href="../index.html" class="btn btn-link text-decoration-none mb-3">Voltar</a>
        </div>

        <div class="col-sm-12">
            <p class="text-warning text-center">RESUMO EM CONSTRUÇÃO</p>
            <h4>Material complementar:</h4>
            <ul>
                <li>Conteúdo no YouTube: <a href="https://youtube.com/playlist?list=PLnPZ9TE1Tj4CygvubCbQtSUFFAaTR0Ehm&si=M2_9DbAEJ44bRBon" target="_blank" class="text-decoration-none">Acesse</a></li>
                <li>Conteúdo no GitHub: <a href="https://github.com/mateusschwede/workover_aws" target="_blank" class="text-decoration-none">Acesse</a></li>
                <li>Curso gratuito com certificado na Workover Academy (Curso AWS Free Tier): <a href="https://workover.com.br/cursos/1898/curso-aws-free-tier" target="_blank" class="text-decoration-none">Acesse</a></li>
            </ul>

            <br><h4>Instância EC2:</h4>
            <p id="textoPost">Amazon EC2 (Elastic Compute Cloud) fornece servidores virtuais na nuvem (instâncias) que podem ser usados para rodar aplicações, hospedar sites, bancos de dados, entre outros. Integra-se com outros serviços AWS, como S3 (armazenamento), RDS (banco de dados) e VPC (rede privada). Usado para hospedar site ou aplicação web, criar ambientes de desenvolvimento e testes, hospedar softwares pesados (IA ML, processamento de dados) e jogos, e backend de aplicações. Criar instância EC2 Ubuntu CLI (free tier), com aplicação nginx, habilitada para acesso externo:</p>
<small><pre><code>
--- CRIAR INSTÂNCIA AWS ---
EC2 / Instâncias / Executar instâncias
- Nome: ubuntuNginxTeste1
- AMI: Ubuntu Server (nível gratuito)
- Tipo: t3.micro (verificar se região é t2 ou t3 nível gratuito)
- Criar par de chaves:
-- Nome: keyNginxTeste1
-- Tipo: RSA
-- Formato: conforme SO de sua máquina
- Rede:
-- Atribuir IP público automaticamente: habilitar
-- Grupo de segurança criado automaticamente, com regras:
--- Permitir tráfego HTTP qualquer lugar
--- Permitir tráfego HTTPS qualquer lugar
--- Permitir tráfego SSH qualquer lugar
OBS: Após instância criada, pode-se editar regras de entrada do grupo de segurança, para permitir acesso apenas de IPs e portas específicas (EC2 / Grupos de segurança / Selecionar grupo / Editar regras de entrada)
- Armazenamento: 8GB (nível gratuito)
Executar instância

--- CONECTAR INSTÂNCIA AWS ---
EC2 / Instâncias / Selecionar instância / Ações / Conectar
- Connection type: IP público
- Endereço IPv4 público: selecionar (guardar IPv4 para acesso futuro)
Conectar

--- OPERAR INSTÂNCIA AWS ---
Na instância EC2 Ubuntu CLI, executar comandos:
- sudo apt update && sudo apt install nginx -y && sudo systemctl enable nginx --now && sudo su
- echo '&lt;h1&gt;Servidor EC2 UB Social&lt;/h1&gt;' &gt; /var/www/html/index.html

--- ACESSAR INSTÂNCIA AWS ---
- Acessar no browser: http://IPv4-PUBLICO-INSTANCIA
- Via Linux: ssh -i "sua-chave.pem" ubuntu@DNS-PUBLICO-INSTANCIA
</code></pre></small>

            <br><h4>Buckets S3:</h4>
            <p id="textoPost">Serviço de armazenamento de dados na AWS, permitindo armazenar qualquer tipo de dado (arquivos, imagens, vídeos, logs, backups, datasets, etc.) em unidades chamadas buckets. Cada bucket é "balde" de armazenamento lógico que pode conter objetos (arquivos), e cada objeto é identificado por key única. Integra-se com EC2 para armazenar backups, logs e arquivos de servidor. Usado também para armazenar BD via Athena. Possibilidade de backups automáticos ao S3. Geralmente usado para armazenar backups, dados, datasets, BDs e sites estáticos. Objetivo é criar S3 para armazenar site UB Social:</p>
<small><pre><code>
--- CRIAR BUCKET S3 ---
S3 / Buckets / Criar bucket
- Nome: bucket-ubsocial-teste1
- Propriedade de objeto: Marcar ACLs desabilitadas (recomendado)
- Configurações de bloqueio do acesso público deste bucket: desabilitar tudo
Criar bucket

--- UPLOAD ARQUIVOS NO BUCKET S3 ---
- Baixar arquivos do site estático: <a href="https://github.com/mateusschwede/workover_aws/archive/refs/heads/main.zip" target="_blank" class="text-decoration-none">https://github.com/mateusschwede/workover_aws/archive/refs/heads/main.zip</a>
- Descompactar arquivos baixados (site está em 2_buckets_s3, pasta ubsocial.github.io)

- S3 / Buckets / Selecionar bucket / Aba Objetos / Carregar
- Adicionar pastas: selecionar pasta ubsocial.github.io
Carregar

--- PUBLICAR SITE ESTÁTICO NO S3 ---
S3 / Buckets / Selecionar bucket / Aba Propriedades / Hospedagem de site estático / Editar / Ativar
- Documento de índice: index.html (se não estiver em uma pasta)
S3 / Buckets / Selecionar bucket / Aba Permissões / Editar política de bucket, informando conteúdo:
&#123;
    "Version": "2012-10-17",
    "Statement": [
        &#123;
            "Sid": "PublicReadGetObject",
            "Effect": "Allow",
            "Principal": "*",
            "Action": "s3:GetObject",
            "Resource": "arn:aws:s3:::bucket-ubsocial-teste1/*"
        &#125;
    ]
&#125;
- Salvar

--- ACESSAR SITE ESTÁTICO NO S3 ---
S3 / Buckets / Selecionar bucket / Aba Propriedades / Hospedagem de site estático
- Copiar URL do endpoint
- Acessar no browser: urlEndpoint/ubsocial.github.io/index.html
</code></pre></small>

            <br><h4>Banco de dados RDS:</h4>
            <p id="textoPost">Amazon RDS (Relational Database Service) é serviço de banco de dados relacional, permitindo gestão e escalabilidade de BD. Geralmente integrado com instâncias EC2 via VPC, funções serverless Lambda, coleção de logs via CloudWatch, backup e armazenamento em bucket S3, entre outros. Utilizado no cotidiano em conjunto com aplicações REST instaladas em instâncias EC2, backups em bucket S3, com disponibilidade para big data. Objetivo é criar BD MySQL em RDS e acessá-lo via máquina externa:</p>
<small><pre><code>
--- CRIAR BANCO DE DADOS RDS ---
Aurora and RDS / Bancos de dados / Criar banco de dados
- Método de criação: Padrão
- Opções de mecanismo: MySQL
- Modelos: Nível gratuito
- Configurações:
-- Identificador do banco de dados: ubsocial-mysql-teste1
-- Nome do usuário principal: admin
-- Senha: UBsocial123
- Configuração da instância:
-- Tipo de instância: (ver opções disponíveis no nível gratuito)
- Armazenamento:
-- Tipo de armazenamento: SSD de uso geral (gp2)
-- Armazenamento alocado: 20GB
-- Escalabilidade automática do armazenamento: desabilitar (para evitar custos extras)
- Conectividade:
-- Recurso de computação: Não se conectar a um recurso de computação do EC2
-- VPC: padrão
-- Grupo de sub-redes de banco de dados: padrão
-- Acesso público: Sim
-- Grupo de segurança de VPC (firewall): criar novo grupo de segurança
--- Nome: grupoSegurancaRDS1
-- Porta do banco de dados: 3306 (padrão MySQL)
- Configuração adicional:
-- Nome do banco de dados inicial: ubsocialdb1
Criar banco de dados

--- HABILITAR PORTA DE ACESSO RDS ---
EC2 / Grupos de segurança / Selecionar grupoSegurancaRDS1 / Editar regras de entrada (adicionar nova regra)
- Tipo: MySQL/Aurora
- Protocolo: TCP (padrão)
- Porta: 3306 (padrão MySQL)
- Origem: Qualquer local-IPv4 (0.0.0.0/0)
Salvar regras

--- ACESSAR BANCO DE DADOS RDS ---
RDS / Bancos de dados / Selecionar banco de dados / Aba Segurança e conexão / Copiar endpoint do RDS
No editor SQL, criar conexão:
- Host: Endpoint do RDS (sem "https://")
- Porta: 3306
- User: admin
- Senha: UBsocial123
- (opcional) Database: ubsocialdb1
Testar conexão e Conectar

Editor SQL, executar comandos:
CREATE TABLE tableTeste (
    id INT AUTO_INCREMENT PRIMARY KEY,
    nome VARCHAR(100) NOT NULL,
    email VARCHAR(100) NOT NULL UNIQUE
);
INSERT INTO tableTeste (nome, email) VALUES ('UB Social','ubsocial@example.com'),('UB Social 2','ubsocial2@example.com');
SELECT * FROM tableTeste;

RDS / Bancos de dados / Selecionar banco de dados / Aba Logs e eventos / Selecionar log de auditoria / Visualizar
</code></pre></small>

            <br><h4>DynamoDB:</h4>
            <p id="textoPost">Amazon DynamoDB é serviço de BD NoSQL, escalável de alta performance. Usa tables de itens (identificados por key única) com atributos - via JSON. Integra-se com Lambda para criar aplicações serverless, API Gateway para expor APIs RESTful, CloudWatch para monitoramento e S3 para armazenamento de dados em buckets. Usado em aplicações web e mobile, jogos, IoT e big data. Objetivo é criar e testar BD NoSQL DynamoDB, via AWS Console e CloudShell:</p>
<small><pre><code>
--- CRIAR TABLE DYNAMODB ---
DynamoDB / Tabelas / Criar tabela
- Nome da tabela: usuarios-teste1
- Chave primária: user_id (String)
- Configurações da tabela: padrão
Criar tabela

--- INSERIR DADOS NA TABLE ---
DynamoDB / Tabelas / Selecionar usuarios-teste1 / Explorar itens da tabela / Criar item
- user_id: 1
Adicionar novo atributo (String)
- nome: 'UB Social'
Adicionar novo atributo (String)
- email: 'ubsocial@example.com'
Criar item

DynamoDB / Tabelas / Selecionar usuarios-teste1 / Explorar itens da tabela / Criar item
- user_id: 2
- nome: 'UB Social 2'
- email: 'ubsocial2@example.com'
Criar item

--- CONSULTAR DADOS NA TABLE ---
DynamoDB / Tabelas / Selecionar usuarios-teste1 / Explorar itens da tabela / Verificar ou consultar itens
- Tipo: Consulta
- Selecionar projeção de atributos: Atributos específicos
- Atributos específicos do projeto: nome
- Chave de partição (user_id): 1
Executar

--- CONSULTAR DADOS NA TABLE - CloudShell ---
Canto superior direito do console AWS / CloudShell, e executar comandos:
- aws dynamodb scan --table-name usuarios-teste1
- aws dynamodb put-item --table-name usuarios-teste1 --item '&#123;"user_id":&#123;"S":"u003"&#125;,"nome":&#123;"S":"UB Social 3"&#125;,"email":&#123;"S":"ubsocial3@example.com"&#125;&#125;'
- aws dynamodb get-item --table-name usuarios-teste1 --key '&#123;"user_id": &#123;"S": "u003"&#125;&#125;'
- aws dynamodb scan --table-name usuarios-teste1 --filter-expression "#n = :nomeVal AND email = :emailVal" --expression-attribute-names '&#123;"#n":"nome "&#125;' --expression-attribute-values '&#123;":nomeVal":&#123;"S":"UB Social 2"&#125;,":emailVal":&#123;"S":"ubsocial2@example.com"&#125;&#125;'
</code></pre></small>

            <br><h4>ECS Fargate:</h4>
            <p id="textoPost">Amazon ECS (Elastic Container Service) é serviço para gerenciar e executar containers Docker, de forma orquestrada e automática, dispensando instalação manual de cluster Kubernetes ou servidores. AWS Fargate é motor de execução (compute engine) do ECS, permitindo executar containers, sem precisar gerenciar servidores EC2. ECS integra-se com ECR (Elastic Container Registry) para criação de registry de Images, VPC para rede de containers, S3/DynamoDB/RDS para armazenamento de dados (Volumes), Elastic Load Balancer (ALB/NLB) para distribuição de tráfego entre containers, CloudWatch para gestão de logs, etc. Usado em microservices web, APIs REST ou GraphQL, Sites estáticos com backend leve (ex: Nginx), onde containers executam tecnologias base para armazenamento e funcionamento de tais aplicações. Fargate usado em tarefas de processamento de dados, para execução de containers on demand. Usado também em ambientes de teste ou CI/CD, na criação de containers temporários em Pipelines. Objetivo é criar ECS de container Nginx, através de cluster Fargate, contendo definição de tarefa para execução do container, e acesso via IP público:</p>
<small><pre><code>
--- CRIAR CLUSTER FARGATE ---
ECS / Clusters / Criar cluster
- Nome: ecs-fargate-nginx-demo
- Infraestrutura: Somente Fargate
Criar

--- CRIAR DEFINIÇÃO DE TAREFA ---
ECS / Definições de tarefa / Criar nova definição de tarefa
- Nome: nginx-fargate-demo
- Tipo de inicialização: AWS Fargate
- CPU: .25vCPU
- Memória: .5GB
- Função da tarefa: Nenhum
- Função de execução de tarefas: ecsTaskExecutionRole
- Container 1:
-- Nome: nginx
-- URI da imagem: nginx:alpine
- Mapeamentos de porta:
-- Porta do container: 80
-- Protocolo: TCP
- Coleção de logs: desabilitar
Criar

--- CRIAR GRUPO DE SEGURANÇA ---
EC2 / Grupos de segurança / Criar grupo de segurança
- Nome: grupoSeg-ecs-fargate-http
- Descrição: Permitir acesso HTTP externo ao Nginx ECS
- VPC: padrão
- Regras de entrada (adicionar nova regra):
-- Tipo: HTTP
-- Protocolo: TCP (padrão)
-- Intervalo de portas: 80 (padrão)
-- Origem: Qualquer local-IPv4 (0.0.0.0/0)
Criar

--- EXECUTAR TAREFA ---
ECS / Clusters / Selecionar ecs-fargate-nginx-demo / Aba Tarefas / Executar nova tarefa
- Família da definição de tarefa: nginx-fargate-demo
- Opções de computação: Selecionar Tipo de inicialização
- Tipo de inicialização: Fargate
- Rede:
-- VPC: padrão
-- Sub-redes: padrão
-- Nome do grupo de segurança: grupoSeg-ecs-fargate-http
-- IP público: Habilitar
Criar

--- ACESSAR CONTAINER ECS FARGATE ---
ECS / Clusters / Selecionar ecs-fargate-nginx-demo / Aba Tarefas / Selecionar tarefa em execução / Aba Associações de rede / Copiar IP público
- Acessar no browser: http://IP-PUBLICO-TAREFA (abrirá página padrão do Nginx)
- Via Linux: curl http://IP-PUBLICO-TAREFA

--- Exclusões ---
1.ECS / Clusters / Selecionar ecs-fargate-nginx-demo / Aba Tarefas / Selecionar tarefa em execução / Ações / Parar
2.ECS / Clusters / Selecionar ecs-fargate-nginx-demo / Excluir cluster
3.ECS / Definições de tarefa / Selecionar definição / nginx-fargate-demo / Ações / Cancelar registro, depois Excluir
4.EC2 / Grupos de segurança / Selecionar grupoSeg-ecs-fargate-http / Excluir
</code></pre></small>

            <br><h4>Serverless Lambda e API Gateway:</h4>
            <p id="textoPost">Serviços serverless não necessitam de servidores como base de funcionamento, sendo própria AWS responsável por manter e escalar aplicação. Lambda é motor que executa códigos serverless on demand, em resposta a eventos (triggers). API Gateway expõe funções Lambda e outros backends à internet, criando endpoints acessáveis externamente como porta de entrada a essas APIs HTTP REST ou WebSocket. Lambda e API Gateway integram-se com serviços S3 para armazenamento permanente de dados, via RDS, DynamoDB e logs no CloudWatch, e integrações com SNS para notificações e SQS para fila de mensagens. Lambda e API Gateway utilizados em APIs REST, juntamente com DynamoDB. Também em processamento de arquivos, tarefas agendadas de backups diários (EventBridge), e IA ML de processamento leve, dispensando necessidade de servidor. Objetivo é criar serviço serverless, via Lambda, que retorna mensagem quando acessado externamente, disponibilizado via API Gateway.</p>
<small><pre><code>
--- CRIAR FUNÇÃO LAMBDA ---
Lambda / Criar função
- Criar função do zero
- Nome da função: hello-serverless
- Tempo de execução: Python
- Permissões / Alterar a função de execução padrão: Selecionar 'Criar uma função com permissões básicas do Lambda'
Criar função

--- ADICIONAR CÓDIGO NA FUNÇÃO LAMBDA ---
Lambda / Selecionar função hello-serverless / Aba Código / Editar código:
def lambda_handler(event, context):
    return &#123;
        "statusCode": 200,
        "headers": {"Content-Type": "text/plain; charset=utf-8"},
        "body": "Olá, mundo serverless!"
    &#125;
- No VSCode da AWS, clicar em Deploy

--- TESTAR FUNÇÃO LAMBDA ---
Lambda / Selecionar função hello-serverless / Aba Testar / Evento de teste
- Ação de evento de teste: Criar novo evento
- Nome do evento: eventoTeste1
Salvar e Testar
- Verificar resultado: Status 200, Body "Olá, mundo UB Social Serverless!"

--- CRIAR API GATEWAY ---
API Gateway / APIs / Criar API
- Tipo de API: API HTTP / Compilar
- Nome da API: api-hello-serverless
- Tipo de endereço IP: IPv4
- Integrações / Acicionar integração
-- Tipo: Lambda
-- Escolher função Lambda: localizacaoAWS:hello-serverless
Avançar
- Configurar rotas:
-- Método: GET
-- Rota: /
-- Destino: hello-serverless
Avançar
- Estágio de implantação: padrão (geralmente com implantação automática habilitada)
Avançar / Criar / Implantar

--- TESTAR API GATEWAY ---
API Gateway / APIs / Selecionar api-hello-serverless / Aba Visão geral
- Copiar URL do endpoint padrão
- Acessar no browser: urlEndpoint
- Via Linux: curl urlEndpoint
- Verificar resultado: "Olá, mundo UB Social Serverless!"

--- Exclusões ---
1.API Gateway / APIs / Selecionar api-hello-serverless / Ações / Excluir
2.Lambda / Selecionar função hello-serverless / Ações / Excluir
3.CloudWatch / Logs / Selecionar grupo de logs / Ações / Excluir grupo de logs
4.IAM / Funções / Selecionar função criada para Lambda / Ações / Excluir função
5.IAM / Políticas / Selecionar política criada para Lambda / Ações / Excluir política
</code></pre></small>

            <br><h4>CloudWatch:</h4>
            <p id="textoPost">Amazon CloudWatch é serviço de monitoramento e observabilidade da AWS, coletando, armazenando e exibindo métricas, logs e eventos dos serviços AWS. Integra-se com praticamente todos serviços AWS, como métricas alarme em instâncias EC2, medindo processamento, armazenamento e memória. Coleta logs e métricas de execução de funções Lambda e APIs Gateway, medindo tempo de resposta, erros e latência. Coleta métricas de desempenho em bases de dados RDS, DynamoDB, em ECS Fargate, e métricas de armazenamento de buckets S3. Usado em praticamente todo ambiente AWS profissional, monitorando servidores EC2, APIs serverless Lambda, dashboards e logs centralizados para times de operações, métricas para gerar escalonamento automático (auto scaling), e alertas de segurança e compliance quando função IAM for modificada, via CloudWatch e CloudTrail. Objetivo é criar alarme no CloudWatch que monitora logs personalizados de função AWS Lambda, disparando quando função for executada:</p>
<small><pre><code>
--- CRIAR FUNÇÃO LAMBDA ---
Lambda / Criar função
- Criar função do zero
- Nome: logLambdaCloudWatch
- Tempo de execução: Python
- Permissões / Alterar a função de execução padrão: Selecionar 'Criar uma função com permissões básicas do Lambda'
Criar função

--- ADICIONAR CÓDIGO NA FUNÇÃO LAMBDA ---
Lambda / Selecionar função logLambdaCloudWatch / Aba Código / Editar código:
import json
import logging

logger = logging.getLogger()
logger.setLevel(logging.INFO)

def lambda_handler(event, context):
    logger.info("Função Lambda executada com sucesso!")
    return &#123;
        'statusCode': 200,
        'body': json.dumps('Log enviado ao CloudWatch!')
    &#125;
- No VSCode da AWS, clicar em Deploy

--- TESTAR FUNÇÃO LAMBDA ---
Lambda / Selecionar função logLambdaCloudWatch / Aba Testar / Evento de teste
- Ação de evento de teste: Criar novo evento
- Nome do evento: eventoTesteLog1
Salvar e Testar

--- VERIFICAR LOGS NO CLOUDWATCH ---
CloudWatch / Logs / Selecionar grupo de logs / Selecionar grupo / Aba Streams de log / Selecionar fluxo / Verificar logs

--- CRIAR ALARME NO CLOUDWATCH ---
CloudWatch / Alarmes / Criar alarme
- Selecionar métrica / Lambda by Function name / Selecionar logLambdaCloudWatch invocations / Selecionar e continuar
- Período: 1 minuto
- Condição: Maior que ou igual a 1
Avançar
- Nome do alarme: AlertaExecucaoLambda
Avançar / Criar alarme

--- TESTAR ALARME NO CLOUDWATCH ---
Lambda / Selecionar função logLambdaCloudWatch / Aba Testar / Evento de teste
- Ação de evento de teste: Selecionar eventoTesteLog1
Testar
- CloudWatch / Alarmes / Selecionar AlertaExecucaoLambda / Verificar estado do alarme (Ok -&gt; Em alarme)

--- Exclusões ---
1.CloudWatch / Alarmes / Selecionar AlertaExecucaoLambda / Ações / Excluir
2.CloudWatch / Logs / Selecionar grupo de logs / Ações / Excluir grupo de logs
3.Lambda / Selecionar função logLambdaCloudWatch / Ações / Excluir
</code></pre></small>

            <br><h4>SNS e SQS:</h4>
            <p id="textoPost">SNS (Simple Notification Service) é serviço de publicação/assinatura (pub/sub), enviando notificações automaticamente para destinos (emails, SMS, filas, funções Lambda) a partir de gatilho. Integra-se com CloudWatch no disparo de alertas automáticos, a partir de gatilhos em execuções de funções Lambda, alteração em arquivos nos buckets S3 e filas SQS de mensagens. SQS (Simple Queue Service) é serviço de filas de mensagens, armazenando mensagens temporariamente até que outro sistema as processe. Integra-se na publicação de mensagens SNS, leitura automatica de fila via funções Lambda, processamento de mensagens em EC2/ECS, e gatilhos de envio de eventos na manipulação de arquivos em buckets S3. Utilizados em ambiente de produção, em que CloudWatch detecta alto consumo CPU, envia evento SNS, que repassa notificação via email e cópia à SQS. Lambda processa fila SQS e executa ações automáticas (ex: escalar instâncias). Também utilizados em sistemas API Gateway de publicação de pedido SNS, que direciona-se em fila SQS, separando mensagens entre setores (ex: faturamento, estoque), e cada microserviço processa sua fila no próprio tempo. Objetivo é publicar mensagem em tópico SNS, entregando-a em fila SQS que, por sua vez, aciona função Lambda de processamento da mensagem, e registrará em log CloudWatch:</p>
<small><pre><code>
--- CRIAR TÓPICO SNS ---
SNS / Tópicos / Criar tópico
- Nome: meu-topico-sns1
- Tipo: Padrão
Criar tópico (anotar ARN gerado)

--- CRIAR FILA SQS ---
SQS / Filas / Criar fila
- Tipo: Padrão
- Nome: minha-fila-sqs1
Criar fila (anotar ARN gerado)

--- CONECTAR SNS COM SQS ---
SNS / Tópicos / Selecionar meu-topico-sns1 / Aba Assinaturas / Criar assinatura
- Protocolo: Amazon SQS
- Endpoint: ARN da fila SQS
Criar assinatura

--- CRIAR FUNÇÃO LAMBDA ---
Lambda / Criar função
- Criar função do zero
- Nome: lambda-processa-sqs1
- Tempo de execução: Python
- Permissões / Alterar a função de execução padrão: Selecionar 'Criar uma função com permissões básicas do Lambda'
Criar função

--- ADICIONAR CÓDIGO NA FUNÇÃO LAMBDA ---
Lambda / Selecionar função lambda-processa-sqs1 / Aba Código / Editar código:
import json

def process_text_message(text):
    text = text.strip()
    if not text:
        print("Mensagem vazia ou somente espaços - ignorando")
        return
    print("Mensagem final:", text)

def lambda_handler(event, context):
    for record in event.get('Records', []):
        body = record.get('body', '')
        try:
            parsed = json.loads(body)
        except Exception:
            parsed = None

        if isinstance(parsed, dict) and 'Message' in parsed:
            msg = parsed.get('Message', '')
            try:
                inner = json.loads(msg)
                print("Mensagem original (JSON):")
                print(json.dumps(inner, ensure_ascii=False))
            except Exception:
                process_text_message(msg)

        elif isinstance(parsed, dict):
            print("Mensagem recebida (body JSON):")
            print(json.dumps(parsed, ensure_ascii=False))
        
        else:
            process_text_message(body)

    return &#123;"statusCode": 200, "body": json.dumps("OK")&#125;
- No VSCode da AWS, clicar em Deploy

--- IAM PERMITIR LAMBDA ACESSAR FILA SQS ---
Lambda / Selecionar função lambda-processa-sqs1 / Aba Configurações / Permissões / Função de execução / Clicar no nome da função (irá para tela IAM)
- Políticas de permissões / Adicionar permissões / Criar política em linha / Aba JSON:
&#123;
  "Version": "2012-10-17",
  "Statement": [
    &#123;
      "Sid": "AllowLambdaToAccessSQS",
      "Effect": "Allow",
      "Action": [
        "sqs:ReceiveMessage",
        "sqs:DeleteMessage",
        "sqs:GetQueueAttributes",
        "sqs:ChangeMessageVisibility"
      ],
      "Resource": "ARN-SUA-FILA-SQS-AQUI"
    &#125;
  ]
&#125;

Avançar
- Nome da política: LambdaSQSAccessPolicy1
Criar política

--- CONECTAR FILA SQS À LAMBDA ---
Lambda / Selecionar função lambda-processa-sqs1 / Aba Configurações / Gatilhos / Adicionar gatilho
- Configuração do gatilho: Selecionar SQS
- Fila: minha-fila-sqs1
Adicionar
- Habilitar gatilho: Aba Gatilhos / Clicar no gatilho SQS / Aba Triggers do Lambda (verificar se trigger está habilitado)

--- PUBLICAR MENSAGEM NO TÓPICO SNS ---
SNS / Tópicos / Selecionar meu-topico-sns1 / Publicar mensagem
- Assunto: Novo pedido 1
- Corpo da mensagem: Pedido de compra UB Social
Publicar mensagem

--- VER LOG NO CLOUDWATCH ---
CloudWatch / Logs / Selecionar grupo de logs / Aba Streams de log / Selecionar fluxo / Verificar logs (deve conter mensagem "Mensagem recebida: Pedido de compra UB Social")

--- Exclusões ---
1.Lambda / Selecionar função lambda-processa-sqs1 / Ações / Excluir
2.SQS / Filas / Selecionar minha-fila-sqs1 / Ações / Excluir fila
3.SNS / Tópicos / Selecionar meu-topico-sns1 / Ações / Excluir tópico
4.CloudWatch / Logs / Selecionar grupo de logs / Ações / Excluir grupo de logs
5.IAM / Funções / Selecionar função criada para Lambda / Ações / Excluir função
6.IAM / Políticas / Selecionar política LambdaSQSAccessPolicy1 / Ações / Excluir política
</code></pre></small>

            <br><h4>CloudFormation:</h4>
            <p id="textoPost">Serviço IaC (infrastructure as code) que permite criar, configurar e versionar infraestrutura AWS via templates YAML/JSON. Integra-se com CodePipeline, na criação de etapas de deploy, e com recursos computacionais de serviços como IAM, EC2, S3, Lambda, RDS, entre outros. Utilizado na prática para gerar arquitetura de tecnologia (VPC, EC2, banco de dados, Lambda), a partir de único template, sendo reprodutível, auditável e padronizada. Objetivo é criar template CloudFormation que cria bucket S3, gerando e destruindo toda sua infraestrutura, de forma automatizada:</p>
<small><pre><code>
--- CRIAR TEMPLATE CLOUDFORMATION ---
- Criar arquivo s3-bucket-simple.yaml:
AWSTemplateFormatVersion: "2010-09-09"
Description: Template CloudFormation simples que cria um bucket S3
Resources:
    MeuBucketS3:
        Type: AWS::S3::Bucket
        Properties:
            BucketName: !Sub "${AWS::AccountId}-meu-bucket-exemplo"
            VersioningConfiguration:
                Status: Suspended
Outputs:
    BucketName:
        Description: "Nome do bucket criado"
        Value: !Ref MeuBucketS3

--- CRIAR PILHA CLOUDFORMATION ---
AWS / CloudFormation / Pilhas / Criar pilha / Com novos recursos (padrão)
- Preparar modelo: Escolher um modelo existente
- Especificar modelo: Fazer upload de um arquivo de modelo
Avançar
- Nome da pilha: exemplo-s3-iac
Avançar / Enviar
- Verificar criação da pilha (Status CREATE_IN_PROGRESS - aguardar até CREATE_COMPLETE)

--- VERIFICAR BUCKET S3 CRIADO ---
S3 / Buckets / Verificar bucket criado com nome ID-CONTA-meu-bucket-exemplo

--- Exclusões ---
1.CloudFormation / Pilhas / Selecionar exemplo-s3-iac / Ações / Excluir
2.Verificar exclusão do bucket S3 (deve ser excluído automaticamente junto com pilha)
</code></pre></small>

            <br><h4>CodePipeline:</h4>
            <p id="textoPost">Serviço DevOps na AWS, orquestrando fluxo completo de integração e entrega contínua (CI/CD), como obtenção de código, compilação e testes, e deploy. Integra-se com repositórios (origem do código), CodeBuild (build e teste), e CloudFormation / Elastic Beanstalk / S3 / ECS / Lambda para destino de deploy. Utilizado na prática para Pipelines de deploy de aplicações, gerados a partir de gatilhos, como push no repositório, gerando artefato e fazendo deploy automático na AWS. Objetivo é criar Pipeline de deploy automatizado de site HTML, executado a partir de push ao repositório GitHub, onde CodePipeline detecta mudança no repositório, baixa artefato e copia arquivos para bucket S3, atualizando o site automaticamente na AWS (necessário conta no GitHub):</p>
<small><pre><code>
--- CRIAR REPOSITÓRIO GITHUB ---
GitHub / New repository
- Nome: meu-site-demo1
- Visibilidade: Público
Criar repositório
- Acessar repositório / Adicionar arquivo / Create new file
- Nome do arquivo: index.html, conteúdo:
&lt;h1&gt;Meu Site Demo 1&lt;/h1&gt;
Commit changes

--- CRIAR BUCKET S3 ---
S3 / Buckets / Criar bucket
- Nome: meu-site-demo1-ubsocial
- Bloquear todo o acesso público: desabilitar
Criar bucket
S3 / Buckets / Selecionar bucket / Aba Propriedades / Hospedagem de site estático / Editar / Ativar
- Documento de índice: index.html
Salvar alterações (aba Propriedades / Hospedagem de site estático / Copiar URL do endpoint)
S3 / Buckets / Selecionar bucket / Aba Permissões / Editar política de bucket, informando conteúdo:
&#123;
    "Version": "2012-10-17",
    "Statement": [
        &#123;
            "Effect": "Allow",
            "Principal": "*",
            "Action": [
                "s3:GetObject"
            ],
            "Resource": [
                "arn:aws:s3:::meu-site-demo1-ubsocial/*"
            ]
        &#125;
    ]
&#125;

- Salvar alterações

--- CRIAR PIPELINE CODEPIPELINE ---
AWS / CodePipeline / Pipelines / Criar pipeline
- Category: Criar pipeline personalizado
Avançar
- Nome: meu-site-demo1-pipeline
- Função de serviço: Nova função de serviço
- Nome da função: CodePipelineServiceRole1
Avançar
- Origem (provedor): GitHub (por meio do aplicativo OAuth)
- Conectar ao GitHub / Autorizar AWS CodePipeline
- Repositório: selecionar meu-site-demo1
- Ramificação: main
Avançar
- Compilação: ignorar etapa de compilação
- Teste: ignorar etapa de teste
- Implantação (Provedor): Amazon S3
- Bucket: meu-site-demo1-ubsocial
- Chave do objeto: site1.zip
- Extraia o arquivo antes de implantar: habilitar
Avançar / Criar pipeline

--- CONFERIR CRIAÇÃO DO PIPELINE ---
CodePipeline / Pipelines / Selecionar meu-site-demo1-pipeline / Verificar execução do pipeline (Status: Succeeded)
S3 / Buckets / Selecionar meu-site-demo1-ubsocial / Verificar arquivo site1.zip criado
- Acessar no browser: URL endpoint do bucket S3 (urlBucket/site.zip/index.html)

--- ALTERAR ARQUIVO NO REPOSITÓRIO GITHUB ---
GitHub / Repositório meu-site-demo1 / Selecionar arquivo index.html / Editar
- Alterar conteúdo do arquivo:
&lt;h1&gt;Meu Site Demo 1 - Atualizado&lt;/h1&gt;
Commit changes

--- CONFERIR EXECUÇÃO DO PIPELINE APÓS ALTERAÇÃO ---
CodePipeline / Pipelines / Selecionar meu-site-demo1-pipeline / Verificar nova execução automática do pipeline (Status: Succeeded)
S3 / Buckets / Selecionar meu-site-demo1-ubsocial / Verificar arquivo site1.zip atualizado
- Atualizar no browser: URL endpoint do bucket S3 (urlBucket/site.zip/index.html)

--- Exclusões ---
1.CodePipeline / Pipelines / Selecionar meu-site-demo1-pipeline / Ações / Excluir pipeline
2.S3 / Buckets / Selecionar meu-site-demo1-ubsocial / Ações / Excluir bucket
3.IAM / Funções / Selecionar CodePipelineServiceRole1 / Ações / Excluir função
4.IAM / Políticas / Selecionar AWSCodePipelineServiceRole-sa-east-1-meu-site-demo1-pipeline / Ações / Excluir política
5.(Opcional) GitHub / Repositório meu-site-demo1 / Settings / Delete this repository
</code></pre></small>

            <br><h4>ELB:</h4>
            <p id="textoPost">ELB (Elastic Load Balancing) distribui automaticamente tráfego de rede entre múltiplas instâncias, containers ou endpoints, garantindo alta disponibilidade e escalabilidade. "porteiro inteligente" que recebe requisições e distribui entre servidores disponíveis. Integra-se com outros serviços AWS, como EC2/ECS na distribuição de tráfego entre instâncias e containers, Lambda pode receber requisições diretamente do ALB, Auto Scaling adiciona ou remove instâncias conforme tráfego, e o ALB se ajusta automaticamente, e Route 53 com DNS que redireciona domínios ao ELB. Usado na prática, onde ALB garante disponibilidade e prevenção a catástrofes, redirecionando tráfego entre instâncias, em sistemas web, garantindo escalabilidade automática conforme demanda de acessos. Usado também em microserviços e containers K8S, onde cada serviço pode ter rota URL específica. Tipos ELB:</p>
            <ul>
                <li>Application Load Balancer (ALB): trabalha na Camada 7 (HTTP/HTTPS), interpreta conteúdo da requisição (rota, header, etc). Usado em APIs, apps web, microserviços;</li>
                <li>Network Load Balancer (NLB): camada 4 (TCP/UDP), focado em performance e baixa latência. Usado em jogos, IoT, apps em tempo real;</li>
                <li>Gateway Load Balancer (GWLB): redireciona tráfego para appliances virtuais (firewalls, IDS, etc). Usado em segurança e inspeção de tráfego;</li>
                <li>Classic Load Balancer (CLB): legado, suportado apenas para compatibilidade em sistemas antigos.</li>
            </ul>
            <p id="textoPost">Objetivo é criar 2 instâncias EC2 (Ubuntu Apache), distribuindo tráfego entre elas, via Application Load Balancer (ALB):</p>
<small><pre><code>
--- CRIAR INSTÂNCIA EC2 Server 1 ---
EC2 / Instâncias / Executar instâncias
- Nome: web-server-1
- AMI: Ubuntu Server (nível gratuito)
- Tipo: t3.micro (verificar se região é t2 ou t3 nível gratuito)
- Criar par de chaves:
-- Nome: curso-elb-key1
-- Tipo: RSA
-- Formato: conforme SO de sua máquina
- Rede: Editar
-- Atribuir IP público automaticamente: habilitar
-- Grupo de segurança: criar novo grupo de segurança
--- Nome: grupoSeg-web-elb1
--- Descrição: HTTP-SSH-EC2-ELB-ubsocial
--- Regras de entrada:
---- Tipo: SSH / Protocolo: TCP / Intervalo de portas: 22 / Tipo de origem: Qualquer local-IPv4 (0.0.0.0/0)
---- Tipo: HTTP / Protocolo: TCP / Intervalo de portas: 80 / Tipo de origem: Qualquer local-IPv4 (0.0.0.0/0)
-- Armazenamento: 8GB (nível gratuito)
-- Dados do usuário (User Data - inserir comandos):
#!/bin/bash
apt update -y
DEBIAN_FRONTEND=noninteractive apt install -y apache2
systemctl enable apache2 --now
echo "&lt;h1&gt;Servidor 1: $(hostname)&lt;/h1&gt;" &gt; /var/www/html/index.html
- Executar instância

--- CRIAR INSTÂNCIA EC2 Server 2 ---
EC2 / Instâncias / Executar instâncias
- Nome: web-server-2
- AMI: Ubuntu Server (nível gratuito)
- Tipo: t3.micro (verificar se região é t2 ou t3 nível gratuito)
- Par de chaves: Selecionar curso-elb-key1
- Rede: Selecionar grupo de segurança comuns: grupoSeg-web-elb1
- Armazenamento: 8GB (nível gratuito)
- Dados do usuário (User Data - inserir comandos):
#!/bin/bash
apt update -y
DEBIAN_FRONTEND=noninteractive apt install -y apache2
systemctl enable apache2 --now
echo "&lt;h1&gt;Servidor 2: $(hostname)&lt;/h1&gt;" &gt; /var/www/html/index.html
- Executar instância

--- TESTAR APACHE NAS INSTÂNCIAS EC2 ---
- Server 1: EC2 / Instâncias / Selecionar web-server-1 / Copiar IPv4 público (abrir no browser: http://IP-PUBLICO-SERVER-1)
- Server 2: EC2 / Instâncias / Selecionar web-server-2 / Copiar IPv4 público (abrir no browser: http://IP-PUBLICO-SERVER-2)

--- CRIAR GRUPO DE DESTINO ---
EC2 / Grupos de Destino / Criar grupo de destino
- Tipo de destino: Instâncias
- Nome: grupo-destino-web1-ubsocial
- Protocolo: HTTP
- Porta: 80
- Tipo de endereço IP: IPv4
- VPC: padrão (mesmo das instâncias EC2)
- Verificações de integridade:
-- Protocolo: HTTP
-- Caminho da verificação de integridade: /
-- Intervalo: 30 segundos (padrão)
-- Tempo limite: 5 segundos (padrão)
Avançar
- Registrar destinos:
-- Selecionar web-server-1 e web-server-2
-- Porta para instâncias: 80
Incluir como pendente abaixo / Criar grupo de destino

--- CRIAR APPLICATION LOAD BALANCER (ALB) ---
EC2 / Load Balancers / Criar Load Balancer / Application Load Balancer / Criar
- Nome: alb-web1-ubsocial
- Esquema: Voltado para a internet
- Tipo de endereço IP: IPv4
- Zonas de disponibilidade: selecionar todas disponíveis (padrão)
- Grupos de segurança: Selecionar grupoSeg-web-elb1
- Listeners e roteamento: Protocolo: HTTP / Porta: 80
- Ação padrão:
-- Encaminhar aos grupos de destino
-- Selecionar grupo-destino-web1-ubsocial
Criar Load Balancer (copiar DNS do ALB gerado)

--- TESTAR APPLICATION LOAD BALANCER (ALB) ---
- Acessar no browser: DNS-ALB-GERADO (recarregar página várias vezes, deve alternar entre Server 1 e Server 2)

--- Exclusões ---
1.EC2 / Load Balancers / Selecionar alb-web1-ubsocial / Ações / Excluir
2.EC2 / Grupos de Destino / Selecionar grupo-destino-web1-ubsocial / Ações / Excluir
3.EC2 / Instâncias / Selecionar web-server-1 / Ações / Instância de estado / Parar, depois Terminar
4.EC2 / Instâncias / Selecionar web-server-2 / Ações / Instância de estado / Parar, depois Terminar
5.EC2 / Grupos de segurança / Selecionar grupoSeg-web-elb1 / Ações / Excluir
6.EC2 / Pares de chaves / Selecionar curso-elb-key1 / Ações / Excluir par de chaves
</code></pre></small>

            <br><h4>Route 53:</h4>
            <p id="textoPost">Serviço de DNS da AWS, realizando tradução entre domínio (ex: meusite.com) e IP (ex: 3.120.45.88), para direcionamento de máquinas. Integra-se com instâncias EC2 no redirecionamento de IPs a DNS, criação automática de alias Elastic Load Balancing no roteamento de vários servidores, domínios em APIs Gateway, integrações DNS com servidor, e automação de zonas DNS e registro IaC no CloudFormation. Utilizado na prática em sites com DNS próprio (EC2, S3, ALB), infraestrutura escalável ELB e Auto Scaling, APIs e microserviços com emissão e validação de certificados SSL, DNS interno em zonas privadas VPC e automações DevOps com CloudFormation ou Terraform. Objetivo é utilizar Route 53 (zona privada), para resolver DNS em VPC, entre instâncias EC2 (Ubuntu + Apache):</p>
<small><pre><code>
--- CRIAR INSTÂNCIA EC2 (web1) ---
EC2 / Instâncias / Executar instâncias
- Nome: web1
- AMI: Ubuntu Server (nível gratuito)
- Tipo: t3.micro (verificar se região é t2 ou t3 nível gratuito)
- Criar par de chaves:
-- Nome: route53-key1
-- Tipo: RSA
-- Formato: conforme SO de sua máquina
- Rede: Editar
-- Atribuir IP público automaticamente: habilitar
-- Grupo de segurança: criar novo grupo de segurança
--- Nome: grupoSeg-route53-ssh-http
--- Descrição: SSH-HTTP-EC2-Route53-ubsocial
--- Regras de entrada:
---- Tipo: SSH / Protocolo: TCP / Intervalo de portas: 22 / Tipo de origem: Qualquer local-IPv4 (0.0.0.0/0)
---- Tipo: HTTP / Protocolo: TCP / Intervalo de portas: 80 / Tipo de origem: Qualquer local-IPv4 (0.0.0.0/0)
-- Armazenamento: 8GB (nível gratuito)
-- Dados do usuário (User Data - inserir comandos):
#!/bin/bash
apt update -y
DEBIAN_FRONTEND=noninteractive apt install -y apache2 dnsutils
systemctl enable apache2 --now
echo "&lt;h1&gt;web1: $(hostname)&lt;/h1&gt;" &gt; /var/www/html/index.html
- Executar instância (anotar IPv4 público e privado da instância)

--- CRIAR INSTÂNCIA EC2 (web2) ---
EC2 / Instâncias / Executar instâncias
- Nome: web2
- AMI: Ubuntu Server (nível gratuito)
- Tipo: t3.micro (verificar se região é t2 ou t3 nível gratuito)
- Par de chaves: Selecionar route53-key1
- Rede: Selecionar grupo de segurança comuns: grupoSeg-route53-ssh-http
- Armazenamento: 8GB (nível gratuito)
- Dados do usuário (User Data - inserir comandos):
#!/bin/bash
apt update -y
DEBIAN_FRONTEND=noninteractive apt install -y apache2 dnsutils
systemctl enable apache2 --now
echo "&lt;h1&gt;web2: $(hostname)&lt;/h1&gt;" &gt; /var/www/html/index.html
- Executar instância (anotar IPv4 público e privado da instância)

--- CRIAR ZONA PRIVADA ROUTE 53 ---
Route 53 / Zonas hospedadas / Criar zona hospedada
- Nome do domínio: ubsocial.local
- Tipo de zona hospedada: Privada para VPC
- VPCs associadas:
-- Região: selecionar região atual
-- VPC: selecionar VPC padrão
Criar zona hospedada

--- CRIAR REGISTROS DNS NA ZONA PRIVADA ---
Route 53 / Zonas hospedadas / Selecionar ubsocial.local / Criar registro
- Nome: web1 (ficará web1.ubsocial.local)
- Tipo: A - endereço IPv4
- Valor: IPv4 privado da instância web1
Adicionar outro registro

- Nome: web2 (ficará web2.ubsocial.local)
- Tipo: A - endereço IPv4
- Valor: IPv4 privado da instância web2
Criar registros

--- TESTAR RESOLUÇÃO DNS VIA INSTÂNCIAS EC2 (via SSH Linux) ---
- Baixar arquivo route53-key1.pem
- Ajustar permissão da chave: chmod 400 route53-key1.pem

- Acessar instância web1 via SSH: ssh -i route53-key1.pem ubuntu@IP-PUBLICO-WEB1
- Criar link para mudar DNS para AWS: sudo ln -sf /run/systemd/resolve/resolv.conf /etc/resolv.conf
- Editar configurações: sudo nano /etc/systemd/resolved.conf (inserir conteúdo abaixo no final do arquivo:)
DNS=169.254.169.253
Domains=sa-east-1.compute.internal
- Reiniciar serviços: sudo systemctl restart systemd-resolved

- Testar resolução DNS web2.ubsocial.local: dig web2.ubsocial.local +short
- Acessar web2 via DNS: curl http://web2.ubsocial.local

- Acessar instância web2 via SSH: ssh -i route53-key1.pem ubuntu@IP-PUBLICO-WEB2
- Testar resolução DNS web1.ubsocial.local: dig web1.ubsocial.local +short
- Acessar web1 via DNS: curl http://web1.ubsocial.local

--- Exclusões ---
1.EC2 / Instâncias / Selecionar web1 / Ações / Instância de estado / Parar, depois Terminar
2.EC2 / Instâncias / Selecionar web2 / Ações / Instância de estado / Parar, depois Terminar
3.EC2 / Grupos de segurança / Selecionar grupoSeg-route53-ssh-http / Ações / Excluir
4.EC2 / Pares de chaves / Selecionar route53-key1 / Ações / Excluir par de chaves
5.Route 53 / Zonas hospedadas / Selecionar ubsocial.local / Selecionar todos os registros (exceto NS e SOA) / Ações / Excluir registros
6.Route 53 / Zonas hospedadas / Selecionar ubsocial.local / Ações / Excluir zona hospedada
</code></pre></small>

            <br><h4>Amplify:</h4>
            <p id="textoPost">Conjunto de ferramentas (CLI, libraries/SDKs, UI components) e serviços para desenvolvimento, deploy e operação de aplicações web e mobile full-stack - inclui hosting (CI/CD), integração com autenticação, storage, APIs (GraphQL/AppSync e REST), funções serverless, analytics, etc. Funciona como camada que facilita criar backends (ou conectar a backends existentes) e integrar isso ao frontend. Integra-se com Cognito (autenticação/usuários), S3 + CloudFront (hosting estático e storage de arquivos), AppSync (GraphQL) e Amazon DynamoDB (APIs GraphQL com realtime), API Gateway + AWS Lambda (APIs REST/funções serverless), entre outros. Utilizado no cotidiano de MVP (front-end + autenticação + API), sites estáticos e SPAs com CI/CD (conexão Git/build/deploy automático), sistemas com login (signup/signin), perfis de usuário, upload/armazenamento de mídia, entre outros. Objetivo é hospedar app Vue 3 (Vite + TypeScript), e prepará-lo para receber outros serviços AWS (necessário conta no GitHub):</p>
<small><pre><code>
--- CRIAR REPOSITÓRIO GITHUB ---
GitHub / New repository
- Nome: amplify-vue-demo1
- Visibilidade: Público
Criar repositório
- Clonar repositório localmente: git clone URL-DO-REPOSITORIO && cd amplify-vue-demo1

--- CRIAR APP VUE 3 COM VITE + TYPESCRIPT ---
- Instalar projeto: npm create vite@latest amplify-vue-demo -- --template vue-ts
- Entrar na pasta do projeto: cd amplify-vue-demo
- Instalar dependências: npm install
- Instalar Amplify: npm install aws-amplify @aws-amplify/ui-vue
- Construir projeto: npm run build
- Instalar Amplify: npm create amplify@latest
- Em .gitignore, remover linha /dist
- Publicar código no GitHub: git add . && git commit -m "Projeto inicial" && git push && git status

--- CONECTAR AMPLIFY AO REPOSITÓRIO GITHUB ---
Amplify / Implantar um app
- Provedor: GitHub (conectar)
- Selecionar repositório: amplify-vue-demo1 / Ramificação: main (padrão)
- Nome da aplicação: amplify-vue-demo1
- Editar arquivo YML:
version: 1
applications:
  - frontend:
      phases:
        preBuild:
          commands:
            - cd amplify-vue-demo
            - npm install
        build:
          commands:
            - npm run build
      artifacts:
        baseDirectory: amplify-vue-demo/dist
        files:
          - "**/*"
      cache:
        paths:
          - amplify-vue-demo/node_modules/**/*

- Salvar e implantar
- Testar app no browser: clicar em URL gerada pelo Amplify

--- Exclusões ---
1.Amplify / Aplicativos / Selecionar amplify-vue-demo1 / Ações / Excluir aplicativo
2.(Opcional) GitHub / Repositório amplify-vue-demo1 / Settings / Delete this repository
</code></pre></small>

            <br><h4>EKS:</h4>
            <p id="textoPost">Serviço de hospedagem e gestão de control plane Kubernetes, a partir de outros serviços na cloud (EC2, Fargate, híbrido). Integra-se com outros serviços AWS, na composição dos nodes VMs EC2, ou serverless Fargate (sem VMs), conectados em rede VPC, balanceados via ELB, e registrados em EC2. Usado na orquestração e deploy de microserviços em contêineres (scaling, rollout), plataformas internas / PaaS para devs com CI/CD, workloads ML via jobs em containers (com autoscaling e GPU em EC2 quando necessário), e ambientes híbridos/edge (EKS Anywhere / Hybrid Nodes para rodar Kubernetes on-prem ou em devices). Objetivo é criar cluster EKS Fargate, e acessar pod Deployment e Service nginx:</p>
<small><pre><code>
--- CRIAR CLUSTER EKS FARGATE ---
EKS / Clusters / Criar cluster
- Opções de configuração: Configuração rápida (com o modo automático do EKS)
- Nome: eks-fargate-tutorial1

- Perfil do IAM do cluster: Criar perfil recomendado (redirecionará para IAM)
-- Tipo de entidade confiável: Serviço AWS
-- Serviço ou caso de uso: EKS - Auto Cluster
Avançar
--- Nome da função: AmazonEKSAutoClusterRole
Criar perfil / Voltar ao EKS / Atualizar / Selecionar esse perfil do cluster (AmazonEKSAutoClusterRole)

- Perfil do IAM do nó: Criar perfil recomendado (redirecionará para IAM)
-- Tipo de entidade confiável: Serviço AWS
-- Serviço ou caso de uso: EKS - Auto Node
Avançar
--- Nome da função: AmazonEKSAutoNodeRole
Criar perfil / Voltar ao EKS / Atualizar / Selecionar esse perfil do nó (AmazonEKSAutoNodeRole)
Criar

--- CONFIGURAR CLUSTER VIA CLOUDSHELL ---
CloudShell / Abrir terminal
- Acessar cluster: aws eks update-kubeconfig --name eks-fargate-tutorial1 --region sa-east-1
- Verificar clusters: aws eks list-clusters --region sa-east-1
- Verificar nós do cluster: kubectl get nodes
- Criar namespace: kubectl create namespace fargate-demo
- Verificar namespaces: kubectl get namespaces
- Associar Fargate ao namespace: kubectl annotate namespace fargate-demo eks.amazonaws.com/compute-type=fargate
- Verificar anotação: kubectl get namespace fargate-demo -o jsonpath='{.metadata.annotations}'
- Implantar app simples: kubectl apply -f https://k8s.io/examples/application/deployment.yaml -n fargate-demo
- Verificar pods: kubectl get pods -n fargate-demo (status Running)

Pod nginx sem load balancer, acessível via proxy kubectl:
- Expôr app via Service, sem gerar Load Balancer: kubectl expose deployment nginx-deployment --port=80 --type=ClusterIP -n fargate-demo
- Verificar Service: kubectl get services -n fargate-demo
- Acessar pod nginx via proxy kubectl: kubectl port-forward svc/nginx-deployment 8080:80 -n fargate-demo
- Testar acesso ao nginx via host docker: curl http://localhost:8080

--- Exclusões ---
1.CloudShell, excluir namespace: kubectl delete namespace fargate-demo
2.EKS / Clusters / Selecionar eks-fargate-tutorial1 / Ações / Excluir cluster
3.IAM / Funções / Selecionar AmazonEKSAutoClusterRole / Ações / Excluir função
4.IAM / Funções / Selecionar AmazonEKSAutoNodeRole / Ações / Excluir função
</code></pre></small>

            <br><h4>CloudTrail:</h4>
            <p id="textoPost">CloudTrail registra trilhas de logs das ações na conta AWS (API calls, Console, SDK/CLI). Serve para auditoria, governança, segurança, investigação e solução de problemas. Integra-se com S3 (destino padrão para armazenar arquivos de log gerados por trails), CloudWatch Logs / CloudWatch Alarms (enviar logs para CloudWatch Logs permite criar métricas, filtros e alarmes sobre eventos específicos, como criação de usuário IAM). Usa EventBridge (antes CloudWatch Events) para rotear eventos do CloudTrail em automações (enviar notificações ou acionar lambdas quando há alteração em políticas IAM). Integra-se com Athena / CloudTrail Lake para consultar e analisar logs (Athena consulta arquivos S3; CloudTrail Lake é data store com queries mais avançadas). Também, AWS Config / SIEM / ferramentas externas (Datadog, Splunk, etc) usam CloudTrail como fonte para inventário/monitoramento contínuo e correlação com alertas de segurança. Utilizado no cotidiano para detectar logins incomuns, chamadas de API fora do horário, criação de chaves IAM, também para gerar provas de alterações (por ex. alteração de regras IAM, criação/exclusão de buckets) para auditorias (SOC, PCI, etc.). Também utilizado para investigar "quem removeu/ligou/desligou" um recurso (quem deletou instância EC2). Utilizado para acionar correções automáticas (via EventBridge / Lambda) quando evento sensível acontece. E aplicado em armazenamento de logs em S3 / CloudTrail Lake e execução de queries para entender sequência de eventos, em análise forense. Objetivo é criar trilha de logs para acompanhar criação de instância EC2:</p>
<small><pre><code>
--- CRIAR TRAIL CLOUDTRAIL ---
CloudTrail / Trilhas / Criar trilha
- Nome: curso-cloudtrail1
Criar trilha (criará bucket S3)

--- ENVIAR LOGS PARA CLOUDWATCH LOGS ---
CloudTrail / Trilhas / Selecionar curso-cloudtrail1 / Editar
- CloudWatch Logs: Editar e habilitar
- Grupo de logs: Criar novo
-- Nome: curso-cloudtrail-logs1
- Função do IAM: Criar nova função
-- Nome: CloudTrailToCloudWatchLogsRole1
Salvar alterações

--- TESTAR GERAÇÃO DE LOGS ---
EC2 / Instâncias / Executar instâncias
- Nome: ubuntuTeste1
- AMI: Ubuntu Server (nível gratuito)
- Tipo: t3.micro (verificar se região é t2 ou t3 nível gratuito)
- Criar par de chaves:
-- Nome: keyTeste1
-- Tipo: RSA
-- Formato: conforme SO de sua máquina
- Rede:
-- Atribuir IP público automaticamente: habilitar
-- Grupo de segurança criado automaticamente, com regras:
--- Permitir tráfego HTTP qualquer lugar
--- Permitir tráfego HTTPS qualquer lugar
--- Permitir tráfego SSH qualquer lugar
- Armazenamento: 8GB (nível gratuito)
Executar instância

--- VERIFICAR LOGS NO CLOUDTRAIL E CLOUDWATCH LOGS ---
CloudTrail / Eventos / Verificar eventos recentes (deve listar evento RunInstances)
CloudWatch / Logs / Grupos de logs / Selecionar curso-cloudtrail-logs1 / Verificar streams de logs (deve listar evento RunInstances)

--- Exclusões ---
1.EC2 / Instâncias / Selecionar ubuntuTeste1 / Ações / Instância de estado / Parar, depois Terminar
2.EC2 / Pares de chaves / Selecionar keyTeste1 / Ações / Excluir par de chaves
3.EC2 / Grupos de segurança / Selecionar grupo criado automaticamente / Ações / Excluir
4.CloudTrail / Trilhas / Selecionar curso-cloudtrail1 / Ações / Excluir trilha (deletará bucket S3)
5.IAM / Funções / Selecionar CloudTrailToCloudWatchLogsRole1 / Ações / Excluir função
6.CloudWatch / Logs / Grupos de logs / Selecionar curso-cloudtrail-logs1 / Ações / Excluir grupo de logs
7.S3 / Buckets / Selecionar bucket criado pelo CloudTrail / Ações / Excluir bucket
8.EventBridge / Regras / Selecionar regra criada automaticamente pelo CloudTrail / Ações / Excluir regra
</code></pre></small>

            <br><h4>EventBridge:</h4>
            <p id="textoPost">Barramento de eventos serverless que permite conectar produtores de eventos (serviços AWS, aplicações próprias ou provedores SaaS) a consumidores (Lambda, Step Functions, SNS, SQS, API Destinations etc.). Ele recebe, filtra, transforma e roteia eventos para alvo(s), permitindo arquiteturas assíncronas e desacopladas. Integra-se com basicamente todos serviços AWS, na criação de regras para disparo em alvos suportados (outros serviços AWS, ou serviços terceiros). Utilizado no cotidiano em notificações entre setores de sistema (faturamento, inventário, envio de e-mail), via regras para Lambda, SNS e Step Functions. Também utilizado na recepção de webhooks e roteá-los em processos internos sem escrever servidor webhook. Também incorporado em automação industrial, reagindo a eventos CloudTrail ou Datadog para auto-remediação ou alertas (ex: criar ticket no PagerDuty). Também no agendamento de jobs recorrentes (EventBridge Scheduler) para tarefas periódicas. Objetivo é publicar evento EventBridge (barramento custom), via regra JSON, em alvo função Lambda, que registrará o evento:</p>
<small><pre><code>
--- CRIAR FUNÇÃO LAMBDA ---
Lambda / Funções / Criar função
- Criar função do zero
- Nome: evento_logger_curso1
- Tempo de execução: Python
- Permissões / Alterar a função de execução padrão: Selecionar 'Criar uma função com permissões básicas do Lambda'
Criar função

--- ADICIONAR CÓDIGO NA FUNÇÃO LAMBDA ---
Lambda / Selecionar função evento_logger_curso1 / Aba Código / Editar código:
import json
def lambda_handler(event, context):
    print("EVENTO RECEBIDO:")
    print(json.dumps(event, indent=2, ensure_ascii=False))
    return &#123;"status": "ok"&#125;

- No VSCode da AWS, clicar em Deploy

--- TESTAR FUNÇÃO LAMBDA ---
Lambda / Selecionar função evento_logger_curso1 / Aba Testar / Evento de teste
- Ação de evento de teste: Criar novo evento
- Nome do evento: teste_evento1
- JSON do evento (inserir conteúdo abaixo):
&#123;"teste": "ok"&#125;
Salvar e Testar
- Verificar resultado: status ok (gerará logs em grupo de logs no CloudWatch)

--- CRIAR BARRAMENTO DE EVENTOS CUSTOMIZADO ---
EventBridge / Barramentos de eventos / Criar barramento de eventos
- Nome: prj_cafe_bus1
Criar

--- CRIAR REGRA EVENTBRIDGE ---
EventBridge / Barramentos de eventos / Selecionar prj_cafe_bus1 / Aba Regras / Criar regra
- Nome: regra_pedido_curso1
- Tipo de regra: Regra com um padrão de eventos
Avançar
- Fonte do evento: Outros
- Método de criação: Padrão personalizado (editor JSON)
- Padrão de evento (inserir conteúdo abaixo):
&#123;
  "source": ["app.cafes"],
  "detail-type": ["pedido_realizado1"]
&#125;
- Avançar
- Tipos de destino: Serviço da AWS (Função do Lambda)
- Local do destino: Destino nessa conta (evento_logger_curso1)
Avançar / Criar regra

--- PUBLICAR EVENTO NO BARRAMENTO EVENTBRIDGE ---
EventBridge / Barramentos de eventos / Selecionar prj_cafe_bus1 / Enviar eventos
- Barramento de eventos: prj_cafe_bus1
- Fonte do evento: app.cafes
- Tipo de detalhe: pedido_realizado1
- Detalhes do evento (inserir conteúdo abaixo):
&#123;
  "id_pedido": "12345",
  "valor": 49.90,
  "cliente": "João"
&#125;
- Enviar (aparecerá mensagem de envio de sucesso)

--- VERIFICAR EVENTO RECEBIDO NA LAMBDA ---
Lambda / Selecionar função evento_logger_curso1 / Aba Monitoramento / Visualizar logs no CloudWatch
- Selecionar stream de logs mais recente / Verificar evento recebido (deve listar o evento enviado)

--- VERIFICAR LOGS NO CLOUDWATCH ---
CloudWatch / Logs / Grupos de logs / Selecionar /aws/lambda/evento_logger_curso1 / Selecionar stream de logs mais recente / Verificar evento recebido (deve listar o evento enviado)

--- Exclusões ---
1.Lambda / Selecionar função evento_logger_curso1 / Ações / Excluir função
2.EventBridge / Barramentos de eventos / Selecionar prj_cafe_bus1 / Aba Regras / Selecionar regra_pedido_curso1 / Ações / Excluir
3.EventBridge / Barramentos de eventos / Selecionar prj_cafe_bus1 / Ações / Excluir barramento de eventos
4.IAM / Funções / Selecionar função criada automaticamente para a Lambda (Amazon_EventBridge_Invoke_Lambda_...) / Ações / Excluir função
5.IAM / Políticas / Selecionar política criada automaticamente para a Lambda (Amazon_EventBridge_Invoke_Lambda_...) / Ações / Excluir política
6.CloudWatch / Logs / Grupos de logs / Selecionar /aws/lambda/evento_logger_curso1 / Ações / Excluir grupo de logs
</code></pre></small>

            <br><h4>Step Functions:</h4>
            <p id="textoPost">Serviço de orquestração de workflows baseado em máquinas de estado (workflows), que coordenam passos (estados) de execução de tarefas. Há workflows standard (execuções auditáveis, longa duração) e express (alta taxa/baixa latência, para cargas massivas). Integra-se com Lambda (invocar funções serverless), SQS/SNS (tráfego de mensagens), DynamoDB (gravar registros de fluxo), ECS / Fargate, Batch, Glue, Athena, SageMaker (acionar jobs, ETL, consultas, treinos/inferência ML), e API Gateway (orquestrar APIs). Utilizado em Pipelines ETL, com transformação de dados em data warehouse, orquestração de microserviços via ECS e Lambda. Utilizado também em jobs auditáveis, e treino de dados ML via SageMaker. Objetivo é executar função Lambda que retorna saudação e máquina de estado invocada via Step Functions:</p>
<small><pre><code>
--- CRIAR FUNÇÃO LAMBDA ---
Lambda / Funções / Criar função
- Criar função do zero
- Nome: hello-stepfn1
- Tempo de execução: Python
- Permissões / Alterar a função de execução padrão: Selecionar 'Criar uma função com permissões básicas do Lambda'
Criar função (anotar ARN da função)

--- ADICIONAR CÓDIGO NA FUNÇÃO LAMBDA ---
Lambda / Selecionar função hello-stepfn1 / Aba Código / Editar código:
def lambda_handler(event, context):
    if "Payload" in event:
        event = event["Payload"]
    nome = event.get("nome", "mundo")
    return &#123;
        "greeting": f"Olá, &#123;nome&#125;!"
    &#125;
- No VSCode da AWS, clicar em Deploy

--- TESTAR FUNÇÃO LAMBDA ---
Lambda / Selecionar função hello-stepfn1 / Aba Testar / Evento de teste
- Ação de evento de teste: Criar novo evento
- Nome do evento: teste_hello1
- JSON do evento (inserir conteúdo abaixo): &#123;"nome": "UB Social"&#125;
Salvar e Testar
- Verificar resultado: deve retornar "Olá, UB Social!"

--- CRIAR MÁQUINA DE ESTADO STEP FUNCTIONS ---
Step Functions / Máquinas de estado / Criar máquina de estado
- Criar do zero
- Nome: HelloStepFunction1
- Tipo de máquina de estado: Padrão
Avançar
- Definição da máquina de estado (inserir conteúdo abaixo) - aba Código:
&#123;
  "Comment": "Exemplo Step Function em Lambda",
  "StartAt": "InvocarLambdaHello1",
  "States": &#123;
    "InvocarLambdaHello1": &#123;
      "Type": "Task",
      "Resource": "arn:aws:states:::lambda:invoke",
      "Parameters": &#123;
        "FunctionName": "ARN-FUNCAO-LAMBDA-AQUI",
        "Payload.$": "$"
      &#125;,
      "End": true
    &#125;
  &#125;
&#125;
- Aba Configuração / Permissões
- Perfil de execução: Criar novo perfil
Criar e Confirmar

--- EXECUTAR MÁQUINA DE ESTADO ---
Step Functions / Selecionar HelloStepFunction1 / Executar
- Nome da execução: exec_hello_1
- Entrada: &#123; "nome": "Mateus" &#125;
Iniciar execução
- Verificar status: Succeeded (ver aba Entrada e Saída - retornará "Olá, mundo!")

--- Exclusões ---
1.Step Functions / Selecionar HelloStepFunction1 / Ações / Excluir máquina de estado
2.Lambda / Selecionar função hello-stepfn1 / Ações / Excluir função
3.IAM / Funções / Selecionar função criada automaticamente para a Step Function (AWSServiceRoleForStepFunctions...) / Ações / Excluir função
4.IAM / Políticas / Selecionar política criada automaticamente para a Step Function (AWSServiceRoleForStepFunctions...) / Ações / Excluir política
5.CloudWatch / Logs / Grupos de logs / Selecionar /aws/vendedlogs/states/HelloStepFunction1 / Ações / Excluir grupo de logs
</code></pre></small>

            <br><h4>SageMaker</h4>
            <p id="textoPost">Serviço de gestão e implantação de modelos de Machine Learning (ML) em escala. Integra-se com S3 (armazenamento de datasets), Lambda (funções com endpoints de inferência do modelo treinado), Redshift / Athena (consulta de dados analíticos para alimentar modelo), Glue (preparação e limpeza de dados para treino), Bedrock (combinar modelos tradicionais de ML com modelos generativos). Utilizado no cotidiano em análises e predições (risco de crédito, previsão de vendas e demandas), detecção de fraudes, classificação de textos (análise de sentimentos), e visão computacional (identificação de imagens). Objetivo é treinar modelo Random Forest, que prevê se passageiro vai sobreviver ou não, com base no dataset online Titanic:</p>
<small><pre><code>
--- CRIAR NOTEBOOK SAGEMAKER ---
SageMaker AI / Notebooks / Criar instância de bloco de anotações
- Nome: notebook-ml-free-tier
- Tipo de instância: nível gratuito
- Permissões e criptografia: Criar nova função do IAM (com Qualquer bucket do S3)
Criar bloco de anotações

--- TREINAR MODELO ML ---
SageMaker AI / Notebooks / Selecionar notebook-ml-free-tier / Abrir JupyterLab
- Criar novo notebook conda_python3
- Inserir código abaixo em células do notebook:
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

url = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
df = pd.read_csv(url)
print("Dataset carregado!\n")
print(df.head())
df = df.copy()

df['Age'] = df['Age'].fillna(df['Age'].mean())
df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])
df['Cabin'] = df['Cabin'].fillna('U')
df['Cabin'] = df['Cabin'].apply(lambda x: x[0])
print("\nValores únicos em 'Cabin' após tratamento:", df['Cabin'].unique())

df = pd.get_dummies(df, columns=['Sex', 'Embarked', 'Cabin'], drop_first=True)
X = df.drop(['Survived', 'Name', 'Ticket'], axis=1)
y = df['Survived']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
acc = accuracy_score(y_test, y_pred)

print(f"\nAcurácia do modelo: &#123;acc:.2f&#125;")
print("\nRelatório de classificação:\n")
print(classification_report(y_test, y_pred))

passageiro_exemplo = pd.DataFrame([X_test.iloc[0]], columns=X_test.columns)
previsao = model.predict(passageiro_exemplo)[0]
print(f"\nPrevisão (1 = Sobreviveu, 0 = Não sobreviveu): &#123;previsao&#125;")

- Executar células (Shift + Enter) para treinar modelo e testar predições

--- Exclusões ---
1.SageMaker AI / Notebooks / Selecionar notebook-ml-free-tier / Ações / Excluir instância de bloco de anotações
2.IAM / Funções / Selecionar função criada automaticamente para o SageMaker (AmazonSageMaker-ExecutionRole-...) / Ações / Excluir função
3.IAM / Políticas / Selecionar política criada automaticamente para o SageMaker (AmazonSageMaker-ExecutionRole-...) / Ações / Excluir política
4.CloudWatch / Logs / Grupos de logs / Selecionar /aws/sagemaker/Endpoints/notebook-ml-free-tier / Ações / Excluir grupo de logs
</code></pre></small>

            <br><h4>Bedrock:</h4>
            <p id="textoPost">Serviço serverless para construção de aplicações de IA generativa, via provedores como Anthropic, AI21 Labs, Stability AI e modelos da própria AWS (Titan) via API unificada. Integra-se com S3, Kendra e DynamoDB para armazenar dados de suporte, Lambda e API Gateway para chamadas de funções serverless e APIs, CloudWatch para coleta de logs e tokens. Também integra-se com SageMaker, para preparo, treino e gestão de modelos complementares em pós-processamento. Utilizado em assistentes e chatbots corporativos, geração de conteúdos automatizados (textos, vídeos, imagens, documentos, blogs), document processing e automação de escritório, buscas inteligentes e RAG (Retrieval Augmented Generation) em respostas a prompts. Também utilizado em agentes autônomos (via AgentCore), que podem planejar, agir, recuperar dados de várias fontes, tomar decisões baseadas em prompts e realizar workflows completos. Objetivo é criar agente de IA, para responder perguntas sobre cafés e simular consulta de preços em "API fictícia", via função Lambda:</p>
<small><pre><code>
OBS: Necessário alterar região para Norte da Virgínia (us-east-1)

--- CRIAR FUNÇÃO LAMBDA ---
Lambda / Funções / Criar função
- Criar função do zero
- Nome: cafePreco1
- Tempo de execução: Python
- Permissões / Alterar a função de execução padrão: Selecionar 'Criar uma função com permissões básicas do Lambda'
Criar função

--- ADICIONAR CÓDIGO NA FUNÇÃO LAMBDA ---
Lambda / Selecionar função cafePreco1 / Aba Código / Editar código:
import logging
import json
from http import HTTPStatus
from typing import Dict, Any

logger = logging.getLogger()
logger.setLevel(logging.INFO)

def lambda_handler(event: Dict[str, Any], context: Any) -&gt; Dict[str, Any]:
    try:
        logger.info("Evento recebido: %s", json.dumps(event))
        action_group = event.get("actionGroup") or event.get("action_group")
        function = event.get("function", "ConsultarPreco")
        parameters = event.get("parameters", [])
        message_version = str(event.get("messageVersion", "1.0"))

        if not action_group:
            raise KeyError("actionGroup ausente no evento")

        tipo_cafe = "capuccino"
        for p in parameters:
            if p.get("name") == "tipo_cafe":
                tipo_cafe = p.get("value", "capuccino")

        precos = &#123;
            "capuccino": 9,
            "espresso": 7,
            "latte": 10
        &#125;
        preco = precos.get(tipo_cafe.lower(), 9)

        response_body = &#123;
            "TEXT": &#123;
                "body": f"Valor do &#123;tipo_cafe&#125; é &#123;preco&#125;"
            &#125;
        &#125;

        final_response = &#123;
            "response": &#123;
                "actionGroup": action_group,
                "function": function,
                "functionResponse": &#123;
                    "responseBody": response_body
                &#125;
            &#125;,
            "messageVersion": message_version
        &#125;

        logger.info("Response final: %s", json.dumps(final_response))
        return final_response

    except KeyError as e:
        logger.error("Campo ausente: %s", str(e))
        return &#123;
            "statusCode": HTTPStatus.BAD_REQUEST,
            "body": json.dumps(&#123;"error": f"Campo ausente: &#123;str(e)&#125;"&#125;)
        &#125;
    except Exception as e:
        logger.error("Erro interno: %s", str(e))
        return &#123;
            "statusCode": HTTPStatus.INTERNAL_SERVER_ERROR,
            "body": json.dumps(&#123;"error": "Erro interno"&#125;)
        &#125;
- No VSCode da AWS, clicar em Deploy

--- TESTAR FUNÇÃO LAMBDA ---
Lambda / Selecionar função cafePreco1 / Aba Testar / Evento de teste
- Ação de evento de teste: Criar novo evento
- Nome do evento: teste_cafe1
- JSON do evento (inserir conteúdo abaixo):
&#123;
  "actionGroup": "ConsultarPrecoCafe__cafePreco1",
  "function": "ConsultarPreco",
  "parameters": [
    &#123;
      "name": "tipo_cafe",
      "value": "capuccino"
    &#125;
  ],
  "messageVersion": "1.0"
&#125;
- Salvar e Testar (deve retornar preço do café)

--- CRIAR AGENTE DE IA BEDROCK ---
Bedrock / Agentes de IA / Criar agente de IA
- Nome: agente_cafe1
Criar
- Modelo de linguagem: Amazon Nova Pro
- Instruções para agentes: Você é um assistente especializado em cafés. Responda perguntas sobre tipos de café e seus preços. Se a pergunta envolver preços, consulte a função Lambda cafePreco1 para obter o preço correto
- Grupos de Ação / Adicionar:
-- Nome: ConsultarPrecoCafe
-- Tipo de ação: Definir com detalhes da função
-- Selecione uma função do Lambda existente (selecionar cafePreco1)
- Função de ação: cafePreco1
- Parâmetros:
-- Nome: tipo_cafe
-- Descrição: Tipo de café para consultar o preço
-- Tipo: String
-- Obrigatório: True
Criar, Salvar e sair

--- PERMITIR LAMBDA PARA BEDROCK ---
Lambda / Selecionar função cafePreco1 / Aba Configuração / Permissões / Adicionar permissão
- Tipo: Serviço AWS
- Serviço: Other
- ID da declaração: cafePrecoBedrockPermission1
- Entidade principal: bedrock.amazonaws.com
- ARN de origem: ARN do agente de IA criado
- Ação: lambda:InvokeFunction
Salvar

--- TESTAR AGENTE DE IA BEDROCK ---
Bedrock / Agentes de IA / Selecionar agente_cafe1 / Testar agente / Preparar
- Mensagem do usuário: Qual o preço de um cappuccino? (responderá com preço conforme função Lambda)

--- Exclusões ---
1.Bedrock / Agentes de IA / Selecionar agente_cafe1 / Ações / Excluir agente de IA
2.Lambda / Selecionar função cafePreco1 / Ações / Excluir função
3.IAM / Funções / Selecionar função criada automaticamente para o Bedrock (AmazonBedrock-InvokeLambda-...) / Ações / Excluir função
4.IAM / Políticas / Selecionar política criada automaticamente para o Bedrock (AmazonBedrock-InvokeLambda-...) / Ações / Excluir política
5.CloudWatch / Logs / Grupos de logs / Selecionar /aws/lambda/cafePreco1 / Ações / Excluir grupo de logs
</code></pre></small>

            <br><h4>Amazon Managed Blockchain:</h4>
            <p id="textoPost">Serviço de gestão de redes blockchain (suporta Hyperledger Fabric para redes privadas/consórcio e Access/Query para blockchains públicas como Ethereum, Bitcoin, Polygon). Oferece nodes peer, autoridade de certificados (CA) para Fabric, APIs RPC para acessar redes públicas e serviços serverless para consultas de dados de blockchain. Integra-se com S3 (armazenamento off-chain), Lambda e API Gateway (expor APIs que leem/escrevem na blockchain), SNS e Step Functions (workflows reativos a eventos), CloudTrail e CloudWatch (logs e auditorias). Usado rastreabilidade de ativos e supply chain (gravar transferências/estados de itens) com provas imutáveis, registros compartilhados entre organizações aplicações Web3 / dApps (carteiras, exploradores de bloco, leitura de saldos/transações usando AMB Access). Também usado em prova de integridade / assinatura de documentos (armazenar hashes na cadeia e conteúdo em S3 off-chain). Objetivo AQUI</p>
<small><pre><code>
--- CRIAR REDE BLOCKCHAIN ---
AMB / Redes / Aba Redes privadas / Criar rede privada
- Estrutura: Hyperledger Fabric
- Edição: starter
- Nome: rede-blockchain-curso1
Avançar
- Nome do membro: membro-curso1
- Nome de usuário do administrador: admin
- Senha do administrador: Ubsocial1
Avançar / Criar rede e membro

--- CRIAR PEER NODE ---
AMB / Redes / Selecionar rede-blockchain-curso1 / Aba Membros / Selecionar membro-curso1 / Aba Nós / Criar nó peer (dados padrão)

CONTINUA AQUI...
1.Criar rede privada e membro
2.No membro, criar nó peer
3.Conectar ao nó peer via CLI do Hyperledger Fabric
4.Criar canal, juntar canal, instalar chaincode, instanciar chaincode
5.Executar transações de gravação e consulta no ledger
6.Excluir recursos criados
</code></pre></small>

            <br><h4>App Runner:</h4>
            <p id="textoPost">Serviço de gestão e execução de aplicações web e APIs containerizadas (ou via código-fonte) serverless, realizando build, deploy, balanceamento de carga, HTTPS e auto-scaling automaticamente. Integra-se com ECR para upload de origens via containers, ou Git para via repositórios. Utiliza RDS / DynamoDB / S3 / SQS / SNS para armazenamento de dados e mensageria, CloudWatch para gestão de logs e Route 53 para gestão de DNS customizado. Objetivo é fazer deploy de API REST Django, via container Docker em ECR:</p>
<small><pre><code>
- Origem do código-fonte da API Django: http://github.com/mateusschwede/workover_aws/tree/main/3_app_runner
- Região: us-east-1 (Norte da Virgínia)

--- CRIAR REPOSITÓRIO ECR ---
ECR / Repositórios / Criar repositório
- Nome: URL-DO-ECR/ubsocial/meu-app-runner
Criar (copiar URL do repositório)

--- CONSTRUIR E PUBLICAR IMAGE NO ECR ---
CloudShell:
- Logar no ECR: aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin URL-DO-REPOSITORIO
- Baixar código-fonte da API Django: curl -L https://codeload.github.com/mateusschwede/workover_aws/zip/refs/heads/main -o workover.zip && unzip workover.zip "workover_aws-main/3_app_runner/paris_cafe/*" && mv workover_aws-main/3_app_runner/paris_cafe . && rm -rf workover_aws-main workover.zip && cd paris_cafe
- Criar imagem Docker: docker build -t meu-app-runner .
- Marcar imagem para ECR: docker tag meu-app-runner:latest URL-DO-REPOSITORIO/ubsocial/meu-app-runner:latest
- Publicar imagem no ECR: docker push URL-DO-REPOSITORIO/ubsocial/meu-app-runner:latest

--- CRIAR SERVIÇO APPRUNNER ---
AWS App Runner / Criar um serviço do App Runner
- Tipo de repositório: Registro de contêiner
- Provedor: Amazon ECR
- URI da imagem de contêiner: Selecionar URL-DO-REPOSITORIO/ubsocial/meu-app-runner:latest
- Gatilho de implantação: Manual
- Função de acesso do ECR: Criar nova função de serviço
-- Nome: AppRunnerECRAccessRole1
Avançar
- Nome do serviço: meu-app-runner-service1
- Variáveis de ambiente: Adicionar variável de ambiente
-- Origem: Texto simples
-- Nome: DJANGO_SETTINGS_MODULE
-- Valor: paris_cafe.settings
Adicionar variável de ambiente
-- Origem: Texto simples
-- Nome: PYTHONUNBUFFERED
-- Valor: 1
Adicionar variável de ambiente
-- Origem: Texto simples
-- Nome: ALLOWED_HOSTS
-- Valor: *
Adicionar variável de ambiente
-- Origem: Texto simples
-- Nome: DEBUG
-- Valor: False
Adicionar variável de ambiente
-- Origem: Texto simples
-- Nome: SECRET_KEY
-- Valor: change-me-123456789
Avançar
- Porta: 8000
- Verificação de integridade:
-- Protocolo: HTTP
-- Caminho: /cafes/
-- Intervalo: 10 segundos
-- Tempo limite: 5 segundos
Criar e implantar (copiar URL do Domínio padrão)

--- ACESSAR APLICAÇÃO ---
- Acessar browser: URL-DO-DOMINIO-PADRAO/cafes/ (deve listar cafés em JSON)
- Acessar via cURL: curl https://URL-DO-DOMINIO-PADRAO/cafes/
- Adicionar café via cURL: curl -X POST https://URL-DO-DOMINIO-PADRAO/cafes/ -H "Content-Type: application/json" -d '{"nome":"UB Café","data_inauguracao":"2001-01-30","endereco":"rua frança 2","avaliacao":10}'

--- Exclusões ---
1.AWS App Runner / Selecionar meu-app-runner-service1 / Ações / Excluir serviço
2.ECR / Repositórios / Selecionar URL-DO-REPOSITORIO/ubsocial/meu-app-runner / Ações / Excluir repositório
3.IAM / Funções / Selecionar AppRunnerECRAccessRole1 / Ações / Excluir função
4.CloudWatch / Logs / Grupos de logs / Selecionar /aws/apprunner/meu-app-runner-service1 / Ações / Excluir grupo de logs
</code></pre></small>

            <hr><br><h4>Publicar container na AWS:</h4>
            <p id="textoPost">Publicar container nginx na AWS via Amazon Elastic Container Service (ECS) e Amazon Elastic Container Registry (ECR), com cluster Fargate.</p>
<small><pre><code>
--- CONTAINER NO HOST DOCKER ---
1.Criar Dockerfile:
FROM nginx:latest
RUN rm -rf /usr/share/nginx/html/*
RUN echo '&lt;h1&gt;UB Social&lt;/h1&gt;&lt;p&gt;Container com servidor nginx na AWS&lt;/p&gt;' &gt; /usr/share/nginx/html/index.html
2.Criar Image e construir container:
- docker build -t ubsocial/meu-nginx .
- docker run -dti -p 8080:80 ubsocial/meu-nginx2
3.Acessar nginx via host docker: curl http://localhost:8080

--- CRIAR USUÁRIO AWS ---
1.IAM / Usuários / Criar usuário
- Nome: usuarioUB1
- Fornecer acesso console AWS: habilitar
- Tipo: Quero criar usuário do IAM
- Senha do console: Senha gerada automaticamente
Próximo
- Permissões: Anexar políticas diretamente
-- AmazonEC2ContainerRegistryFullAccess
-- AmazonECS_FullAccess
-- AdministratorAccess
Próximo / Criar usuário / Baixar CSV
2.Selecionar usuário / Habilitar acesso console FMA
- Nome dispositivo: ubuntuTeste1
- MFA device: Chave de acesso ou chave de segurança
Próximo / Ativar via navegador
3.Selecionar usuário / Criar chave de acesso
- Tipo: CLI
- Valor etiqueta descrição: Criar containers
Criar chave de acesso / Baixar CSV

--- INSTALAR AWS CLI ---
1.curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
2.sudo apt update && sudo apt install -y unzip
3.unzip awscliv2.zip
4.sudo ./aws/install
5.aws --version
6.aws configure
- informar keys geradas no CSV com dados de chave de acesso do usuário
- região: sa-east-1
- Default output format: json
7.Login AWS CLI: aws ecr get-login-password --region sa-east-1 | docker login --username AWS --password-stdin ID-CONTA.dkr.ecr.sa-east-1.amazonaws.com

--- PUBLICAR IMAGE NA AWS ---
1.ECR / Repositórios / Criar repositório
- Nome: ubsocial/meu-nginx
- Etiqueta: Mutable
Criar
2.No host Docker, upload Image na AWS:
- docker tag ubsocial/meu-nginx:latest ID-CONTA.dkr.ecr.sa-east-1.amazonaws.com/ubsocial/meu-nginx:latest
- docker push ID-CONTA.dkr.ecr.sa-east-1.amazonaws.com/ubsocial/meu-nginx:latest

--- CRIAR CLUSTER FARGATE ---
ECS / Clusters / Criar cluster
- Nome gerado automaticamente
- Infraestrutura: AWS Fargate (sem servidor)
Criar

--- CRIAR DEFINIÇÃO DE TAREFA ---
ECS / Definições de tarefa / Criar nova definição de tarefa
- Família: familia-task
- Tipo de inicialização: AWS Fargate
- CPU: .25vCPU
- Memória: .5GB
Container 1:
- Nome: meu-nginx-container
- URI da imagem: ID-CONTA.dkr.ecr.sa-east-1.amazonaws.com/ubsocial/meu-nginx:latest
- Porta do container: 80
Criar

--- CRIAR SERVIÇO FARGATE ---
ECS / Clusters / Selecionar cluster / Aba serviços / Criar
- Família da definição de tarefa: familia-task
- Nome do serviço gerado automaticamente
- Provedor de capacidade: Fargate (padrão)
- Tarefas desejadas: 1 (padrão)
- Rede VPC: padrão
- Sub-redes: padrão
- IP público: habilitar (padrão)
Criar

--- HABILITAR ACESSO AO CONTAINER AWS ---
ECS / Clusters / Selecionar cluster / Aba Serviços / Tarefas / Selecionar tarefa
- Aba Redes: clicar no ID da ENI
- Na ENI: clicar no grupo de segurança
- No grupo de segurança: editar regras de entrada (adicionar nova regra)
-- Tipo: HTTP
-- Protocolo: TCP (padrão)
-- Intervalo de portas: 80 (padrão)
-- Origem: Qualquer local-IPv4
-- 0.0.0.0/0
Salvar regras

--- ACESSAR CONTAINER AWS ---
ECS / Clusters / Selecionar cluster / Aba Serviços / Tarefas / Selecionar tarefa
- Aba Associações de rede: Copiar IP-AWS
- No host docker: curl http://IP-AWS

--- Exclusões ---
1.ECS / Clusters / Selecionar cluster / Excluir cluster
2.ECS / Definições de tarefa / Selecionar definição / familia-task / Ações / Cancelar registro
3.ECR / Repositórios / Selecionar repositório / Excluir
4.IAM / Usuários / Selecionar usuário / Excluir (desativar chave de acesso, e confirmar exclusão)
5.Apagar dados locais no host docker (images, container, Dockerfile)
</code></pre></small>

            <br><h4>Publicar projeto RESTful fullstack AWS:</h4>
            <p id="textoPost">Publicar projeto RESTful fullstack, com frontend Vue.js e backend Django, via criação de instância EC2 (Ubuntu).</p>
<small><pre><code>
--- CRIAR INSTÂNCIA AWS ---
EC2 / Instâncias / Executar instâncias
- Nome: ubuntuDjangoTeste1
- AMI: Ubuntu Server (nível gratuito)
- Tipo: t3.micro (verificar se região é t2 ou t3 nível gratuito)
- Criar par de chaves:
-- Nome: keyDjangoTeste1
-- Tipo: RSA
-- Formato: conforme SO de sua máquina
- Rede:
-- Atribuir IP público automaticamente: habilitar
-- Grupo de segurança criado automaticamente, com regras:
--- Permitir tráfego HTTP qualquer lugar
--- Permitir tráfego HTTPS qualquer lugar
--- Permitir tráfego SSH qualquer lugar
- Armazenamento: 8GB (nível gratuito)
Criar

--- CRIAR E ATRIBUIR GRUPO DE SEGURANÇA ---
EC2 / Grupos de segurança / Criar grupo de segurança
- Nome: grupoSegurancaTeste1
- Descrição: Grupo de seguranca para testes 1
- Regras de entrada:
-- SSH: porta 22, IP 0.0.0.0/0
-- HTTP: porta 80, IP 0.0.0.0/0
-- Personalizado TCP: porta 8000 (porta Django), IP 0.0.0.0/0
-- Personalizado TCP: porta 5173 (porta Vue.js), IP 0.0.0.0/0
Criar

EC2 / Instâncias / Selecionar instância / Ações / Segurança
- Alterar grupos de segurança para grupoSegurancaTeste1
Confirmar Executar instância (guardar IPv4 para acesso futuro)

--- CONECTAR INSTÂNCIA AWS ---
EC2 / Instâncias / Selecionar instância / Ações / Conectar CLI usando IP público (e executar comandos):
- sudo apt update && sudo apt install python3-pip npm python3-venv git -y && sudo pip3 install django djangorestframework markdown django-filter django-cors-headers pytest pytest-django pytest-html model_bakery --break-system-packages && sudo npm install -g @vue/cli
- curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash - && sudo apt install nodejs -y
- git clone https://github.com/mateusschwede/cafe_fullstack.git && cd cafe_fullstack/paris_cafe
- python3 manage.py migrate
- nano paris_cafe/settings.py (informar conteúdo abaixo):
ALLOWED_HOSTS = [
    'ec2-54-233-2-156.sa-east-1.compute.amazonaws.com', // IPv4 da instância EC2
    'localhost',
    '127.0.0.1',
]

- cd ../ && python3 manage.py runserver 0.0.0.0:8000 &
-- Enter para sair do comando iterativo (servidor Django executando em background nohup)
- cd ../cafe-frontend
- sudo npm install
- nano vite.config.ts (informar conteúdo abaixo):
export default defineConfig(&#123;
    // outro conteúdo
    server: &#123;
        host: '0.0.0.0',
        port: 5173,
        allowedHosts: [
            'ec2-54-233-2-156.sa-east-1.compute.amazonaws.com' // IPv4 da instância EC2
        ]
    &#125;
&#125;)

- nano src/services/api.ts (informar conteúdo abaixo):
// outro conteúdo
baseURL: 'http://ec2-54-233-2-156.sa-east-1.compute.amazonaws.com:8000' // IPv4 da instância EC2

- sudo npx vite --host
-- Acessar API REST backend Django: http://ipv4_aws:8000
-- Acessar projeto no browser: http://ipv4_aws:5173

--- Exclusões ---
1.EC2 / Instâncias / Selecionar instância / Ações / Estado da instância / Encerrar instância
2.EC2 / Grupos de segurança / Selecionar grupoSegurancaTeste1 / Excluir
3.EC2 / Chaves de acesso / Selecionar ubuntuDjangoTeste1-key.pem / Excluir
</code></pre></small>
        </div>
    </div>


<!--Rodapé-->
<div class="row">
    <div class="col-sm-12 text-center bg-black text-light pt-4 pb-3">
        <p>Elaborado por Mateus Schwede<br><small class="text-muted">ubsocial.github.io</small></p>
    </div>
</div>

</div>
</body>
</html>